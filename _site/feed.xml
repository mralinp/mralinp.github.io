<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-05-01T22:11:13+03:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">mralinp</title><subtitle>My awesome blog</subtitle><entry><title type="html">Smart Card: An Introduction to smart card development</title><link href="http://localhost:4000/blog/embeded/smart-card/2023/07/19/smart-card-intro.html" rel="alternate" type="text/html" title="Smart Card: An Introduction to smart card development" /><published>2023-07-19T20:50:01+03:30</published><updated>2023-07-19T20:50:01+03:30</updated><id>http://localhost:4000/blog/embeded/smart-card/2023/07/19/smart-card-intro</id><content type="html" xml:base="http://localhost:4000/blog/embeded/smart-card/2023/07/19/smart-card-intro.html"><![CDATA[<h1 id="0-introduction">0. Introduction</h1>

<p>Smart cards are small, pocket-sized cards that contain an embedded microprocessor and memory chip. These cards are often made of plastic, and they look similar to traditional credit or debit cards, but they possess advanced technology that sets them apart. Smart cards are designed to securely store and process data, making them a powerful tool for various applications in today’s digital world.</p>

<p>There are two main types of smart cards:</p>

<ul>
  <li>
    <p><strong>Contact Smart Cards</strong>: These cards have gold-plated contact pads on their surface, which need to physically touch a card reader to establish communication. When inserted into a card reader or terminal, the contacts establish an electrical connection, enabling data transfer between the card and the reader. The data exchange can involve tasks such as authentication, data storage, and cryptographic operations.</p>
  </li>
  <li>
    <p><strong>Contactless Smart Cards</strong>: In contrast to contact smart cards, contactless smart cards do not require physical contact with a card reader. Instead, they use radio frequency identification (RFID) technology to communicate wirelessly with compatible card readers or terminals. This communication occurs when the card is placed within close proximity to the reader, making contactless smart cards particularly convenient and efficient for quick transactions.</p>
  </li>
</ul>

<p>Smart cards find applications in a wide range of industries and use cases, including:</p>

<ul>
  <li><strong>Financial Transactions</strong>: They are commonly used for secure payments in credit/debit cards, prepaid cards, and electronic wallets.</li>
  <li><strong>Access Control and Security</strong>: Smart cards are used for secure building access, network authentication, and data protection.</li>
  <li><strong>Healthcare</strong>: They facilitate secure access to electronic health records, patient identification, and prescription management.</li>
  <li><strong>Transportation</strong>: Smart cards are utilized in fare collection systems for public transport, allowing for seamless ticketing and fare management.</li>
  <li><strong>Government Identification</strong>: National ID cards, driver’s licenses, and electronic passports often incorporate smart card technology for enhanced security features.</li>
</ul>

<p>The ability of smart cards to securely store sensitive data, perform cryptographic operations, and communicate with various systems has made them an indispensable component of modern technology, ensuring safer and more efficient transactions and interactions in numerous domains.</p>

<p>Smart cards are equipped with a microprocessor and a specialized operating system, which sets them apart from traditional magnetic stripe cards. The presence of these components enables smart cards to perform more sophisticated functions and offer enhanced security features.</p>

<ol>
  <li>
    <p><strong>Microprocessor</strong>:
The microprocessor is the brain of the smart card, responsible for executing commands and processing data. It is a small integrated circuit that can perform complex calculations and cryptographic operations. The microprocessor allows the card to interact intelligently with card readers or terminals, enabling secure data exchange and executing specific tasks according to the applications it supports.</p>
  </li>
  <li>
    <p><strong>Operating System</strong>:
The operating system (OS) of a smart card is a specialized software that manages the card’s functions, controls access to its resources, and provides a standardized interface for applications to interact with the card’s hardware and data. The operating system facilitates communication with the outside world, ensuring that commands and data sent to the card are processed correctly and securely.</p>
  </li>
</ol>

<p>The presence of a microprocessor and an operating system on smart cards allows for several important capabilities:</p>

<ol>
  <li>
    <p><strong>Security Features</strong>:
Smart cards use their microprocessors to perform encryption and decryption operations, making them highly secure for sensitive transactions and data storage. The operating system plays a crucial role in managing cryptographic keys and ensuring secure access to the card’s data.</p>
  </li>
  <li>
    <p><strong>Secure Application Execution</strong>:
The operating system provides a secure environment for applications running on the smart card. It isolates different applications from one another, preventing unauthorized access and ensuring that one application’s activities cannot compromise the security of others on the same card.</p>
  </li>
  <li>
    <p><strong>Multiple Applications</strong>:
Smart cards have the ability to support multiple applications simultaneously. For example, a single smart card can be used for electronic payments, access control, and healthcare records. The operating system facilitates seamless execution and switching between these applications.</p>
  </li>
  <li>
    <p><strong>Dynamic Updates</strong>:
The operating system can be updated or patched to address security vulnerabilities or add new features to the smart card without replacing the physical card itself.</p>
  </li>
</ol>

<p>Due to these advanced features, smart cards have become a reliable and secure tool for various applications, such as financial transactions, secure access control, healthcare, and more. The combination of a microprocessor and an operating system empowers smart cards to deliver enhanced functionality, robust security, and unparalleled convenience in the digital age.</p>

<p>In the context of smart cards, an applet refers to a small, specialized software application that runs on the smart card’s microprocessor and is managed by the card’s operating system. These applets are designed to perform specific functions or provide particular services on the smart card. They enable the smart card to support various applications and perform tasks relevant to the cardholder’s needs.</p>

<h1 id="1-applets">1. Applets</h1>

<p>Applets on smart cards are comparable to apps on a smartphone. Each applet functions as a self-contained program with a defined set of functionalities, and multiple applets can coexist on the same smart card without interfering with each other. This modularity and isolation of applets are essential for maintaining security and ensuring that sensitive data from one application remains isolated from others.</p>

<p>The key characteristics of applets on smart cards include:</p>

<ol>
  <li>
    <p><strong>Security</strong>:
Applets are designed with security in mind, ensuring that the data and operations they perform remain protected from unauthorized access. The smart card’s operating system enforces strict access controls to prevent unauthorized applets from interfering with sensitive data or executing malicious operations.</p>
  </li>
  <li>
    <p><strong>Isolation</strong>:
Each applet runs within its own secure execution environment, isolated from other applets on the smart card. This isolation prevents one applet from accessing data or resources belonging to another, ensuring a high level of data privacy and integrity.</p>
  </li>
  <li>
    <p><strong>Flexibility</strong>:
Applets can be added, removed, or updated on the smart card without replacing the physical card itself. This flexibility allows card issuers to introduce new services or applications to the card without disrupting existing functionalities.</p>
  </li>
  <li>
    <p><strong>Common Criteria Compliance</strong>:
Applets are typically developed following the Common Criteria standard, which defines security requirements for evaluating and certifying the security of IT products, including smart cards.</p>
  </li>
</ol>

<p>Examples of applets on smart cards include:</p>

<ul>
  <li><strong>Payment Applet</strong>: Enables secure financial transactions and management of funds on the smart card, allowing it to be used as a debit or credit card.</li>
  <li><strong>Identity Applet</strong>: Stores and manages personal identification information for government-issued identification cards or electronic passports.</li>
  <li><strong>Health Applet</strong>: Manages electronic health records and provides secure access to patient information for healthcare applications.</li>
  <li><strong>Access Control Applet</strong>: Facilitates secure access to buildings, computer systems, or networks by providing authentication and authorization services.</li>
</ul>

<p>Overall, applets on smart cards play a crucial role in extending the card’s capabilities, enhancing security, and enabling multiple applications to coexist on a single card while maintaining data privacy and integrity.</p>

<h1 id="2-developing-applets">2. Developing Applets</h1>

<p>Writing applets for smart cards requires specialized skills and knowledge of smart card technology, microcontroller programming, and the specific programming language supported by the smart card’s microprocessor. Most smart cards use the Java Card platform, which allows developers to write applets in Java Card language.</p>

<p>Here are the general steps to write applets for smart cards:</p>

<ol>
  <li>
    <p><strong>Set Up Development Environment</strong>:
First, you need to set up the development environment for smart card applet development. This involves installing the necessary software development kit (SDK) provided by the smart card manufacturer or Java Card platform.</p>
  </li>
  <li>
    <p><strong>Learn Java Card Programming</strong>:
Familiarize yourself with Java Card programming, which is a subset of the Java programming language tailored for smart card development. Understand the limitations and specific features of Java Card, as it differs from regular Java programming.</p>
  </li>
  <li>
    <p><strong>Define Applet Functionality</strong>:
Determine the functionality you want your applet to provide. Identify the specific tasks the applet should perform on the smart card, such as handling financial transactions, managing access control, or storing and retrieving sensitive data.</p>
  </li>
  <li>
    <p><strong>Develop the Applet Code</strong>:
Write the applet code in Java Card language. This code will define the behavior and operations of the applet on the smart card. Ensure that the applet code adheres to the security requirements and best practices for smart card development.</p>
  </li>
  <li>
    <p><strong>Compile and Convert to CAP File</strong>:
After writing the applet code, compile it using the Java Card compiler to produce a .cap file (CAP stands for “Converted Applet”). This file contains the binary representation of the applet code, ready for installation on the smart card.</p>
  </li>
  <li>
    <p><strong>Load the Applet onto the Smart Card</strong>:
Use the appropriate tools or APIs provided by the smart card manufacturer or Java Card platform to load the .cap file onto the smart card. This process is known as “applet installation.”</p>
  </li>
  <li>
    <p><strong>Test and Debug</strong>:
Test the applet on the smart card to ensure that it functions as expected. Debug any issues that may arise during testing, making necessary adjustments to the applet code if needed.</p>
  </li>
  <li>
    <p><strong>Deploy and Distribute</strong>:
Once the applet is thoroughly tested and verified, it can be deployed on the desired smart cards or distributed to end-users through card issuers or service providers.</p>
  </li>
</ol>

<p>Please note that writing applets for smart cards requires expertise in smart card development and may vary depending on the specific smart card’s capabilities and the programming language supported by its microprocessor. It’s essential to refer to the smart card manufacturer’s documentation and Java Card specifications for detailed guidelines and best practices when developing applets for smart cards.</p>

<p>Next time i prepare an article about developing an applet and playing around with this old technology, stay tuned…</p>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="embeded" /><category term="smart-card" /><summary type="html"><![CDATA[0. Introduction]]></summary></entry><entry><title type="html">PyTorch Tutorial, Part 1: Installation and The basics</title><link href="http://localhost:4000/project/ai/machine-learning/deep-learning/python/2023/03/27/pytorch-tutorial-1.html" rel="alternate" type="text/html" title="PyTorch Tutorial, Part 1: Installation and The basics" /><published>2023-03-27T17:15:23+03:30</published><updated>2023-03-27T17:15:23+03:30</updated><id>http://localhost:4000/project/ai/machine-learning/deep-learning/python/2023/03/27/pytorch-tutorial-1</id><content type="html" xml:base="http://localhost:4000/project/ai/machine-learning/deep-learning/python/2023/03/27/pytorch-tutorial-1.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>

<p>PyTorch is a fully featured framework for building deep learning models, which is a type of machine learning that’s commonly used in applications like image recognition and language processing. Written in Python, it’s relatively easy for most machine learning developers to learn and use. PyTorch is distinctive for its excellent support for GPUs and its use of reverse-mode auto-differentiation, which enables computation graphs to be modified on the fly. This makes it a popular choice for fast experimentation and prototyping.</p>

<p align="center">
    <img class="img-light-bg" width="60%" src="/assets/images/posts/projects/pytorch-tutorial/logo.png" />
</p>

<p>PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella. It is free and open-source software released under the modified BSD license.</p>

<p>PyTorch is the work of developers at Facebook AI Research and several other labs. The framework combines the efficient and flexible GPU-accelerated backend libraries from Torch with an intuitive Python frontend that focuses on rapid prototyping, readable code, and support for the widest possible variety of deep learning models. Pytorch lets developers use the familiar imperative programming approach, but still output to graphs.  It was released to open source in 2017, and its Python roots have made it a favorite with machine learning developers.</p>

<p>Significantly, PyTorch adopted a Chainer innovation called reverse-mode automatic differentiation. Essentially, it’s like a tape recorder that records completed operations and then replays backward to compute gradients. This makes PyTorch relatively simple to debug and well-adapted to certain applications such as dynamic neural networks. It’s popular for prototyping because every iteration can be different.</p>

<p>PyTorch is especially popular with Python developers because it’s written in Python and uses that language’s imperative, define-by-run eager execution mode in which operations are executed as they are called from Python. As the popularity of the Python programming language persists, a survey identified a growing focus on AI and machine learning tasks and, with them, greater adoption of related PyTorch. This makes PyTorch a good choice for Python developers who are new to deep learning, and a growing library of deep learning courses are based on PyTorch. The API has remained consistent from early releases, meaning that the code is relatively easy for experienced Python developers to understand.</p>

<p>PyTorch’s particular strength is in rapid prototyping and smaller projects. Its ease of use and flexibility also makes it a favorite for academic and research communities.</p>

<p>Facebook developers have been working hard to improve PyTorch’s productive applications. Recent releases have provided enhancements like support for Google’s TensorBoard visualization tool, and just-in-time compilation. It has also expanded support for ONNX (Open Neural Network Exchange), which enables developers to match with deep learning frameworks or runtimes that work best for their applications.</p>

<h1 id="2-installing-pytorch">2. Installing PyTorch</h1>

<p>You can follow this tutorial using some online platforms such as <a href="https://colab.research.google.com">Google Colab</a> or <a href="https://kaggle.com">Kaggle</a> which give you a python environment via a jupyter note book and a proper GPU to meet your needs during learning process and even doing small projects and homeworks. If you prefer using these platforms you can skip this section but if you want to use pytorch on your local machine and use your own GPU, here are the installation steps you should follow.</p>

<h2 id="21-installing-pytorch">2.1 Installing PyTorch</h2>

<p>You can follow the steps on PyTorch official website <a href="https://pytorch.org/get-started/locally/">pytorch.org</a> to install it locally or stay with me.</p>

<p>If you haven’t installed Anaconda on your machine download and install anaconda then create a conda environment:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>conda create <span class="nt">--name</span> torch <span class="nv">python</span><span class="o">=</span>3.9
</code></pre></div></div>

<p>After creating the environment activate it using:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>conda activate torch
</code></pre></div></div>

<p>Then use pip to install PyTorch:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>pip <span class="nb">install </span>torch torchvision torchaudio
</code></pre></div></div>

<p>It will take some time but will install pytorch and all gpu requirements on your machine.</p>

<p>to test that if gpu is supported, open a python file and run the code below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"Is GPU supported? </span><span class="si">{</span><span class="s">'Yes'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'No'</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-output">Is GPU supported? Yes
</code></pre>

<p>Well done, you have installed PyTorch on your computer and ready to go through this tutorial.</p>

<h1 id="3-tensor-basics">3. Tensor basics</h1>
<p>The very basic class in PyTorch library is the tensor class. almost Every variable and operation in PyTorch is represented by a tensor. You can look at the tensor as just like a numpy array or a multi-dimensional python list.
Because of the mathematical nature of Machine Learning operations which are performed on linear-algebra, we need such a class to implement and use the calculations in python.</p>

<p>Tensor can be used in CPU or GPU. Using GPU makes the calculations so much faster. To move the tensor to GPU, you have to use  <code class="language-plaintext highlighter-rouge">tensor.to('cuda')</code> or <code class="language-plaintext highlighter-rouge">tensor.to(device)</code> function.</p>

<p>Creating tensors:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Createing a tensor
</span><span class="n">sample_tensor</span>   <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">random_tensor</span>   <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">zero_tensor</span>     <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">one_tensor</span>      <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

</code></pre></div></div>

<p>Moving tensors to GPU:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">getDevice</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span>

<span class="n">sample_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="c1"># Send tensor to GPU
</span><span class="n">sample_tensor</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>You can reshape the tensors using the <code class="language-plaintext highlighter-rouge">view</code> function. This function as very similar to the <code class="language-plaintext highlighter-rouge">reshape</code> function in numpy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>   <span class="mi">3</span><span class="p">,</span>   <span class="mi">4</span> <span class="p">],</span> 
                              <span class="p">[</span><span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>   <span class="mi">7</span><span class="p">,</span>   <span class="mi">8</span> <span class="p">],</span> 
                              <span class="p">[</span><span class="mi">9</span><span class="p">,</span>  <span class="mi">10</span><span class="p">,</span>  <span class="mi">11</span><span class="p">,</span>  <span class="mi">12</span><span class="p">],</span> 
                              <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span>  <span class="mi">15</span><span class="p">,</span>  <span class="mi">16</span><span class="p">]])</span>

<span class="c1"># turn into 1 D tensor ([1, 2, 3, ..., 16])
</span><span class="n">one_dimension_tensor</span> <span class="o">=</span> <span class="n">sample_tensor</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<h2 id="31-operations-and-gradient-calculation">3.1 Operations and gradient calculation</h2>
<p>In PyTorch every calculation is represented by a computation graph. For example, if we say \(y = x + 2\) this will build a graph as below:</p>

<p align="center">
<img class="img-light-bg" src="/assets/images/posts/projects/pytorch-tutorial/graph.png" width="30%" />
<br />
<span>Figure-1: Computational graph for Y = X + 2</span>
</p>

<p>This is due to the ace of the gradient calculation. The gradients are required for optimization of the model weights. This computation graphs used for computing the gradients based on the chain rule and Jacobian matrix method. The gradient calculation can be automatically done using the <code class="language-plaintext highlighter-rouge">backward</code> function. If you want to compute the gradient of a tensor, you have to set the <code class="language-plaintext highlighter-rouge">require_gradients</code> parameter to true while defining the tensor.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">require_gradients</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>

<span class="n">y</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"dy/dx: </span><span class="si">{</span><span class="n">y</span><span class="p">.</span><span class="n">grad</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="4-linear-regression">4. Linear regression</h1>
<p>Learning by doing a real project is a perfect way to gain some kinds of skills specially programming. To understand the basics of using the framework, it’s recommended to implement a simple mini project step by step from scratch. We choose linear regression as the training example and will go through the implementations from scratch and with out using pytorch. Then we will convert the code into using PyTorch and advanced functions.</p>

<h2 id="41-problem-statement">4.1 Problem statement</h2>

<p>Simple linear regression is used to estimate the relationship between two quantitative variables. You can use simple linear regression when you want to know:</p>

<ol>
  <li>How strong the relationship is between two variables (e.g., the relationship between rainfall and soil erosion).</li>
  <li>The value of the dependent variable at a certain value of the independent variable (e.g., the amount of soil erosion at a certain level of rainfall).</li>
</ol>

<p>Regression models describe the relationship between variables by fitting a line to the observed data. Linear regression models use a straight line, while logistic and nonlinear regression models use a curved line. Regression allows you to estimate how a dependent variable changes as the independent variable(s) change.</p>

<p>The formula for a simple linear regression is:</p>

\[y = \beta_{0} + \beta_{1} . X + \epsilon\]

<ul>
  <li><strong>\(y\)</strong> is the predicted value of the dependent variable (\(y\)) for any given value of the independent variable (\(x\)).</li>
  <li><strong>\(\beta_0\)</strong> is the intercept, the predicted value of \(y\) when the \(x\) is \(0\).</li>
  <li><strong>\(\beta_1\)</strong> is the regression coefficient – how much we expect \(y\) to change as \(x\) increases.</li>
  <li><strong>\(x\)</strong> is the independent variable ( the variable we expect is influencing \(y\)).</li>
  <li><strong>\(\epsilon\)</strong> is the error of the estimate, or how much variation there is in our estimate of the regression coefficient.</li>
</ul>

<p>Linear regression finds the line of best fit line through your data by searching for the regression coefficient (B1) that minimizes the total error (e) of the model.</p>

<p>The loss function or error function in linear regression is determined by <strong>M</strong>ean <strong>S</strong>quared <strong>E</strong>rror or MSE.</p>

\[L = \frac{1}{N} \sum_{i=1}^{N} (\hat{Y}_{i} - Y_{i})^2\]

<p>To minimize the error, we have to update the regression coefficients by computing the gradient with respect to the dependent variables (Model weights). And update the regression coefficients as below:</p>

\[w = w - \alpha.\frac{dJ}{dw}\]

<p>Which:</p>

\[\frac{dJ}{dw} = \frac{1}{N} . 2x . (\hat{y}-y)\]

<p>For this example we define a simple training set which is a set of 2D points \((x,y)\) such that \(y = 2 \times x\).</p>

<table>
  <thead>
    <tr>
      <th>x</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>2</td>
      <td>4</td>
    </tr>
    <tr>
      <td>3</td>
      <td>6</td>
    </tr>
    <tr>
      <td>4</td>
      <td>8</td>
    </tr>
    <tr>
      <td>5</td>
      <td>10</td>
    </tr>
    <tr>
      <td>6</td>
      <td>12</td>
    </tr>
  </tbody>
</table>

<p>We pick \(x=6\) as the test point and the rest as training data. Here is the implementation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Training Data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Test Data
</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">12</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div>

<p>The network will have a single node that has a single parameter $w$ which is randomly evaluated.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Weights: A single node (no bias is considered)
</span><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">()</span>
</code></pre></div></div>

<p>In PyTorch the forward pass in calculating the layer output is done by calling the forward function which, represents the forward pass of the network. In conclusion, we will call the model output function, the forward function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Forward pass:
# Predict the output of the network on the input data.
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">weights</span>
</code></pre></div></div>

<p>Then we have to define the loss function of the network which is the MSE loss function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model loss function:
# MSE = 1/N * sum((y_i - y_hat_i)^2)
</span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y_pred</span><span class="p">))</span>

<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">'prediction before training f(</span><span class="si">{</span><span class="n">x_test</span><span class="si">}</span><span class="s">): </span><span class="si">{</span><span class="n">forward</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>    
</code></pre></div></div>
<p>Finally, we will need a function to calculate the gradient of the network coefficients, which in pytorch is called the backward function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculating gradients: 
# dJ/dw = 1/N * 2x *(w*x-y) // w*x = y_pred
</span><span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)).</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<p>Finally, here is the training loop:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="c1"># Alpha
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># Forward pass: Compute predicted y by passing x to the model
</span>    <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

    <span class="c1"># Compute and print loss
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>

    <span class="c1"># Backward pass: Compute gradient of the loss with respect to model parameters
</span>    <span class="n">dw</span> <span class="o">=</span> <span class="n">backward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>

    <span class="c1"># Update parameters
</span>    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">, weights=</span><span class="si">{</span><span class="p">[</span><span class="n">w</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"Model prediction for x=6 is: </span><span class="si">{</span><span class="n">forward</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">)

</span></code></pre></div></div>

<pre><code class="language-output">Epoch: 0 loss=24.130, weights=[2.14810945503594]
Epoch: 10 loss=0.000, weights=[2.0000000976789147]
Epoch: 20 loss=0.000, weights=[2.0000000976789147]
Epoch: 30 loss=0.000, weights=[2.0000000976789147]
Epoch: 40 loss=0.000, weights=[2.0000000976789147]
Epoch: 50 loss=0.000, weights=[2.0000000976789147]
Epoch: 60 loss=0.000, weights=[2.0000000976789147]
Epoch: 70 loss=0.000, weights=[2.0000000976789147]
Epoch: 80 loss=0.000, weights=[2.0000000976789147]
Epoch: 90 loss=0.000, weights=[2.0000000976789147]
Model prediction for x=6 is: [12.]
</code></pre>
<p>As you can see, the model converged after 100 iterations and successfully predicted the expected value for \(x=6\) which is \(y=12\).</p>

<h2 id="42-including-pytorch">4.2 Including PyTorch</h2>

<p>We implemented a simple linear regression model from scratch and only using numpy. Now it’s time to include PyTorch in our code. First, we have to turn every variable (\(x\), \(y\) and \(w\)) into a tensor instead of numpy arrays.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Training Data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Test Data
</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">12</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Weights: A single nuron
</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div></div>

<p>In the above code, while defining the weight parameter, we said that it requires tracking the gradient calculation for this tensor by setting the <code class="language-plaintext highlighter-rouge">require_grad</code> parameter to <code class="language-plaintext highlighter-rouge">True</code>. If we don’t set this parameter to <code class="language-plaintext highlighter-rouge">True</code>, while calling the backward function, it will throw an exception because it doesn’t store the gradients in the computation graph. So, be careful when defining a tensor which is required to calculate the gradients.</p>

<p>Next, we have to define the forward and loss function for the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Forward pass:
# Predict the output of the network on the input data.
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">weights</span>

<span class="c1"># Model loss function:
# MSE = 1/N * sum((y_i - y_hat_i)^2)
</span><span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<p>As we said in the previous section, gradients can be calculated by calling the backward function. For this reason, there is no need to define the backward function. While calling the backward function, the calculated gradients will remain in the computation graph until you free its memory. and this could be done by calling <code class="language-plaintext highlighter-rouge">tensor.grad.zero_()</code> function. So, be careful while calling the backward function and make sure that you free the memory associated with the gradients (you can see this in the code below).</p>

<p>Here is the training loop:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">w</span><span class="p">.</span><span class="n">grad</span>
    <span class="c1"># You have to zero the gradients before calling the backward function in the next step
</span>    <span class="n">w</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="n">zero_</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> loss=</span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">, weights=</span><span class="si">{</span><span class="n">w</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"Model prediction for x=6 is: </span><span class="si">{</span><span class="n">forward</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">)
</span></code></pre></div></div>
<pre><code class="language-output">Epoch: 0 loss=49.172, weights=tensor([0.9472], requires_grad=True)
Epoch: 10 loss=0.139, weights=tensor([1.9122], requires_grad=True)
Epoch: 20 loss=0.001, weights=tensor([1.9927], requires_grad=True)
Epoch: 30 loss=0.000, weights=tensor([1.9994], requires_grad=True)
Epoch: 40 loss=0.000, weights=tensor([1.9999], requires_grad=True)
Epoch: 50 loss=0.000, weights=tensor([2.0000], requires_grad=True)
Epoch: 60 loss=0.000, weights=tensor([2.0000], requires_grad=True)
Epoch: 70 loss=0.000, weights=tensor([2.0000], requires_grad=True)
Epoch: 80 loss=0.000, weights=tensor([2.0000], requires_grad=True)
Epoch: 90 loss=0.000, weights=tensor([2.0000], requires_grad=True)
Model prediction for x=6 is: tensor([12.0000], grad_fn=&lt;MulBackward0&gt;)
</code></pre>

<h2 id="43-more-including-pytorch">4.3 More including PyTorch</h2>
<p>Now, let’s use the built-in PyTorch optimizer and loss function as well as the built-in forward function. First change that we should make is to remove the loss function that we where using and use the built-in MSELoss instead. Then, instead of manually updating the model parameters, we can use the built-in optimizers such as <strong>S</strong>tochastic <strong>G</strong>radient <strong>D</strong>escent (SGD), Adam or etc.</p>

<p>As we know, this model is a single linear nuron which can be represented by <code class="language-plaintext highlighter-rouge">torch.nn.linear(input_size, output_size)</code>. This layer has its own parameters which means it’s not required to define the weights parameter \(w\) any more.</p>

<p>While using optimizers, calling <code class="language-plaintext highlighter-rouge">optimizer.step()</code> will automatically update the model parameters and <code class="language-plaintext highlighter-rouge">optimizer.zero_grad()</code> will automatically free the gradients memory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Training Data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">],[</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">],[</span><span class="mi">6</span><span class="p">],[</span><span class="mi">8</span><span class="p">],[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Test Data
</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">12</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="n">n_features</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="n">n_features</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">'prediction before training f(</span><span class="si">{</span><span class="n">x_test</span><span class="si">}</span><span class="s">): </span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>    

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">2000</span>

<span class="c1"># using built-in SGD optimizer
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="c1"># using built-in MSE loss function
</span><span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">l</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> loss=</span><span class="si">{</span><span class="n">l</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="mf">0.5</span><span class="n">f</span><span class="si">}</span><span class="s">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="mf">0.5</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> 
</code></pre></div></div>
<pre><code class="language-output">prediction before training f(tensor([6.])): 0.314
Epoch: 0 loss=45.60832, weights=0.29675
Epoch: 500 loss=0.00051, weights=0.29675
Epoch: 1000 loss=0.00002, weights=0.29675
Epoch: 1500 loss=0.00000, weights=0.29675
12.000
</code></pre>

<h2 id="44-turning-model-into-a-torch-module">4.4 Turning model into a Torch module</h2>

<p>We can define blocks of layers as modules in PyTorch which are called <strong>modules</strong>. To do so, we have to define a class which inherits from the base <code class="language-plaintext highlighter-rouge">torch.nn.Module</code> class and implement the forward function for that module.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we can instantiate and use this model instead of defining a single fully connected layer as our model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">mport</span> <span class="n">torch</span>

<span class="c1"># Training Data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">],[</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">],[</span><span class="mi">6</span><span class="p">],[</span><span class="mi">8</span><span class="p">],[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># Test Data
</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">12</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="n">n_features</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="n">n_features</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">'prediction before training f(</span><span class="si">{</span><span class="n">x_test</span><span class="si">}</span><span class="s">): </span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>    

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">2000</span>

<span class="c1"># using built-in SGD optimizer
</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="c1"># using built-in MSE loss function
</span><span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">l</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> loss=</span><span class="si">{</span><span class="n">l</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="mf">0.5</span><span class="n">f</span><span class="si">}</span><span class="s">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="mf">0.5</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="45-more-realistic-example">4.5 More realistic example</h1>
<p>Now lets use a more realistic data and plot the results with matplotlib.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)),</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">ll_1</span><span class="p">.</span><span class="n">parameters</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">Y</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="s">'ro'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">prediction</span><span class="p">,</span> <span class="s">'b'</span><span class="p">)</span>

</code></pre></div></div>

<p align="center">
    <img src="/assets/images/posts/projects/pytorch-tutorial/plot.png" />
    <br />
    <span>Figure-2: Regression results</span>
</p>

<h1 id="5-logistic-regression">5. Logistic regression</h1>

<p>Here is a classification example using the breast cancer dataset from scikit-learn library. To recap, the problem statement is, we want to classify patients into two classes, having and not having the breast cancer using a single nuron as the previous examples.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">target</span>

<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">StandardScaler</span><span class="p">()</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">y_pred</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Prevent tracking gradients during the below calculation
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="nb">round</span><span class="p">()</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_test</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">03</span><span class="n">f</span><span class="si">}</span><span class="s">, accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">03</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>    
</code></pre></div></div>

<p>As you can see, in the code, when we want to compute the accuracy of the model, we dont need to to keep track of calculated gradients of the calculation. To prevent this to affect our training and calculations, we have to turn this tracking off. This can be done by calling <code class="language-plaintext highlighter-rouge">torch.no_grad()</code> in a <code class="language-plaintext highlighter-rouge">with</code> block or making a detached copy of the variables directly by calling the <code class="language-plaintext highlighter-rouge">tensor.detach()</code> function of that tensor which returns a detached copy of that tensor and work with the returned value instead of the main tensor.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">a_copy</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span>
<span class="c1"># now use a_copy to compute the accuracy...
</span></code></pre></div></div>

<pre><code class="language-output">epoch: 0, loss: 0.892, accuracy: 0.281
epoch: 10, loss: 0.650, accuracy: 0.667
epoch: 20, loss: 0.515, accuracy: 0.860
epoch: 30, loss: 0.433, accuracy: 0.939
epoch: 40, loss: 0.380, accuracy: 0.947
epoch: 50, loss: 0.342, accuracy: 0.965
epoch: 60, loss: 0.315, accuracy: 0.965
epoch: 70, loss: 0.293, accuracy: 0.965
epoch: 80, loss: 0.276, accuracy: 0.965
epoch: 90, loss: 0.262, accuracy: 0.965
</code></pre>
<h1 id="6-conclusion">6. Conclusion</h1>
<p>In this section we learned what is PyTorch, Tensors and the computation graph definition. Then, we implemented a simple linear regression from scratch using numpy which helped us to better understanding the problem and how to solve the problem by implementation. After that, we turned the calculations from numpy into PyTorch tensors. Finally, we completed the implementation using built-in PyTorch optimizers and loss functions and some examples.</p>]]></content><author><name>Ali N. Parizi</name></author><category term="project" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><category term="python" /><summary type="html"><![CDATA[1. Intro]]></summary></entry><entry><title type="html">PyTorch Tutorial, Part 2: Datasets and Dataloaders</title><link href="http://localhost:4000/project/ai/machine-learning/deep-learning/python/2023/03/27/pytorch-tutorial-2.html" rel="alternate" type="text/html" title="PyTorch Tutorial, Part 2: Datasets and Dataloaders" /><published>2023-03-27T17:15:23+03:30</published><updated>2023-03-27T17:15:23+03:30</updated><id>http://localhost:4000/project/ai/machine-learning/deep-learning/python/2023/03/27/pytorch-tutorial-2</id><content type="html" xml:base="http://localhost:4000/project/ai/machine-learning/deep-learning/python/2023/03/27/pytorch-tutorial-2.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>

<p>Almost every machine learning algorithm and model works with Data. Creating a Dataset and managing it with Dataloader keeps your data manageable and helps to simplify your machine learning pipeline. a Dataset stores all your data, and Dataloader is can be used to iterate through the data, manage batches, transform the data, and much more. Let’s begin with a simple example. Assuming the popular Wine dataset as our target dataset, we want to load and use this dataset in pytorch. Before getting started, we have to download the dataset from <a href="https://archive.ics.uci.edu/ml/datasets/wine">UCA machine-learning repository</a>. I usually place my data insied a data directory so the address to this dataset will be <code class="language-plaintext highlighter-rouge">../data/win/wine.data</code>.</p>

<p>In pytorch we have a Dataset class which each dataset should inherit from this base class. For datasets we have to implement at least to methods which are <code class="language-plaintext highlighter-rouge">__getitem__</code> and<code class="language-plaintext highlighter-rouge">__len__</code> which return the iten with the given index from the dataset and the length of the dataset respectively.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">PATH_TO_DATASET</span> <span class="o">=</span> <span class="s">'../data/wine/wine.data'</span>

<span class="k">class</span> <span class="nc">WineDataset</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="c1"># default constructor
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">raw_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">PATH_TO_DATASET</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">raw_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">raw_data</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># returns item index of dataset (x, y)
</span>    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    
    <span class="c1"># returns the length of dataset
</span>    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we are able to use this dataset as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">WineDataset</span><span class="p">()</span>
<span class="n">x_sample</span><span class="p">,</span> <span class="n">y_sample</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"x:</span><span class="si">{</span> <span class="n">x_sample</span><span class="si">}</span><span class="s">, y: </span><span class="si">{</span><span class="n">y_sample</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-txt">x:tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,
        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,
        1.0650e+03]), y: tensor([1.])
</code></pre>

<p>Thats it, it lookes easy, doesn’t it?</p>

<h1 id="2-dataloader">2. Dataloader</h1>
<p>To manage the dataset we can use pytorch dataloader to prepare the dataset for the training process. For example it’s responsible for creating batches and shuffling them in in training process.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataiter</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
<span class="k">print</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-txt">Output exceeds the size limit. Open the full output data in a text editor
tensor([[1.3740e+01, 1.6700e+00, 2.2500e+00, 1.6400e+01, 1.1800e+02, 2.6000e+00,
         2.9000e+00, 2.1000e-01, 1.6200e+00, 5.8500e+00, 9.2000e-01, 3.2000e+00,
         1.0600e+03],
        [1.1660e+01, 1.8800e+00, 1.9200e+00, 1.6000e+01, 9.7000e+01, 1.6100e+00,
         1.5700e+00, 3.4000e-01, 1.1500e+00, 3.8000e+00, 1.2300e+00, 2.1400e+00,
         4.2800e+02],
        [1.4340e+01, 1.6800e+00, 2.7000e+00, 2.5000e+01, 9.8000e+01, 2.8000e+00,
         1.3100e+00, 5.3000e-01, 2.7000e+00, 1.3000e+01, 5.7000e-01, 1.9600e+00,
         6.6000e+02],
        [1.1610e+01, 1.3500e+00, 2.7000e+00, 2.0000e+01, 9.4000e+01, 2.7400e+00,
         2.9200e+00, 2.9000e-01, 2.4900e+00, 2.6500e+00, 9.6000e-01, 3.2600e+00,
         6.8000e+02],
        [1.4130e+01, 4.1000e+00, 2.7400e+00, 2.4500e+01, 9.6000e+01, 2.0500e+00,
         7.6000e-01, 5.6000e-01, 1.3500e+00, 9.2000e+00, 6.1000e-01, 1.6000e+00,
         5.6000e+02],
        [1.3050e+01, 5.8000e+00, 2.1300e+00, 2.1500e+01, 8.6000e+01, 2.6200e+00,
         2.6500e+00, 3.0000e-01, 2.0100e+00, 2.6000e+00, 7.3000e-01, 3.1000e+00,
         3.8000e+02],
        [1.3510e+01, 1.8000e+00, 2.6500e+00, 1.9000e+01, 1.1000e+02, 2.3500e+00,
         2.5300e+00, 2.9000e-01, 1.5400e+00, 4.2000e+00, 1.1000e+00, 2.8700e+00,
         1.0950e+03],
        [1.2600e+01, 2.4600e+00, 2.2000e+00, 1.8500e+01, 9.4000e+01, 1.6200e+00,
         6.6000e-01, 6.3000e-01, 9.4000e-01, 7.1000e+00, 7.3000e-01, 1.5800e+00,
         6.9500e+02],
        [1.3500e+01, 1.8100e+00, 2.6100e+00, 2.0000e+01, 9.6000e+01, 2.5300e+00,
...
        [2.],
        [1.],
        [2.],
        [1.]])
</code></pre>

<h1 id="3-transformers">3. Transformers</h1>

<p>Some times we need to make some changes on the raw data before using them. For example, in data augmentation technique, we make some changes to the original data before using them in training epochs. This will make our model more robust and more prone to overfitting. We can modify our dataset class to be able to use some transformer functions by defining an optional input in the constructor function (<code class="language-plaintext highlighter-rouge">__init__</code>). Then when ever we want to read a data from the dataset, the transformer functions will automatically execute on the data before returning the results. This will be so useful during our implementation. We will see more examples in the next parts of these series.</p>

<p>Here is the modified dataset class:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">WineDataset</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="p">[])</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">raw_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s">'../data/wine/wine.data'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">raw_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">raw_data</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
    
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">transform</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="k">print</span> <span class="p">(</span><span class="n">sample</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sample</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<p>We can define a transformer as a callable class. Here are some examples:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ToTensorTransformer</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sample</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MultiplierTransformer</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">factor</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
        
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sample</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">factor</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</code></pre></div></div>

<p>To use these transformers we can easily pass them through the constructor while creating the dataset object, Then they will be applied to the data on after another in the order of their placement in the array.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">WineDataset</span><span class="p">(</span><span class="n">transforms</span><span class="o">=</span><span class="p">[</span><span class="n">ToTensorTransformer</span><span class="p">(),</span> <span class="n">MultiplierTransformer</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">x_sample</span><span class="p">,</span> <span class="n">y_sample</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span> <span class="p">(</span><span class="sa">f</span><span class="s">"x:</span><span class="si">{</span> <span class="n">x_sample</span><span class="si">}</span><span class="s">, y: </span><span class="si">{</span><span class="n">y_sample</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-txt">(tensor([1.4230e+02, 1.7100e+01, 2.4300e+01, 1.5600e+02, 1.2700e+03, 2.8000e+01,
        3.0600e+01, 2.8000e+00, 2.2900e+01, 5.6400e+01, 1.0400e+01, 3.9200e+01,
        1.0650e+04]), tensor([1.]))
x:tensor([1.4230e+02, 1.7100e+01, 2.4300e+01, 1.5600e+02, 1.2700e+03, 2.8000e+01,
        3.0600e+01, 2.8000e+00, 2.2900e+01, 5.6400e+01, 1.0400e+01, 3.9200e+01,
        1.0650e+04]), y: tensor([1.])
</code></pre>]]></content><author><name>Ali N. Parizi</name></author><category term="project" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><category term="python" /><summary type="html"><![CDATA[1. Intro]]></summary></entry><entry><title type="html">The Subtle Art of Not Giving a Fuck</title><link href="http://localhost:4000/book/self-help/focus/study-lessens/2023/03/22/the-art-of-dont-giving-a-fuck.html" rel="alternate" type="text/html" title="The Subtle Art of Not Giving a Fuck" /><published>2023-03-22T13:11:32+03:30</published><updated>2023-03-22T13:11:32+03:30</updated><id>http://localhost:4000/book/self-help/focus/study-lessens/2023/03/22/the-art-of-dont-giving-a-fuck</id><content type="html" xml:base="http://localhost:4000/book/self-help/focus/study-lessens/2023/03/22/the-art-of-dont-giving-a-fuck.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>

<p>There’s nothing subtle about Mark Manson. He’s crude, vulgar and doesn’t give a f*ck.
But like anything of true value in life, dig a little deeper and you’ll find treasure worthy of any explorer willing to look below the surface.</p>

<p>I recently interviewed Mark about his new book, The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life, and found that the man behind the profanity is actually incredibly inspiring, deeply philosophical, and extremely clever.</p>

<p>So clever in fact that he’s brilliantly disguised his book using language as a way of tricking the reader into reading a book about values.</p>

<p>At its core, The Subtle Art of Not Giving a F*ck is a book about finding what’s truly important to you and letting go of everything else. In the same way that he encourages limiting exposure to mindless distractions such as social media, television and technology, he encourages limiting concern over things that have little to no meaning or value in your life.</p>

<p>In our interview, Mark said, “If seeing things online or hearing things your co-workers say is really affecting you that much then you need to look at the values in your life. If your emotions are constantly being pushed this way or that way, and you feel like you’re never in control, it’s probably because you’re valuing a lot of the wrong things.”</p>

<p>More than a practical guidebook to choosing what’s important in our lives and what’s unimportant, it’s a brutally honest and much needed reality check about our personal problems, fears and expectations. It’s a bold confrontation of self, our painful truths, faults and uncertainties, without all the positive airy fairy fluff we’ve been spoon-fed to believe by self-help gurus.</p>

<h1 id="2-think-positive">2. Think positive?</h1>

<p>“Fuck positivity,” Manson says. “Let’s be honest; sometimes things are fucked up and we have to live with it.”</p>

<p>Be extraordinary?</p>

<p>“Not everyone can be extraordinary - there are winners and losers in society, and some if it is not fair or your fault,” Manson writes.</p>

<p>Seek happiness?</p>

<p>“The path to happiness is a path full of shit heaps and shame,” he remarks.</p>

<p>By far, my favorite quote in the book. And I’m an incessant happiness seeker.</p>

<p>Reading Mark’s book, I laughed until I snorted and cried until I shriveled. He’s as painfully honest as he is outrageously funny. I find his honesty to be refreshing and fulfilling. When every other self-help book injects you with cheap, feel-good highs that last as long as your nose remains buried in the book and serves no practical purpose out in the mud and grime of your daily life, Mark’s book yanks you out of delusion and denial, points at the pit you’re stuck in and forces you to not only look at the filth and dirt covering you but also to accept it.</p>

<p>This, he says, is the real source of empowerment. “Once we embrace our fears, faults and uncertainties - once we stop running from and avoiding, and start confronting painful truths - we can begin to find the courage and confidence we desperately seek.”</p>

<p>Instead of aiming for an unattainably perfect, problem free, feel-good life, Mark suggests asking the essential question, “What problem do you want to have?”</p>

<p>If it’s true what he writes, that “Life is essentially an endless series of problems. The solution to one problem is merely the creation of another,” then it makes sense when he tells me that life sucks for those who constantly try to get away from problems. Instead of asking “how can I get rid of my problems?” the question becomes, “What are the problems that excite me? What are the problems for which I am willing to sacrifice for, to work for?”</p>

<p>“Predicated on peddling highs to people rather than solving legitimate problems,” he calls the modern self-help market the “french fries and soda version of personal growth”. “It’s really good and easy to consume… but there is an inherently painful and difficult struggle as part of growth and if you are never willing to hit people on the face with that, most people are just gonna avoid it… They’re just going to keep finding more feel-good stuff to distract themselves with.”</p>

<p>As any fast food restaurant can tell you, there’s a lot of money to be made in french fries and soda. And with the self-improvement industry netting $11 billion a year in the US alone, it’s no wonder the market is saturated with touchy feely everything-is-awesome french fries. You can practically lick the hope off your fingers along with the salt.</p>

<p>Manson, on the other hand, offers no hope in his book. At least, not on the surface. “This book doesn’t give a fuck about alleviating your problems or your pain,” he writes. “This book is not some guide to greatness - it couldn’t be, because greatness is merely an illusion in our minds, a made-up destination that we obligate ourselves to pursue, our own psychological Atlantis.”</p>

<p>The irony is the book actually is about greatness. It is hopeful. There’s greatness to be discovered in accepting our lack of greatness, our simplicity and beauty amidst the complex and ugly. And in embracing our problems along with the dirt, muck and grime that essentially accompany life and humanity, we come to live the good life we always yearned for.</p>

<p>The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life is a deeply inspiring book about values and purpose cleverly disguised in crude four-letter vulgarity, negativity and apocalyptic doom.</p>

<p>There are no soft puffy cloud prancing unicorns offering hugs on colorful rainbows, only F-bomb explosions and brutal smack-you-in-the-face reality slaps.</p>

<p>But by the time you finish reading it, you’ll find yourself tingling with promise. The world suddenly seems brighter and lighter. You’ll feel free, and oddly, good, despite the shit sandwiches served throughout the book. And it won’t be the surfacey french fry kind of good that makes your body crave real nourishment, but the kind of home-cooked-goodness good that warms you from deep within, like you’ve just been served a hearty platter of whole, raw, organic, unfiltered truth.</p>]]></content><author><name>Ali N. Parizi</name></author><category term="book" /><category term="self-help" /><category term="focus" /><category term="study-lessens" /><summary type="html"><![CDATA[1. Intro]]></summary></entry><entry><title type="html">Adversarial attacks in deep learning</title><link href="http://localhost:4000/blog/ai/machine-learning/deep-learning/2023/03/21/adverserial-attack.html" rel="alternate" type="text/html" title="Adversarial attacks in deep learning" /><published>2023-03-21T16:01:02+03:30</published><updated>2023-03-21T16:01:02+03:30</updated><id>http://localhost:4000/blog/ai/machine-learning/deep-learning/2023/03/21/adverserial-attack</id><content type="html" xml:base="http://localhost:4000/blog/ai/machine-learning/deep-learning/2023/03/21/adverserial-attack.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>Big Data powered machine learning and deep learning has yielded impressive advances in many fields. One example is the release of ImageNet consisting of more than 15 million labelled high-resolution images of 22,000 categories which revolutionized the field of computer vision. State-of-the-art models have already achieved a 98% top-five accuracy on the ImageNet dataset, so it seems as though these models are foolproof and that nothing can go wrong.</p>

<p>However, recent advances in adversarial training have found that this is an illusion. A good model misbehaves frequently when faced with adversarial examples. The image below illustrates the problem:</p>
<p align="center">
 <img src="/assets/images/posts/blog/adversarial-attack/1.png" />
</p>
<p>The model initially classifies the panda picture correctly, but when some noise, imperceptible to human beings, is injected into the picture, the resulting prediction of the model is changed to another animal, gibbon, even with such a high confidence. To us, it appears as if the initial and altered images are the same, although it is radically different to the model. This illustrates the threat these adversarial attacks pose — we may not perceive the difference so we cannot tell an adversarial attack as happened. Hence, although the output of the model may be altered, we cannot tell if the output is correct or incorrect.</p>

<p>This formed the motivation behind the talk for Professor Ling Liu’s keynote speech at the 2019 IEEE Big Data Conference, where she touched on types of adversarial attacks, how adversarial examples are generated, and how to combat against these attacks. Without further ado, I will get into the contents of her speech.</p>

<h1 id="2-types-of-adversarial-attacks">2. Types of adversarial attacks</h1>

<p>Adversarial attacks are classified into two categories — targeted attacks and untargeted attacks.</p>

<p>The targeted attack has a target class, Y, that it wants the target model, M, to classify the image I of class X as. Hence, the goal of the targeted attack is to make M misclassify by predicting the adversarial example, I, as the intended target class Y instead of the true class X. On the other hand, the untargeted attack does not have a target class which it wants the model to classify the image as. Instead, the goal is simply to make the target model misclassify by predicting the adversarial example, I, as a class, other than the original class, X.
Researchers have found that in general, although untargeted attacks are not as good as targeted attacks, they take much less time. Targeted attacks, although more successful in altering the predictions of the model, come at a cost (time).</p>

<h1 id="3-how-are-adversarial-examples-generated">3. How are Adversarial Examples Generated</h1>

<p>Having understood the difference between targeted and untargeted attacks, we now come to the question of how these adversarial attacks are carried out. In a benign machine learning system, the training process seeks to minimize the loss between the target label and the predicted label, formulated mathematically as such:</p>

<!-- Image -->

<p>During the testing phase, the learned model is tested to determine how well it can predict the predicted label. Error is then calculated by the sum of the loss between the target label and the predicted label, formulated mathematically as such:
<!-- Image -->
In adversarial attacks, the following 2 steps are taken:</p>
<ol>
  <li>The query input is changed from the benign input x to \(x^\prime\).</li>
  <li>An attack goal is set such that the prediction outcome, \(H(x)\) is no longer \(y\). The loss is changed from \(L(H(x_i), y_i)\) to \(L(H(x_i), y^{\prime}_i)\) where \(y^{\prime}_i  \ne y_i\).</li>
</ol>

<h1 id="4-adversarial-perturbation">4. Adversarial Perturbation</h1>
<p>One way the query input is changed from x to x’ is through the method called “adversarial perturbation”, where the perturbation is computed such that the prediction will not be the same as the original label. For images, this can come in the form of pixel noise as we saw above with the panda example. Untargeted attacks have the single goal of maximizing the loss between H(x) and H(x’) until the prediction outcome is not y (the real label). Targeted attacks have an additional goal of not only maximizing the loss between H(x) and H(x’) but also to minimize the loss between H(x’) and y’ until H(x’) = y’ instead of y.</p>

<p>Adversarial perturbation can then be categorized into one-step and multi-step perturbation. As the names imply, the one-step perturbation only involves a single stage — add noise once and that is it. On the other hand, the multi-step perturbation is an iterative attack that makes small modifications to the input each time. Therefore, the one-step attack is fast but excessive noise may be added, hence making it easier for humans to detect the changes. Furthermore, it places more weight on the objective of maximizing loss between H(x) and H(x’) and less on minimizing the amount of perturbation. Conversely, the multi-step attack is more strategic as it introduces small amounts of perturbation at each time. However, this also means such an attack is computationally more expensive.</p>

<h1 id="5-black-box-vs-white-box-attacks">5. Black Box VS White Box Attacks</h1>
<p>Now that we have looked at how adversarial attacks are generated, some astute readers may realize one fundamental assumption these attacks take on — that the attack target prediction model, H, is known to the adversary. Only when the targeted model is known can it be compromised to generate adversarial examples by changing the input. However, attackers do not always know or have access to the targeted model. This may sound like a surefire way to ward off these adversarial attackers, but the truth is that black box attacks are also highly effective.
Black box attacks are based on the notion of transferability of adversarial examples — the phenomenon whereby adversarial examples, although generated to attack a surrogate model G, can achieve impressive results when attacking another model H. The steps taken are as follows:</p>
<ol>
  <li>The attack target prediction model H is privately trained and unknown to the adversary.</li>
  <li>A surrogate model G, which mimics H, is used to generate adversarial examples.</li>
  <li>By using the transferability of adversarial examples, black box attacks can be launched to attack H.</li>
</ol>

<p>This attack can be launched either with the training dataset being known or unknown. In the case where the dataset is known to the adversary, the model G can be trained on the same dataset as model H to mimic H.</p>

<p>When the training dataset is unknown however, adversaries can leverage on Membership Inference Attacks, whereby an attack model whose purpose is to distinguish the target model’s behavior on the training inputs from its behavior on the inputs that it did not encounter during training is trained. In essence, this turns into a classification problem to recognize differences in the target model’s predictions on the inputs that it trained on versus the inputs that it did not train on. This enables the adversary to obtain a better sense of the training dataset D which model H was trained on, enabling the attacker to generate a shadow dataset S on the basis of the true training dataset so as to train the surrogate model G. Having trained G on S where G mimics H and S mimics D, black box attacks can then be launched on H.</p>

<h2 id="51-black-box-attacks">5.1 Black Box Attacks</h2>
<p>Now that we have seen how black box attacks vary from white box attacks in that the target model H is unknown to the adversary, we will cover the various tactics used in black box attacks.</p>

<h2 id="52-white-box-attacks">5.2 White Box Attacks</h2>

<h2 id="53-physical-attacks">5.3 Physical Attacks</h2>
<p>One simple way in which the query input is changed from x to x’ is by simply adding something physically (eg. bright colour) to disturb the model. One example is how researchers at CMU added eyeglasses to a person in an attack against facial recognition models. The image below illustrates the attack:</p>

<p><img src="/assets/images/posts/blog/adversarial-attack/2.png" alt="image" /></p>

<p>The first row of images correspond to the original image modified by adding the eyeglasses, and the second row of images correspond to the impersonation targets, which are the intended misclassification targets. Just by adding the eyeglasses onto the original image, the facial recognition model was tricked into classifying the images on the top row as the images in the bottom row.</p>

<p>Another example comes from researchers at Google who added stickers to the input image to change the classification of the image, as illustrated by the image below:
<img src="/assets/images/posts/blog/adversarial-attack/3.png" alt="image" /></p>

<p>These examples show how effective such physical attacks can be.</p>

<h2 id="54-out-of-distribution-ood-attack">5.4 Out of Distribution (OOD) Attack</h2>
<p>Another way in which black box attacks are carried out is through out-of-distribution (OOD) attacks. The traditional assumption in machine learning is that all train and test examples are drawn independently from the same distribution. In an OOD attack, this assumption is exploited by providing images of a different distribution from the training dataset to the model, for example feeding TinyImageNet data into a CIFAR-10 classifier which would lead to an incorrect prediction with high confidence.</p>

<h1 id="6-how-can-we-trust-machine-learning">6. How Can We Trust Machine Learning?</h1>
<p>Now that we have taken a look at the various types of adversarial attacks, a natural question then comes — how can we trust our machine learning models if they are so susceptible to adversarial attacks?</p>

<p>One possible approach has been proposed by Chow et al. in 2019 in the paper titled “Denoising and Verification Cross-Layer Ensemble Against Black-box Adversarial Attacks”. The approach is centred around enabling machine learning systems to automatically detect adversarial attacks and then automatically repair them through the use of denoising and verification ensembles.</p>

<h1 id="7-denoising-ensembles">7. Denoising Ensembles</h1>
<p>First, input images have to pass through denoising ensembles that attempt different methods to remove any added noise to the image, for example adding Gaussian noise. Since the specific noise added to the image by the adversary is unknown to the defender, there is a need for an ensemble of denoisers to each attempt to remove each type of noise.</p>

<p>The image below shows the training process for the denoising autoencoder — the original image is injected with some noise that the attacker might inject, and the autoencoder tries to reconstruct the original uncorrupted image. In the training process, the objective is to reduce the reconstruction error between the reconstructed image and the original image.</p>

<p><img src="/assets/images/posts/blog/adversarial-attack/4.png" alt="image" /></p>

<p>By developing an ensemble of these autoencoders each trained to remove a specific type of noise, the hope is that the corrupted images would be sufficiently denoised such that it is close to the original uncorrupted image to allow for image classification.</p>

<h2 id="71-verification-ensemble">7.1 Verification Ensemble</h2>
<p>After the images have been denoised, they then go through a verification ensemble which reviews every denoised image produced by each denoiser and then classifies the denoised image. Each classifier in the verification ensemble classifies each denoised image, and the ensemble then votes to determine the final category the image belongs to. This means that although some images may not have been denoised the correct way in the denoising step, the verification ensemble votes on all the denoised images, thereby increasing the likelihood of making a more accurate prediction.</p>

<h2 id="72-diversity">7.2 Diversity</h2>
<p>Diversity of the denoisers and verifiers have found to be very important because firstly, adversarial attackers will get better at altering images so there is a need for a diverse group of denoisers that can handle a variety of corrupted images. Following this, there is also a need for verifiers to be diverse so they can generate a variety of classifications so that it would be difficult adversarial attackers to manipulate them just as how they have managed to manipulate normal classifiers that we trust and use so frequently in machine learning.</p>

<p>This remains an open problem because, after all these decisions by the various verifiers, there is still a final decision maker that needs to decide whose opinion to listen to. The final decision maker would need to preserve the diversity present in the ensemble, which is not an easy task to tackle.</p>

<h1 id="8-conclusion">8. Conclusion</h1>
<p>We have taken a look at various types of adversarial attacks as well as a promising method to defend against these attacks. This is definitely something to keep in mind when we implement machine learning models. Instead of blindly trusting the models to produce the correct results, we need to guard against these adversarial attacks and always think twice before we accept the decisions made by these models.</p>

<p>A huge thanks to Professor Liu for this enlightening keynote on this pressing problem in machine learning!</p>

<h1 id="references">References</h1>
<ol>
  <li><a href="https://arxiv.org/abs/1805.07984">I. J. Goodfellow, J. Shlens, και C. Szegedy, “Explaining and Harnessing Adversarial Examples”. arXiv, 2014.</a></li>
  <li><a href="https://www.tensorflow.org/tutorials/generative/adversarial_fgsm">Tensorflow blog tutorials</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">Adverserial Machine Learning</a></li>
  <li><a href="https://openai.com/blog/adversarial-example-research/">Attacking Machine Learning
with Adversarial Examples</a></li>
  <li><a href="https://towardsdatascience.com/breaking-neural-networks-with-adversarial-attacks-f4290a9a45aa">Breaking neural networks with adversarial attacks</a></li>
</ol>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><summary type="html"><![CDATA[1. Intro Big Data powered machine learning and deep learning has yielded impressive advances in many fields. One example is the release of ImageNet consisting of more than 15 million labelled high-resolution images of 22,000 categories which revolutionized the field of computer vision. State-of-the-art models have already achieved a 98% top-five accuracy on the ImageNet dataset, so it seems as though these models are foolproof and that nothing can go wrong.]]></summary></entry><entry><title type="html">Installing Tensorflow with GPU Support</title><link href="http://localhost:4000/blog/ai/machine-learning/deep-learning/2023/03/19/installing-tensorflow-with-gpu.html" rel="alternate" type="text/html" title="Installing Tensorflow with GPU Support" /><published>2023-03-19T12:19:43+03:30</published><updated>2023-03-19T12:19:43+03:30</updated><id>http://localhost:4000/blog/ai/machine-learning/deep-learning/2023/03/19/installing-tensorflow-with-gpu</id><content type="html" xml:base="http://localhost:4000/blog/ai/machine-learning/deep-learning/2023/03/19/installing-tensorflow-with-gpu.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>

<p>The rise to prominence of deep learning over the past decade is spectacular. From dominating in almost every single competition with its innovative and groundbreaking technologies, it has also led to several new types of research and training methods. One of the most popular ways to handle deep learning models to solve complex computational problems is with the help of deep frameworks.</p>

<p>One such popular deep learning library to build and construct models to find solutions to numerous tasks is TensorFlow. TensorFlow is regarded as one of the best libraries to solve almost any question related to neural networks and deep learning. While this library performs effectively with most smaller and simpler datasets to achieve tasks on a CPU, its true power lies in the utilization of the Graphics Processing Unit (GPU).</p>

<p>The GPU improvises the performance of this deep learning framework to reach new heights and peaks. However, one of the most annoying issues that deep learning programmers, developers, and enthusiasts face is the trouble of CUDA errors. This experience is rather frustrating for most individuals because it is a common occurrence while dealing with deep learning models.</p>

<p>In this article, we will explore how to get the latest version of TensorFlow and stay updated with modern technology.</p>

<p>We will use Anacoda because it’s almost the best python environment for machine-learning operations. To get started, let’s install anacoda on your computer. You can skip this step if you already have installed Anacoda on your Ubuntu machine.</p>

<p align="center">
    <img class="img-light-bg" src="/assets/images/posts/blog/installing-tensorflow-gpu/keras-logo.png" width="40%" />
</p>

<h1 id="2-anaconda">2. Anaconda</h1>
<p>Anaconda is a distribution of the Python and R programming languages for scientific computing (data science, machine learning applications, large-scale data processing, predictive analytics, etc.), that aims to simplify package management and deployment. The distribution includes data-science packages suitable for Windows, Linux, and macOS. It is developed and maintained by Anaconda, Inc., which was founded by Peter Wang and Travis Oliphant in 2012. As an Anaconda, Inc. product, it is also known as Anaconda Distribution or Anaconda Individual Edition, while other products from the company are Anaconda Team Edition and Anaconda Enterprise Edition, both of which are not free. For me and probably you and almost 90% of people, the free version is good and does the job well for us. Installing anaconda requires installing For Debian based distros (such as Ubuntu) run the command below:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt <span class="nb">install </span>libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6
</code></pre></div></div>
<p>For installing Anaconda you can visit its official website <a href="https://www.anaconda.com/products/distribution">anaconda.com</a> and download the latest installer version or Run the command below:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>curl https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh | /bin/bash
</code></pre></div></div>

<p>Then follow the installation process to complete it. Close and re-open your terminal window for the installation to take effect, or enter the command source ~/.bashrc (or ~/.zshrc if you are using zsh) to refresh the terminal.</p>

<blockquote>
  <p><strong>Note</strong>: The installer prompts you to choose whether to initialize Anaconda Distribution by running <code class="language-plaintext highlighter-rouge">conda init</code>. Anaconda recommends entering “yes”. If you enter “no”, then conda will not modify your shell scripts at all. To initialize after the installation process is done, first run source [PATH TO CONDA]/bin/activate and then run <code class="language-plaintext highlighter-rouge">conda init</code>.</p>
</blockquote>

<h2 id="21-creating-conda-environment">2.1 Creating Conda Environment</h2>

<p>Create a new conda environment named tf with the following command.</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>conda create <span class="nt">--name</span> tf <span class="nv">python</span><span class="o">=</span>3.9
</code></pre></div></div>
<p>You can deactivate and activate it with the following commands.</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>conda deactivate
<span class="gp">$</span><span class="w"> </span>conda activate tf
</code></pre></div></div>

<blockquote>
  <p><strong>Note</strong>: After installing Anaconda, the default conda environment will automatically activated when you open a new terminal. I personally prefer not to activate the environment automatically. You can turn off this feature running <code class="language-plaintext highlighter-rouge">$ conda config --set auto_activate_base False</code>.</p>
</blockquote>

<h1 id="4-nvidia-driver-cuda-and-cudnn">4. Nvidia Driver, CUDA and cuDNN</h1>
<p>It is required you to install a proper Nvidia driver on your machine. If you haven’t installed the Nvidia driver on your machine use the command below to install the driver:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt <span class="nb">install </span>nvidia-driver-515
</code></pre></div></div>

<p>To confirm that it is installed properly run the command bellow:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>nvidia-smi
</code></pre></div></div>

<pre><code class="language-output">Mon Mar 19 12:19:49 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ...  Off  | 00000000:65:00.0  On |                  N/A |
|  0%   47C    P8    44W / 340W |   1325MiB / 10240MiB |      4%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1876      G   /usr/lib/xorg/Xorg                940MiB |
|    0   N/A  N/A      2034      G   /usr/bin/gnome-shell               48MiB |
|    0   N/A  N/A      3396      G   ...1/usr/lib/firefox/firefox      161MiB |
|    0   N/A  N/A      4658      G   ...816051303568945556,131072       42MiB |
|    0   N/A  N/A      4797      G   ...RendererForSitePerProcess      130MiB |
+-----------------------------------------------------------------------------+
</code></pre>

<p>Then install CUDA and cuDNN:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(tf) $</span><span class="w"> </span>conda <span class="nb">install</span> <span class="nt">-c</span> conda-forge <span class="nv">cudatoolkit</span><span class="o">=</span>11.2.2 <span class="nv">cudnn</span><span class="o">=</span>8.1.0
</code></pre></div></div>
<p>Configure the system paths. You can do it with the following command every time you start a new terminal after activating your conda environment.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(tf) $</span><span class="w"> </span><span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:<span class="nv">$CONDA_PREFIX</span>/lib/
</code></pre></div></div>

<p>For your convenience it is recommended that you automate it with the following commands. The system paths will be automatically configured when you activate this conda environment.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(tf) $</span><span class="w"> </span><span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nv">$CONDA_PREFIX</span>/etc/conda/activate.d
<span class="gp">(tf) $</span><span class="w"> </span><span class="nb">echo</span> <span class="s1">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/'</span> <span class="o">&gt;</span> <span class="nv">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh
</code></pre></div></div>

<p>In Ubuntu 22.04, we have to install NVCC as well:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>Install NVCC
<span class="gp">(tf) $</span><span class="w"> </span>conda <span class="nb">install</span> <span class="nt">-c</span> nvidia cuda-nvcc<span class="o">=</span>11.3.58
<span class="gp">#</span><span class="w"> </span>Configure the XLA cuda directory
<span class="gp">(tf) $</span><span class="w"> </span><span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nv">$CONDA_PREFIX</span>/etc/conda/activate.d
<span class="gp">(tf) $</span><span class="w"> </span><span class="nb">printf</span> <span class="s1">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/\nexport XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib/\n'</span> <span class="o">&gt;</span> <span class="nv">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh
<span class="gp">(tf) $</span><span class="w"> </span><span class="nb">source</span> <span class="nv">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh
<span class="gp">#</span><span class="w"> </span>Copy libdevice file to the required path
<span class="gp">(tf) $</span><span class="w"> </span><span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nv">$CONDA_PREFIX</span>/lib/nvvm/libdevice
<span class="gp">(tf) $</span><span class="w"> </span><span class="nb">cp</span> <span class="nv">$CONDA_PREFIX</span>/lib/libdevice.10.bc <span class="nv">$CONDA_PREFIX</span>/lib/nvvm/libdevice/
</code></pre></div></div>

<h1 id="5-installing-tensorflow">5. Installing Tensorflow</h1>
<p>TensorFlow requires a recent version of pip, so upgrade your pip installation to be sure you’re running the latest version.</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(tf) $</span><span class="w"> </span>pip <span class="nb">install</span> <span class="nt">--upgrade</span> pip
<span class="gp">(tf) $</span><span class="w"> </span>pip <span class="nb">install </span>tensorflow
</code></pre></div></div>
<p>Verify the GPU setup:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">(tf) $</span><span class="w"> </span>python3 <span class="nt">-c</span> <span class="s2">"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"</span>
</code></pre></div></div>
<p>If a list of GPU devices is returned, you’ve installed TensorFlow successfully.</p>

<pre><code class="language-output">[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
</code></pre>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://docs.anaconda.com/anaconda/install/index.html"><em>Installing Anaconda (anaconda.com)</em></a></li>
  <li><a href="https://www.tensorflow.org/install/pip"><em>Install TensorFlow with pip (tensorflow.org)</em></a></li>
</ul>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><summary type="html"><![CDATA[1. Intro]]></summary></entry><entry><title type="html">Bypass The Islamic Republic Again: Installing V2ray + XUI</title><link href="http://localhost:4000/blog/network/vpn/2022/10/31/v2ray-xui.html" rel="alternate" type="text/html" title="Bypass The Islamic Republic Again: Installing V2ray + XUI" /><published>2022-10-31T13:10:23+03:30</published><updated>2022-10-31T13:10:23+03:30</updated><id>http://localhost:4000/blog/network/vpn/2022/10/31/v2ray-xui</id><content type="html" xml:base="http://localhost:4000/blog/network/vpn/2022/10/31/v2ray-xui.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>Last time, I wrote an article about bypassing God’s government restrictions to be able to access the outside world. Now the base solution still stands, but the protocol we used to implement that solution no longer works. We can clap our hands to the government priests for upgrading their knowledge about VPN protocols and say bravo in chinese “<a href="https://translate.google.com/?sl=zh-CN&amp;tl=en&amp;text=%E9%AB%98%E4%B8%9D%E7%BA%B3%E7%BA%B3%E9%A1%BF&amp;op=translate" title="Kose na na ton!">高丝纳纳顿</a>”.</p>

<p>As our government and Chinese folks are each other’s besties and in the same bed! we can conclude that any protocol that works on the great firewall of china, should work for the evils firewall of the Islamic Republic!</p>

<p>V2Ray is a VPN protocol written with love by some free Chinese people. It works on the application layer and its traffic looks like working with an actual web-site and it’s less prone to detect. The problem with V2Ray is the english language support, documentations and weak client software which can easily be improved if their community decided to share their information and issues in english not in fucking chinees!</p>

<p>For this article we consider you have access to a Virtual Machine in the outside world. You can access that machine using SSH or you can easily install a cockpit to be able to access your Linux machine through the browser.</p>

<h2 id="11-installing-cockpit-optional">1.1 Installing Cockpit (Optional)</h2>
<p>To install Cockpit, connect to your machine using ssh and use the aptitude package manager to install cockpit:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt update <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt upgrade <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt <span class="nb">install </span>cockpit <span class="nt">--yes</span>
</code></pre></div></div>

<p>This should install the cockpit and dose all the configurations for you. The cockpit is a web-based control panel and it will run on port 9090 of the server so, you have to allow connecting this port if your firewall is enabled:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw allow 9090
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw disable
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw <span class="nb">enable</span>
</code></pre></div></div>

<p>Then open a browser and type the address <code class="language-plaintext highlighter-rouge">YOUR_VM_IP:9090</code> to see the cockpit panel.
Username and password of cockpit panel are the same as your vm user for example:</p>

<pre><code class="language-txt">username: root
password: 123456
</code></pre>

<p align="center">
    <img width="80%" src="/assets/images/posts/blog/v2ray/cockpit.png" />
</p>

<h1 id="2-installing-v2ray-using-x-ui">2. Installing V2ray using X-UI</h1>
<p>To install V2ray you can easily install X-UI panel on your machine and this will automatically install all necessary things for you. X-UI documentation could be found here: <a href="https://seakfind.github.io/2021/10/10/X-UI/"><strong>seakfind</strong></a></p>

<p>The installation process is pretty easy, just connect to your machine and install <code class="language-plaintext highlighter-rouge">socat</code> first:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>curl socat <span class="nt">-y</span>
</code></pre></div></div>

<p>Then you can skip obtaining certificate steps and directly jump on installing the x-ui using its script:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>bash &lt;<span class="o">(</span>curl <span class="nt">-Ls</span> https://raw.githubusercontent.com/vaxilu/x-ui/master/install.sh<span class="o">)</span>
</code></pre></div></div>
<p>Then it will ask you to type <code class="language-plaintext highlighter-rouge">yes|no</code>, you type yes and press enter on any chinese message prompt it shows to you. That’s it, you can start  the panel by typing:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>x-ui start
</code></pre></div></div>

<p>It starts the X-UI panel on the port <code class="language-plaintext highlighter-rouge">54321</code> of server. Open a browser and type <code class="language-plaintext highlighter-rouge">YOUR_VM_IP:54321</code> in the address bar to see the panel. Default username and password are:</p>

<pre><code class="language-txt">username: admin
password: admin
</code></pre>

<p align="center">
    <img width="80%" src="/assets/images/posts/blog/v2ray/xui.png" />
</p>

<p>Default language of x-ui is chaines, i use Google chrome and Google translate to translate its contexts to english and i recommend you to do so.</p>

<p>After login, you have to go and change the default username and password of the panel (You can change the default port as well). From the sidebar panel select the third option, then select the second tab. Now type the old username and password on first two fields the new ones on the next two. Press <code class="language-plaintext highlighter-rouge">Revise</code> to save the changes.</p>

<p align="center">
    <img width="80%" src="/assets/images/posts/blog/v2ray/x-ui-1.png" />
</p>

<p>Now go to inbound list from the sidebar and press add for creating a new VPN configuration. For example you can select VMess or VLess protocol under Websocket(ws) as you can see on the picture below. If you choose VLess be aware of that VLess has no encryption and VMess is a better choice.</p>

<blockquote>
  <p>Note: You can go and search for other V2Ray configurations but VMess is good enough for our article.</p>
</blockquote>

<p align="center">
    <img width="80%" src="/assets/images/posts/blog/v2ray/xui-u.png" />
</p>

<p>Now, you are all set, you can scan the QR code or press copy share link to copy the share link to the clip board and send it to your clients.</p>

<p align="center">
    <img width="80%" src="/assets/images/posts/blog/v2ray/x-ui-2.png" />
</p>

<h1 id="3-clients-setup-for-using-v2ray">3. Clients setup for using V2Ray</h1>
<p>To connect to the V2Ray server you have to install the proper client application on your devices. Here is a list of application clients for different devices and operating systems:</p>

<ul>
  <li><strong>Android</strong>: <a href="https://play.google.com/store/apps/details?id=com.v2ray.ang">V2rayNG (Google play)</a></li>
  <li><strong>IOS</strong>: <a href="https://apps.apple.com/us/app/napsternetv/id1629465476">NapsternetV (App Store)</a></li>
  <li><strong>Windows</strong>: <a href="https://github.com/Qv2ray/Qv2ray/releases/download/v2.7.0/Qv2ray-v2.7.0-Windows-Installer.exe">Qv2ray-v2.7.0-Windows-Installer.exe</a></li>
  <li><strong>Mac OSX</strong>: <a href="https://github.com/Qv2ray/Qv2ray/releases/download/v2.7.0/Qv2ray-v2.7.0-macOS-x64.dmg">Qv2ray-v2.7.0-macOS-x64.dmg</a></li>
  <li><strong>Linux</strong>: <a href="https://github.com/Qv2ray/Qv2ray/releases/download/v2.7.0/Qv2ray-v2.7.0-linux-x64.AppImage">Qv2ray-v2.7.0-linux-x64.AppImage</a></li>
</ul>

<h1 id="4-using-tls-optional-but-recommended">4. Using TLS (Optional but, recommended.)</h1>

<p>To make the clients connection more secure and safer, we need to use TLS on our server.</p>
<h2 id="41-what-is-transport-layer-security-tls">4.1 What is Transport Layer Security (TLS)?</h2>

<p>Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the Internet. A primary use case of TLS is encrypting the communication between web applications and servers, such as web browsers loading a website. TLS can also be used to encrypt other communications such as email, messaging, and voice over IP (VoIP). In this article we will focus on the role of TLS in web application security.</p>

<p>TLS was proposed by the Internet Engineering Task Force (IETF), an international standards organization, and the first version of the protocol was published in 1999. The most recent version is TLS 1.3, which was published in 2018.</p>

<h1 id="42-buy-a-domain">4.2 Buy a domain</h1>

<h1 id="43-generating-a-new-certificate-using-cert-bot">4.3 Generating a new certificate using <code class="language-plaintext highlighter-rouge">cert-bot</code></h1>

<h1 id="45-activating-cdn-optional-but-recommended">4.5 Activating CDN (Optional but recommended)</h1>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://seakfind.github.io/2021/10/10/X-UI/">https://seakfind.github.io/2021/10/10/X-UI/</a></li>
</ul>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="network" /><category term="vpn" /><summary type="html"><![CDATA[1. Intro Last time, I wrote an article about bypassing God’s government restrictions to be able to access the outside world. Now the base solution still stands, but the protocol we used to implement that solution no longer works. We can clap our hands to the government priests for upgrading their knowledge about VPN protocols and say bravo in chinese “高丝纳纳顿”.]]></summary></entry><entry><title type="html">How to bypass the ‘Islamic Republic’ internet filtering?</title><link href="http://localhost:4000/blog/network/vpn/2022/09/26/bypass-islamic-republic.html" rel="alternate" type="text/html" title="How to bypass the ‘Islamic Republic’ internet filtering?" /><published>2022-09-26T17:50:22+03:30</published><updated>2022-09-26T17:50:22+03:30</updated><id>http://localhost:4000/blog/network/vpn/2022/09/26/bypass-islamic-republic</id><content type="html" xml:base="http://localhost:4000/blog/network/vpn/2022/09/26/bypass-islamic-republic.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>

<p>Some days, we hear some stories around the world that governments argue with people about some wrong laws, opaque decisions, bad economic environment, financial corruption, and many other reasons. To control the situation, one of their solutions is to disconnect people from the world by forcing ISPs and top-tier provider companies to shut down their internet connections. Some of these countries are China, North Korea, And the Islamic Republic Of Iran. The people living in these countries may do their jobs with the internet and in other words, their life has a direct relation with the connectivity to online services. In this situation, some necessary jobs that are in scathe are Developers, online shops, reporters, and many more. As a developer, I can’t live without the internet and my professional life is mixed with this technology. So I have to solve this problem by myself and in this case, I can’t accept the government’s politics. Let’s begin.</p>

<h1 id="2-what-is-the-solution">2. What is the solution</h1>
<p>How can we access the outside world? to access the outside world, we need to access a machine that is connected to the internet. We can access the world through that machine. In these situations, governments wouldn’t disconnect data centers from the internet because some bad things can happen to their servers and their companies will be at huge risk, especially in terms of security. So we can conclude that data centers that are inside the country are still connected to the internet and can access the outside world.</p>

<p>If we could successfully be connected to the world via a machine in the local data center, there still would be a problem for our freedom, <strong>cruel sanctions of the united states</strong>, which prevent these poor people to access services and contents which is accessible by other people in the world. To tackle this problem, we need a second machine which is in another country and is accessible through the internet. We have to send our packets using that second machine to be fully free. To do so, we need to make a <strong>virtual private network</strong>(VPN).</p>

<h2 id="21-virtual-private-network-vpn">2.1 Virtual Private Network (VPN)</h2>
<p>A virtual private network extends a private network across a public network and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network. The benefits of a VPN include increases in functionality, security, and management of the private network.</p>

<div align="center">
    <img src="/assets/images/posts/blog/vpn-setup/vpn-schema.png" />
</div>
<p><br /></p>

<p>It provides access to resources that are inaccessible on the public network and is typically used for remote workers. Encryption is common, although not an inherent part of a VPN connection. A VPN is created by establishing a virtual point-to-point connection through the use of dedicated circuits or with tunneling protocols over existing networks. A VPN available from the public Internet can provide some of the benefits of a wide area network. From a user perspective, the resources available within the private network can be accessed remotely (<a href="https://en.wikipedia.org/wiki/Virtual_private_network">Wikipedia</a>).</p>

<h1 id="3-running-a-wireguard-vpn-server-on-ubuntu-2004-lts">3. Running a WireGuard VPN server on Ubuntu 20.04 (LTS)</h1>
<p>WireGuard is a communication protocol and free and open-source software that implements encrypted virtual private networks, and was designed with the goals of ease of use, high speed performance, and low attack surface. It aims for better performance and more power than IPsec and OpenVPN, two common tunneling protocols (<a href="https://en.wikipedia.org/wiki/WireGuard">Wikipedia</a>).</p>

<div align="center">
    <img width="50%" src="/assets/images/posts/blog/vpn-setup/wg-logo.png" />
</div>

<p>For this tutorial, I choose Wireguard as the VPN protocol of this article. Installation and configuration of the Wireguard VPN server are quite simple and easy to understand for those who are not familiar with some concepts of networking in Linux in comparison with other protocols such as OpenVPN.</p>

<p>To get started, you need a Virtual Machine(VM) accessible through the internet via SSH in outside world. Let’s assume my VM IP address is <code class="language-plaintext highlighter-rouge">77.222.67.140</code>, I can connect to it using SSH as below:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ssh root@77.222.67.140
</code></pre></div></div>

<p>After running the command above, it asks you to type “yes” if you trust this host, just type “<code class="language-plaintext highlighter-rouge">yes</code>” and don’t ask why. Then you have to enter the VM password.
The first thing you do after connecting to the virtual machine is updating operating system packages to the latest available version using <code class="language-plaintext highlighter-rouge">Aptitude Package Manager</code>(apt):</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt update <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span>apt upgrade <span class="nt">--yes</span>
</code></pre></div></div>

<blockquote>
  <p>Note: It’s recommended that you reboot and reconnect to the VM after upgrading its packages.</p>
</blockquote>

<p>Now we have to install <code class="language-plaintext highlighter-rouge">wireguard</code> and <code class="language-plaintext highlighter-rouge">wireguard-tools</code> using apt:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>wireguard <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>wireguard-tools <span class="nt">--yes</span>
</code></pre></div></div>

<p>This should install the Wireguard kernel module and the necessary tools for running our VPN server. If you would like to route your WireGuard Peer’s Internet traffic through the WireGuard Server then you will need to configure IP forwarding. To configure forwarding, open the <code class="language-plaintext highlighter-rouge">/etc/sysctl.conf</code> file using vim or your preferred editor:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>vim /etc/sysctl.conf 
</code></pre></div></div>

<p>Then you have to look for a line containing <code class="language-plaintext highlighter-rouge">net.ipv4.ip_forward=1</code> and uncomment that line (remove leading <code class="language-plaintext highlighter-rouge">#</code>) Or, you can just add this text at the end of <code class="language-plaintext highlighter-rouge">sysctl.conf</code> file. If you are using IPv6 with WireGuard, uncomment/add line <code class="language-plaintext highlighter-rouge">net.ipv6.conf.all.forwarding=1</code>. If you are using both IPv4 and IPv6, ensure that you include both lines. Save and close the file when you are finished (if you were using vim press <code class="language-plaintext highlighter-rouge">ESC</code> then type <code class="language-plaintext highlighter-rouge">wq</code> and press <code class="language-plaintext highlighter-rouge">enter</code>). To read the file and load the new values for your current terminal session, run:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>sysctl <span class="nt">-p</span>
</code></pre></div></div>
<p>If you did it right, you have to see an output as below:</p>
<pre><code class="language-output">net.ipv6.conf.all.forwarding = 1
net.ipv4.ip_forward = 1
</code></pre>

<p>Now your WireGuard Server will be able to forward incoming traffic from the virtual VPN ethernet device to others on the server, and from there to the public Internet. Using this configuration will allow you to route all web traffic from your WireGuard Peer via your server’s IP address, and <strong>your client’s public IP address will be effectively hidden</strong>.</p>

<p>However, before traffic can be routed via your server correctly, you will need to configure some firewall rules. These rules will ensure that traffic to and from your WireGuard Server and Peers flows properly.</p>

<h2 id="31-wireguard-ui">3.1 Wireguard UI</h2>
<p><a href="https://github.com/ngoduykhanh/wireguard-ui"><strong>Wireguard UI</strong></a> is a web-based config generator for wireguard server. If you’ve seen the DigitalOcean tutorial for running WireGurad server on ubuntu 20.04 which i pasted some parts of their tutorial here(Or other popular tutorials), they use the command line to generate configurations for clients which is called <strong>adding peers</strong> for wireguard server. Using command line interface and using wireguard-tool is quite hard to manage clients if you are making a network for your co-workers, family or friends. Wireguard-ui is a web-based interface for generating and managing client profiles and it’s written with go-lang which means that if you use its binary files which are available on their <a href="https://github.com/ngoduykhanh/wireguard-ui/releases"><strong>releases page</strong></a>, You don’t have to worry about running the application and it should work without any problems.</p>

<p>To start using wireguard-ui, you need to download the binary files first:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>wget https://github.com/ngoduykhanh/wireguard-ui/releases/download/v0.3.7/wireguard-ui-v0.3.7-linux-amd64.tar.gz
</code></pre></div></div>

<p>Then unzip the downloaded file:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">tar</span> <span class="nt">-xvf</span> wireguard-ui-v0.3.7-linux-amd64.tar.gz
</code></pre></div></div>

<p>Before running wireguard-ui, you have to open port 5000 on your VM which is the default port of wireguard-ui:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ufw allow 5000 # Open 5000 port
$ ufw disable # stop the firewall
$ ufw enable  # start the firewall
</code></pre></div></div>

<p>Now, run wireguard-ui using:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>./wireguard-ui
</code></pre></div></div>
<blockquote>
  <p>Note: If the above command failed, make sure that you gave the run access to that binary file using <code class="language-plaintext highlighter-rouge">$ chmod +x wireguard-ui</code></p>
</blockquote>

<p>After running wireguard-ui you can open your browser and type <code class="language-plaintext highlighter-rouge">YOUR_MACHINE_ADDRESS:5000</code> at the address bar and start using wireguard-ui. The default username and passwords for wireguard-ui are:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>username: admin
password: admin
</code></pre></div></div>
<p>Login to the panel and make as many client as you want, then download the configuration files or save the qr code for each client. After you finished your job, press <code class="language-plaintext highlighter-rouge">apply config</code> and go back to your vm, terminate the wireguard-ui by pressing <code class="language-plaintext highlighter-rouge">ctrl + c</code>.</p>

<div align="center">
    <img src="/assets/images/posts/blog/vpn-setup/wireguard-ui.png" />
</div>

<p><br /></p>

<blockquote>
  <p>Note: Before making user clients, I recommend you to first change the server’s default port (then press <code class="language-plaintext highlighter-rouge">apply config</code>) and then begin creating profiles.</p>
</blockquote>

<p>Wireguard-ui should generate a configuration file and place it inside <code class="language-plaintext highlighter-rouge">/etc/wireguard/wg0.conf</code>. After terminating wireguard-ui, no further configurations are needed for adding clients and you can give the downloaded config files to your clients. To run the server there are two more steps to go with. One is configuring the server’s firewall and the other one is running wireguard server as a background service which is available in the next sections.</p>

<h2 id="32-configuring-the-wireguard-servers-firewall">3.2 Configuring the WireGuard Server’s Firewall</h2>

<p>In this section you will edit the WireGuard Server’s configuration to add firewall rules that will ensure traffic to and from the server and clients is routed correctly. As with the previous section, skip this step if you are only using your WireGuard VPN for a machine to machine connection to access resources that are restricted to your VPN.</p>

<p>To allow WireGuard VPN traffic through the Server’s firewall, you’ll need to enable masquerading, which is an iptables concept that provides on-the-fly dynamic network address translation (NAT) to correctly route client connections.</p>

<p>First find the public network interface of your WireGuard Server using the ip route sub-command:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ip route list default
</code></pre></div></div>

<p>The public interface is the string found within this command’s output that follows the word “dev”. For example, this result shows the interface named eth0, which is highlighted below:</p>

<pre><code class="language-output">default via 77.222.67.140 dev eth0 proto static
</code></pre>
<p>Note your device’s name since you will add it to the iptables rules in the next step.
To add firewall rules to your WireGuard Server, open the /etc/wireguard/wg0.conf file with vim or your preferred editor again.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>vim /etc/wireguard/wg0.conf
</code></pre></div></div>
<p>At the bottom of the file after the <code class="language-plaintext highlighter-rouge">SaveConfig = true</code> line, paste the following lines:</p>

<pre><code class="language-txt">PostUp = ufw route allow in on wg0 out on eth0
PostUp = iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
PostUp = ip6tables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
PreDown = ufw route delete allow in on wg0 out on eth0
PreDown = iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE
PreDown = ip6tables -t nat -D POSTROUTING -o eth0 -j MASQUERADE
</code></pre>

<p>The PostUp lines will run when the WireGuard Server starts the virtual VPN tunnel. In the example here, it will add three ufw and iptables rules:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ufw route allow in on wg0 out on eth0</code> - This rule will allow forwarding IPv4 and IPv6 traffic that comes in on the wg0 VPN interface to the eth0 network interface on the server. It works in conjunction with the net.ipv4.ip_forward and net.ipv6.conf.all.forwarding sysctl values that you configured in the previous section.</li>
  <li><code class="language-plaintext highlighter-rouge">iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE</code> - This rule configures masquerading, and rewrites IPv4 traffic that comes in on the wg0 VPN interface to make it appear like it originates directly from the WireGuard Server’s public IPv4 address.</li>
  <li><code class="language-plaintext highlighter-rouge">ip6tables -t nat -I POSTROUTING -o eth0 -j MASQUERADE</code> - This rule configures masquerading, and rewrites IPv6 traffic that comes in on the wg0 VPN interface to make it appear like it originates directly from the WireGuard Server’s public IPv6 address.</li>
</ul>

<blockquote>
  <p>Note: You can run these command just after running the server without adding Post and Pre configs.</p>
</blockquote>

<p>The PreDown rules run when the WireGuard Server stops the virtual VPN tunnel. These rules are the inverse of the PostUp rules, and function to undo the forwarding and masquerading rules for the VPN interface when the VPN is stopped.</p>

<p>In both cases, edit the configuration to include or exclude the IPv4 and IPv6 rules that are appropriate for your VPN. For example, if you are just using IPv4, then you can exclude the lines with the ip6tables commands.</p>

<p>Conversely, if you are only using IPv6, then edit the configuration to only include the ip6tables commands. The ufw lines should exist for any combination of IPv4 and IPv6 networks. Save and close the file when you are finished.</p>

<p>The last part of configuring the firewall on your WireGuard Server is to allow traffic to and from the WireGuard UDP port itself. If you did not change the port in the server’s <code class="language-plaintext highlighter-rouge">/etc/wireguard/wg0.conf</code> file, the port that you will open is 51820. If you chose a different port when editing the configuration be sure to substitute it in the following UFW command.</p>

<blockquote>
  <p>Note: In my experience data centers might close irregular ports such as the default Wireguard port <code class="language-plaintext highlighter-rouge">51820</code> and I suggest you to choose a popular service port for your VPN connection. I usually prefer using database ports or streaming services ports that are working with data and high network traffic on these ports seems less suspicious. (i.e. MongoDB default port 27017)</p>
</blockquote>

<p>In case you forgot to open the SSH port when following the prerequisite tutorial, add it here too:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ufw allow 51820/udp <span class="c"># The chosen VPN server port (you can change it to what ever you want)</span>
<span class="gp">$</span><span class="w"> </span>ufw allow OpenSSH   <span class="c"># To be able to connect the server using openSSH trough port 22</span>
</code></pre></div></div>

<blockquote>
  <p>Note: If you are using a different firewall or have customized your UFW configuration, you may need to add additional firewall rules. For example, if you decide to tunnel all of your network traffic over the VPN connection, you will need to ensure that port 53 traffic is allowed for DNS requests, and ports like 80 and 443 for HTTP and HTTPS traffic respectively. If there are other protocols that you are using over the VPN then you will need to add rules for them as well.</p>
</blockquote>

<p>After adding those rules, disable and re-enable UFW to restart it and load the changes from all of the files you’ve modified:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ufw disable
<span class="gp">$</span><span class="w"> </span>ufw <span class="nb">enable</span>
</code></pre></div></div>

<p>You can confirm the rules are in place by running the ufw status command. Run it, and you should receive output like the following:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ufw status
</code></pre></div></div>
<pre><code class="language-output">Status: active

To                         Action      From
--                         ------      ----
51280/udp                  ALLOW       Anywhere                  
22/tcp                     ALLOW       Anywhere                  
51280/udp (v6)             ALLOW       Anywhere (v6)             
22/tcp (v6)                ALLOW       Anywhere (v6)
</code></pre>

<p>Your WireGuard Server is now configured to correctly handle the VPN’s traffic, including forwarding and masquerading for peers. With the firewall rules in place, you can start the WireGuard service itself to listen for peer connections.</p>

<h2 id="33-starting-the-wireguard-server">3.3 Starting the WireGuard Server</h2>
<p>WireGuard can be configured to run as a systemd service using its built-in wg-quick script. While you could manually use the wg command to create the tunnel every time you want to use the VPN, doing so is a manual process that becomes repetitive and error prone. Instead, you can use systemctl to manage the tunnel with the help of the wg-quick script.</p>

<p>Using a systemd service means that you can configure WireGuard to start up at boot so that you can connect to your VPN at any time as long as the server is running. To do this, enable the wg-quick service for the wg0 tunnel that you’ve defined by adding it to systemctl:</p>
<div class="language-terminal highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>systemctl <span class="nb">enable </span>wg-quick@wg0
</code></pre></div></div>
<p>Now start the service:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>systemctl start wg-quick@wg0
</code></pre></div></div>
<p>Double check that the WireGuard service is active with the following command. You should see active (running) in the output:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>systemctl status wg-quick@wg0.service
</code></pre></div></div>
<pre><code class="language-output">● wg-quick@wg0.service - WireGuard via wg-quick(8) for wg0
     Loaded: loaded (/lib/systemd/system/wg-quick@.service; enabled; vendor preset: enabled)
     Active: active (exited) since Wed 2021-08-25 15:24:14 UTC; 5s ago
       Docs: man:wg-quick(8)
             man:wg(8)
             https://www.wireguard.com/
             https://www.wireguard.com/quickstart/
             https://git.zx2c4.com/wireguard-tools/about/src/man/wg-quick.8
             https://git.zx2c4.com/wireguard-tools/about/src/man/wg.8
    Process: 3245 ExecStart=/usr/bin/wg-quick up wg0 (code=exited, status=0/SUCCESS)
   Main PID: 3245 (code=exited, status=0/SUCCESS)

Aug 25 15:24:14 wg0 wg-quick[3245]: [#] wg setconf wg0 /dev/fd/63
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip -4 address add 10.8.0.1/24 dev wg0
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip -6 address add fd0d:86fa:c3bc::1/64 dev wg0
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip link set mtu 1420 up dev wg0
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ufw route allow in on wg0 out on eth0
Aug 25 15:24:14 wg0 wg-quick[3279]: Rule added
Aug 25 15:24:14 wg0 wg-quick[3279]: Rule added (v6)
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip6tables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
Aug 25 15:24:14 wg0 systemd[1]: Finished WireGuard via wg-quick(8) for wg0.
</code></pre>

<p>The output shows the ip commands that are used to create the virtual wg0 device and assign it the IPv4 and IPv6 addresses that you added to the configuration file. You can use these rules to troubleshoot the tunnel, or with the wg command itself if you would like to try manually configuring the VPN interface.</p>

<p>With the server configured and running, the next step is to configure your client machine as a WireGuard Peer and connect to the WireGuard Server. Wireguard clients are available for almost every popular operating system such as Windows, Linux, Android, IOS, Mac OS, and many more. You can simply download the proper client and pass the client configuration file which you downloaded from wireguard-ui and connect to the server. (<a href="https://www.wireguard.com/install/"><strong>Download wireguard client</strong></a>)</p>

<blockquote>
  <p>Note: when ever you want to add more clients to the server, just run wireguard-ui and add your clients. After terminating the wireguard-ui, you have to restart the wireguard service using <code class="language-plaintext highlighter-rouge">systemctl restart wg-quick@wg0</code>. If you didn’t add Post and Pre Scripts to the wireguard config file like the previous section, you have to run iptables MASQUERADE rules again.</p>
</blockquote>

<h1 id="5-revers-proxy">5. Revers Proxy</h1>
<p>Congratulations, till now, you have configured a Virtual private network for your self but you might not be able to connect to the network directly in situations the government restricts users from connecting to the outside world as regards your outer VPN server is out there. To make your clients escape from the local intranet, you need a second machine inside a local data-centers which is connected to the public internet. That machine would be your middle server or the bridge to connect to the VPN server that you have configured previously. One simple solution to use this middle server as a bridge is setting a proxy on that middle server which redirects our requests to the target VPN server. In computer networking, a proxy server is a server application that acts as an intermediary between a client requesting a resource and the server providing that resource(<a href="https://en.wikipedia.org/wiki/Proxy_server">Wikipedia</a>).</p>

<h2 id="51-nginx-reverse-proxy">5.1 Nginx Reverse Proxy</h2>
<p>Nginx is a popular web-server application that is used to deploy various web applications and it has so many capabilities. One of the configurations that you can set for Nginx is to redirect incoming requests to a specific address by setting proxy routes. As we know that WireGuard traffic is a stream of data and its UDP. So, we have to set a stream proxy route for our purpose.</p>
<div align="center">
    <img width="60%" src="/assets/images/posts/blog/vpn-setup/nginx-logo.png" />
</div>
<p><br /></p>

<p>This time, let’s connect to our middle server using ssh and after updating its packages, install Nginx on that machine.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>nginx <span class="nt">--yes</span>
</code></pre></div></div>

<p>After that, open Nginx configuration file from <code class="language-plaintext highlighter-rouge">/etc/nginx/nginx.conf</code> using vim or your preferred editor:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>vim /etc/nginx/nginx.conf
</code></pre></div></div>

<p>Then add a stream section at the end of that file and write your proxy config there:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>stream {
    server {
        listen 51820 udp;
        proxy_pass 77.222.67.140:51820;
    }
}
</code></pre></div></div>

<p>Save and exit when you are done. Restart nginx:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>service nginx restart
</code></pre></div></div>

<blockquote>
  <p>Note: In the config above, I opened 51820 port on my middle server and redirected incoming requests through this port to the target VPN server which we have wireguard installed. The first port number on the config <code class="language-plaintext highlighter-rouge">51820</code> is the port that I want to open on my middle server and the other one is the port I chose for my VPN server. You have to change these numbers if you chose something else.</p>
</blockquote>

<div align="center">
    <img src="/assets/images/posts/blog/vpn-setup/wg-client.png" />
</div>
<p><br /></p>

<p>Now your clients should be able to connect to the VPN server through the middle server by changing the <code class="language-plaintext highlighter-rouge">Endpoint</code> on their configuration.</p>

<pre><code class="language-txt">[Interface]
PrivateKey = [CLIENT_PRIVATE_KEY]
Address = 10.252.1.1/32
DNS = 1.1.1.1

[Peer]
PublicKey = [PUBLIC_KEY]
PresharedKey = [PRE_SHARED_KEY]
AllowedIPs = 0.0.0.0/0
Endpoint = 77.222.67.140:51820 --&gt; change this address to  YOUR_MIDDLE_SERVER_IP:51820
PersistentKeepalive = 15
</code></pre>

<p>After editing the config file on the client’s machines:</p>

<pre><code class="language-txt">[Interface]
PrivateKey = [CLIENT_PRIVATE_KEY]
Address = 10.252.1.1/32
DNS = 1.1.1.1

[Peer]
PublicKey = [PUBLIC_KEY]
PresharedKey = [PRE_SHARED_KEY]
AllowedIPs = 0.0.0.0/0
Endpoint = 192.168.0.1:51820
PersistentKeepalive = 15
</code></pre>

<h2 id="52-nginx-on-docker">5.2 Nginx on docker</h2>
<p>As the Nginx docker image is available on the docker hub, you can use the Nginx container instead of installing Nginx on a separate VM. You can run your proxy server on the cloud which is cheaper cost beneficial than renting a virtual machine. Also, some proxy managers are available on docker-hub with a web-based interface such as the popular <a href="https://nginxproxymanager.com/guide/#project-goal"><strong>nginx-proxy-manager</strong></a>.</p>
<div align="center">
    <img width="50%" src="/assets/images/posts/blog/vpn-setup/docker-logo.png" />
</div>
<p><br /></p>

<h1 id="6-wireguard-over-tcp-optional">6. WireGuard Over TCP (Optional)</h1>
<p>Wireguard itself is working only on UDP because it aims to be as fast as possible but, some providers may block UDP packets using their firewalls. This will make us some problems and prevents WireGuard to work properly. To tackle this issue, we have to convert UDP packets into TCP packets and transfer them through the network after delivering the packets to the VPN server, revert the TCP packets into UDP and pass them to the WireGuard service. This goal can be reached using <a href="http://www1.cs.columbia.edu/~lennox/udptunnel/"><strong>udptunnel</strong></a>. (<a href=""><strong>udp2raw</strong></a> is another popular UDP to TCP converter)</p>

<blockquote>
  <p>Note: Udptunnel does not support IPv6.</p>
</blockquote>

<p>Udptunnel is a simple application written in c and It should be run on two endpoints. On one end, it listens to incoming UDP packets on a specific port and converts them to TCP packets, then it transfers the TCP packet to the destination address which is running a udptunnel server on the other endpoint. In our case, the first endpoint is our middle server which is the local server inside the local intranet. Obviously, the second endpoint is our machine inside the outer world.</p>

<div align="center">
    <img src="/assets/images/posts/blog/vpn-setup/udp2raw.svg" />
</div>
<p><br /></p>

<p>Udptunnel can be run in two modes server mode and client mode. You have to run the first instance in client mode and the second one as the server. In server mode it listens for TCP packets and transfers them back into UDP and in client mode receives UDP packets and transfers them to TCP.</p>

<p>Let’s start with the server, the machine located in the open world. First, we have to download the source code of udptunnel:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>wget https://github.com/rfc1036/udptunnel/archive/refs/heads/master.zip
</code></pre></div></div>

<p>Then we have to build the source code using the build-essential <strong>make</strong> but before that, run the command below to be sure you have the required packages:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt <span class="nb">install </span>build-essential pkg-config zip unzip <span class="nt">-y</span>
</code></pre></div></div>

<p>Let’s unzip the downloaded source codes:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>unzip master.zip
</code></pre></div></div>

<p>And build the source files:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">cd </span>udptunnle-master
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>make
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>make <span class="nb">install</span> 
</code></pre></div></div>

<p>Now let’s pick a TCP port and open the port on the firewall (I chose port 8080):</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw allow 8080/tcp
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw disable
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw <span class="nb">enable</span>
</code></pre></div></div>

<p>Then run the udptunnel as server:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>udptunnel <span class="nt">--server</span> 0.0.0.0:8080 <span class="nt">--verbose</span> 127.0.0.1:51820
</code></pre></div></div>
<p>It listens to the incoming TCP packets from everywhere converts the into UDP and passes them through port 51820 on the localhost which is the WireGuard server port.</p>

<p>Now jump into the middle server and, download and build the udptunnel source codes:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>apt <span class="nb">install </span>build-essential pkg-config zip unzip <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span>wget https://github.com/rfc1036/udptunnel/archive/refs/heads/master.zip
<span class="gp">$</span><span class="w"> </span>unzip master.zip
<span class="gp">$</span><span class="w"> </span><span class="nb">cd </span>udptunnle-master
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>make
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>make <span class="nb">install</span> 
</code></pre></div></div>

<p>Pick a udp port, (I chose 8080 again!)</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw allow 8080
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw disable
<span class="gp">$</span><span class="w"> </span><span class="nb">sudo </span>ufw <span class="nb">enable</span>
</code></pre></div></div>

<p>And run the udptunnel client on the middle server:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ udptunnel  0.0.0.0:8080 77.222.67.140:8080
</code></pre></div></div>

<blockquote>
  <p>Note: In the code above, <code class="language-plaintext highlighter-rouge">77.222.67.140</code> was the outer machine’s address.</p>
</blockquote>

<p>That’s it, go change the endpoint address to the new UDP port on the middle server:</p>

<pre><code class="language-txt">[Interface]
PrivateKey = [CLIENT_PRIVATE_KEY]
Address = 10.252.1.1/32
DNS = 1.1.1.1

[Peer]
PublicKey = [PUBLIC_KEY]
PresharedKey = [PRE_SHARED_KEY]
AllowedIPs = 0.0.0.0/0
Endpoint = 192.168.0.1:51820 --&gt; change this address to  YOUR_MIDDLE_SERVER_IP:8080
PersistentKeepalive = 15
</code></pre>

<p>After editing the config file on the client’s machines:</p>

<pre><code class="language-txt">[Interface]
PrivateKey = [CLIENT_PRIVATE_KEY]
Address = 10.252.1.1/32
DNS = 1.1.1.1

[Peer]
PublicKey = [PUBLIC_KEY]
PresharedKey = [PRE_SHARED_KEY]
AllowedIPs = 0.0.0.0/0
Endpoint = 192.168.0.1:8080
PersistentKeepalive = 15
</code></pre>

<p>That’s it.</p>

<blockquote>
  <p>Note: udptunnel is not a background server which means you don’t have to exit the ssh sessions (on middle and outer servers) while running this application. You can build a systemctl daemon, use <a href="https://linuxhint.com/linux-screen-command-tutorial/">screen</a> or <a href="https://en.wikipedia.org/wiki/Tmux">tmux</a> for running this application to prevent crashing of udptunnel after closing the session.</p>
</blockquote>

<p>And remember using WireGuard over TCP will affect your connection speed/bandwidth but some networks block or reduce the bandwidth for UDP connections and we have no other choices but running wire guard over TCP. Here is my experience using WireGuard over TCP:</p>

<p align="center">
    <img src="/assets/images/posts/blog/vpn-setup/speed-test-udp-no-filter.png" />
    <br />
    <span>Bandwidth while using UDP and it's not restricted by government's firewall</span>
</p>

<p align="center">
    <img src="/assets/images/posts/blog/vpn-setup/speed-test-udp.png" />
    <br />
    <span>Bandwidth while using UDP and it's restricted by government's firewall</span>

</p>

<p align="center">
    <img src="/assets/images/posts/blog/vpn-setup/speed-test-tcp.png" />
    <br />
    <span>Bandwidth while using WireGuard over TCP</span>

</p>

<h1 id="7-final-words">7. Final words</h1>
<p>Some of you might have trouble using my solution for making your private network because of port choosing filtered port numbers. If things were not working change the chosen port numbers and try again. In some cases, government firewalls might block UDP packets and you need to do the solution on <a href="#6-wireguard-over-tcp-(optional)">part 6</a>.</p>

<p>The reverse proxy could be done using some simple firewall (iptables) rules but I chose Nginx to not be confused with iptables complexities and concepts.</p>

<p>WireGuard VPN server is the newest and best VPN protocol in the world till now, it is secure, fast, and easy to configure, and that’s why I chose this protocol to go within this article, but in extreme cases, it can be detected and your servers could be blocked.</p>

<p>To tackle this, keep the number of your clients as low as possible to prevent high network traffic from going through these servers. Also, you can use other VPN protocols using this abstract solution and find the one which works for you (such as <a href="https://shadowsocks.org/"><strong>Shadowsocks</strong></a>, <a href="https://getoutline.org/"><strong>Google Outline</strong></a>, <a href="https://openvpn.net/"><strong>OpenVPN</strong></a>, <a href="https://www.softether.org/"><strong>Softether</strong></a>, <a href="https://www.v2ray.com/"><strong>V2ray</strong></a>, etc.). If you have problems with this article reading the article’s references and a little search on DuckDuckGo (Or google) might help you to find the solution. I hope you find this article useful.</p>

<p>for a better world,<br />
Regards</p>

<h1 id="references">References</h1>
<ul>
  <li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-wireguard-on-ubuntu-20-04">How to set up wireguard on ubuntu 20.04 (LTS)</a></li>
  <li><a href="https://github.com/ngoduykhanh/wireguard-ui">Wireguard-ui</a></li>
  <li><a href="https://ericiniguez.com/p/wireguard-vpn-and-nginx-reverse-proxy/">Wireguard vpn and nginx reverse proxy</a></li>
  <li><a href="https://nginxproxymanager.com/guide/#project-goal">Nginx proxy manager</a></li>
  <li><a href="https://www.oilandfish.com/posts/wireguard-udptunnel.html">WireGuard + udptunnel</a></li>
</ul>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="network" /><category term="vpn" /><summary type="html"><![CDATA[1. Intro]]></summary></entry><entry><title type="html">What is an AutoEncoder?</title><link href="http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/09/16/auto-encoder.html" rel="alternate" type="text/html" title="What is an AutoEncoder?" /><published>2022-09-16T13:21:13+04:30</published><updated>2022-09-16T13:21:13+04:30</updated><id>http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/09/16/auto-encoder</id><content type="html" xml:base="http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/09/16/auto-encoder.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>AutoEncoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.
AutoEncoder, by design, reduces data dimensions by learning how to ignore the noise in the data.
Here is an example of the input/output image from the MNIST dataset to an AutoEncoder.</p>

<p align="center">
  <img src="/assets/images/posts/blog/auto-encoder/ae-arch.jpeg" />
    <br />
    <span>a simple AutoEncoder</span>
</p>

<h2 id="11-autoencoder-components">1.1 AutoEncoder Components:</h2>
<p>Autoencoders consists of 4 main parts:</p>
<ol>
  <li>
    <p><strong>Encoder</strong>: In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.</p>
  </li>
  <li>
    <p><strong>Bottleneck</strong>: which is the layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data.</p>
  </li>
  <li>
    <p><strong>Decoder</strong>: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.</p>
  </li>
  <li>
    <p><strong>Reconstruction Loss</strong>: This is the method that measures measure how well the decoder is performing and how close the output is to the original input.</p>
  </li>
</ol>

<p>The training then involves using back propagation in order to minimize the network’s reconstruction loss. You must be wondering why would I train a neural network just to output an image or data that is exactly the same as the input! This article will cover the most common use cases for Autoencoder. Let’s get started:</p>

\[Loss = \lVert X - \hat{X} \rVert_{2}^{2}\]

<h2 id="12-problem-statement">1.2 Problem statement:</h2>
<p>The network architecture for AutoEncoders can vary between a simple FeedForward network, LSTM network or Convolutional Neural Network depending on the use case. This article will use CNN networks to solve a simple problem. The problem is to remove an annoying text from the given picture. You might have seen that many photographic websites or some famous photographers use some texts as a sign or a signature on their images. That would prevent other people from stealing their valuable artistic photos, paintings, etc.</p>

<p>For example here is a sample photo taken by my psychologist friend Reza Parizi (<a href="https://www.instagram.com/reza__parizi/">reza__parizi</a>):</p>

<p align="center">
  <img width="70%" src="/assets/images/posts/blog/auto-encoder/reza-parizi.jpg" />
</p>

<p>We can consider these kinds of texts which may be known by the name <a href="https://en.wikipedia.org/wiki/Watermark"><strong>watermark</strong></a> as static noise in pictures. We can try to find a way or a set of filters to be applied to that image in order to remove that artifact. One of the main use cases of AutoEncoders is denoising, so let’s solve this problem using AutoEncoders.</p>

<h1 id="2-preparing-the-data">2. Preparing the data:</h1>
<p>As you know for deep learning models the first thing we need is the data. For this problem, I used the popular <a href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html"><strong>Stanford cars</strong></a> dataset and I added the static text “Hot-Tube” to the images as the signature of the image. Let’s say that the data is stored in a directory named <code class="language-plaintext highlighter-rouge">datasets/car</code> and the training data is located inside another directory called <code class="language-plaintext highlighter-rouge">train</code>. First, we import all required modules:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">keras.layers</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">cv2</span>
</code></pre></div></div>

<p>Then we have to load the dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path_to_train_imgs</span> <span class="o">=</span> <span class="s">'./datasets/cars/train'</span>
<span class="n">train_imgs_list</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_to_train_imgs</span><span class="p">)</span>
<span class="n">train_imgs_list</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">path_to_train_imgs</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">train_imgs_list</span><span class="p">]</span>
</code></pre></div></div>
<p>These images are the original images which considered the ground truth. To generate the input data we have 2 ways:</p>
<ol>
  <li>load all data into the memory and loop throw them adding the signature text.</li>
  <li>Write a DataGenerator which adds the signature to each image while creating the batch.</li>
</ol>

<p>The first method is not always a good option, especially while working with images. because image data volumes are regularly high, loading this amount of data into the memory will cause the Out of memory problem and lead your programs to crash.</p>

<p>DataGenerators will load only that part of the data which is needed for the training on each period of time and it prevents the out-of-memory problem. After knowing the need for DataGenerators let’s write a DataGenerator for our program.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">Sequence</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">image_list</span> <span class="o">=</span> <span class="n">image_list</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">on_epoch_end</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">load_img</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">img</span>
        
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image_list</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">shuffle</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">indexes</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image_list</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span>
    
    <span class="k">def</span> <span class="nf">add_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cv2</span><span class="p">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'Hot-Tube'</span><span class="p">,</span> <span class="n">org</span><span class="o">=</span><span class="p">(</span><span class="mi">46</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">fontFace</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="n">fontScale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">indexes</span><span class="p">[</span><span class="n">index</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">img_paths</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">image_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indexes</span><span class="p">]</span>
        
        <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="n">img_paths</span><span class="p">]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">add_text</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">))</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
</code></pre></div></div>
<p>Let’s see how it works:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plt_img</span><span class="p">(</span><span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="p">,</span> <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

<span class="n">validation_imgs</span><span class="p">,</span> <span class="n">train_imgs</span> <span class="o">=</span> <span class="n">train_imgs_list</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">train_imgs_list</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span>
<span class="n">train_data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">image_list</span><span class="o">=</span><span class="n">train_imgs</span><span class="p">)</span>
<span class="n">validation_data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">image_list</span><span class="o">=</span><span class="n">validation_imgs</span><span class="p">)</span>

<span class="c1"># Showing some sample images
</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">validation_data_generator</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">cnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
    <span class="n">plt_img</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s">"Original Image"</span><span class="p">)</span>
    <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
    <span class="n">plt_img</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s">"Augmented Image"</span><span class="p">)</span>
    <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p align="center">
  <img width="70%" src="/assets/images/posts/blog/auto-encoder/sample_data.png" />
</p>

<h1 id="3-building-the-model">3. Building the model</h1>

<p>Let’s say that we have trained an autoencoder on the Cars dataset. Using a simple FeedForward neural network, we can achieve this by building a simple 9 layers network as below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Input</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 128x128
</span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"bottle-neck"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 128*128
</span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">UpSampling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 256x256
</span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">"mean_squared_error"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<pre><code class="language-output">Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 256, 256, 3)]     0         
                                                                 
 conv2d_2 (Conv2D)           (None, 256, 256, 32)      896       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         
 )                                                               
                                                                 
 bottle-neck (Conv2D)        (None, 128, 128, 8)       2312      
                                                                 
 up_sampling2d (UpSampling2D  (None, 256, 256, 8)      0         
 )                                                               
                                                                 
 conv2d_3 (Conv2D)           (None, 256, 256, 32)      2336      
                                                                 
 conv2d_4 (Conv2D)           (None, 256, 256, 64)      18496     
                                                                 
 conv2d_5 (Conv2D)           (None, 256, 256, 128)     73856     
                                                                 
 conv2d_6 (Conv2D)           (None, 256, 256, 3)       387       
                                                                 
=================================================================
Total params: 98,283
Trainable params: 98,283
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<p>I used mean squared error (MSE) loss to train my model. Because I wanted the model’s output to be the same as the original image. MSE should do the job for us perfectly but, we could use a different loss function that would compare the images from a regional point of view and would be better for high-resolution images and more general datasets. But, we are good with MSE on this task.</p>

<h2 id="31-tensorboard">3.1 Tensorboard</h2>
<p>To see how the training process is going on and monitor the training process, there is a useful option called Tensorboard developed by the TensorFlow team. Tensorboard is a background process that looks inside a directory (usually named “logs”) and visualizes the training process logs such as training and validation accuracy and loss for us. It also is capable to display images that can be generated during the training process such as model predictions at the end of each epoch. It would be so handy to store the model prediction during the training process. It could help us to find out when to terminate the training process in an experimental way.</p>

<p>To do so, we have to define a custom callback class to store model prediction on each epoch ended.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TensorBoardImageCallBack</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">noisy_image</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">noisy_image</span> <span class="o">=</span> <span class="n">noisy_image</span>

    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">filename_suffix</span><span class="o">=</span><span class="s">'images'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">write_image</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">noisy_image</span><span class="p">,</span> <span class="s">'Noisy Image'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">write_image</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image</span><span class="p">,</span> <span class="s">'Original Image'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">write_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="n">image_to_write</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">image</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">image_to_write</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="n">denoised_image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">noisy_image</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">write_image</span><span class="p">(</span><span class="n">denoised_image</span><span class="p">,</span> <span class="s">'Denoised Image'</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        
<span class="n">tensorboard_callback</span> <span class="o">=</span> <span class="n">TensorBoardImageCallBack</span><span class="p">(</span><span class="s">'./logs'</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">tensorboard_callback_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s">"./logs"</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="32-training-the-model">3.2 Training the model</h2>
<p>Now, it’s time to start training our model. I just hangup training the model after 25 epochs but, in code, I’ve defined the number of epochs to be 100. I hope continuing the training till 100 epochs will tend to a great convergence of the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">train_data_generator</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data_generator</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tensorboard_callback</span><span class="p">,</span> <span class="n">tensorboard_callback_loss</span><span class="p">]</span>
        <span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-output">...
502/502 [==============================] - 86s 171ms/step - loss: 6.6057e-04 - accuracy: 0.8184 - val_loss: 5.3678e-04 - val_accuracy: 0.8163
</code></pre>

<p>As you can see in the output, which is the results of training for about 25 epochs, the last reconstruction loss/error for the validation set is 5.3678e-04 which is great but it can be better if you run this code for about 100 epochs. Now, if I pass a new image from the test dataset, the reconstruction loss will be very low BUT if I tried to pass any other different image (outlier or anomaly), we will get a high reconstruction loss value because the network failed to reconstruct the image/input that is considered an anomaly, which is another use case of autoencoders to detect outlier data points.</p>

<p align="center">
  <img width="70%" src="/assets/images/posts/blog/auto-encoder/sample_prediction.png" />
</p>

<p>Notice in the code above, you can use only the encoder part to compress some data or images and you can also only use the decoder part to decompress the data by loading the decoder layers. As you can see, we reduced the input image dimensions from \(256 \times 256 \times 3\) to \(128 \times 128 \times 8\) which is accessible in the bottle-neck layer’s output. storing the features of this layer instead of the original images lowers the space needed to store the images by a factor of 1.5. If it was a video of size 900MB, using this technique would lead the size of the video to be 600MB which is more efficient for data storage.</p>

\[\frac{256 \times 256 \times 3}{128 \times 128 \times 8} = 1.5\]

<p align="center">
  <img class="img-light-bg" src="/assets/images/posts/blog/auto-encoder/loss.png" />
  <br />
  <span>Model loss per epoch</span>
</p>

<blockquote>
  <p>Note: In the figure above, red is validation loss and the blue one is training loss per epoch.</p>
</blockquote>

<p>Another use case of AutoEncoders is learning a data representation in lower dimensions which tends to data compression. Another cool use case is to enhance the quality of the picture which is called super-resolution which we can’t see on our model but I’ll do an experiment to implement super-resolution using AutoEncoders in another article.</p>

<p>Finally, we removed a static noise from the input data which is another use case of auto encoders we were follow.
I hope you enjoyed reading my article. Stay tuned!</p>

<h1 id="references">References</h1>
<ol>
  <li><a href="https://paperswithcode.com/method/autoencoder"><em>G. E. Hinton, &amp; R. R. Salakhutdinov (2006). Reducing the Dimensionality of Data with Neural Networks. Science, 313(5786), 504-507.</em></a></li>
</ol>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><summary type="html"><![CDATA[1. Intro AutoEncoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible. AutoEncoder, by design, reduces data dimensions by learning how to ignore the noise in the data. Here is an example of the input/output image from the MNIST dataset to an AutoEncoder.]]></summary></entry><entry><title type="html">The Poisson Distribution</title><link href="http://localhost:4000/blog/math/statistics/random-process/2022/07/14/the-poisson-distribution.html" rel="alternate" type="text/html" title="The Poisson Distribution" /><published>2022-07-14T12:32:35+04:30</published><updated>2022-07-14T12:32:35+04:30</updated><id>http://localhost:4000/blog/math/statistics/random-process/2022/07/14/the-poisson-distribution</id><content type="html" xml:base="http://localhost:4000/blog/math/statistics/random-process/2022/07/14/the-poisson-distribution.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>Knowing statistics for a computer engineer, a data scientist, or a machine-learning engineer is a unique need in their professional career. We learn about statistics in most universities more like learning differential equations or calculus instead. We know so many mathematical basics for statistics that we will never use in the future. That prevents us from seeing the use of statistics and what we can do with these concepts in the real world.</p>

<p>In this article, we are about to learn two crucial statistics concepts, The Poisson Distribution and The Poisson Process, through solving a common problem in the concept of online website hosting.</p>

<h1 id="2-what-poisson-distribution-or-poisson-process-is-about">2. What Poisson Distribution or Poisson Process is about?</h1>
<p>Before we get started, let’s first ask our selves a simple question, “Why do we need Poisson?”</p>

<p>The Poisson distribution helps us to o predict the probability of a given number of events occurring in a fixed interval of time, or just simply, to predict the number of events in the future.</p>

<p>For example,</p>
<ul>
  <li>How many visitors do you get on your website in a day?</li>
  <li>How many clicks do your ads get for the next month?</li>
  <li>How many phone calls do you get during your shift?</li>
  <li>How many people will die from covid-19 next year?</li>
</ul>

<p>Every week, on average, 17 people react to my blog posts via sending me emails. I’d like to predict the number of people who react to my blog posts next week because I have to consider some free time to answer them properly and planning is so critical for me.</p>

<p>What is the probability that exactly 20 people (or 10, 30, 40, etc.) will react to my posts next week?</p>

<p>To answer this question, if we knew some statistics, it would comes my our minds that we should be able to solve this problem using <strong>the Binomial distribution</strong>. Let’s first, look at the concept of Binomial distribution and solve the problem using it.</p>

<h1 id="3-binomial-distribution">3. Binomial distribution</h1>
<p>One way to solve this should be to start with the number of reads. Each person who reads the blog has some probability that they will really have a question or found some thing interesting to share with me.</p>

<p>A binomial random variable is the number of successes \(x\) in \(n\) repeated trials. And we assume the probability of success \(p\) is constant over each trial. The Binomial distribution formula is:
\begin{equation}
P[X=x] = \binom{n}{x}p^x(1-p)^{n-x}
\end{equation}</p>

<p>However here, we are given only one piece of information, \(17 \frac{emails}{week}\), which is a rate. we don’t know any thing about the probability of receiving an email by an individual reader p, nor the number of blog visitors n. So, we use google analytics to retrieve this data from our blog history.</p>

<p align="center"> <img src="/assets/images/posts/blog/poisson/website-stats.png" /><br /><span>Stats from google</span></p>

<p>By looking to the stats we can say, in one year, A total of \(59k\) people read my blog. Out of \(59k\) people, \(888\) of them liked my post. Therefore, the number of people who read my blog per week (\(n\)) is \(\frac{59k}{52}=1134\). The number of people who liked my posts per week (\(x\)) is \(\frac{888}{52}=17\). So, the success probability p would be \(\frac{888}{59k} = 0.015\) or \(1.5\%\).</p>

<p>Now Using Binomial PMF, we should be able to calculate the probability of getting 20 emails for next week as below:</p>

\[P[X=20] = \binom{1134}{20}(0.015)^{20}(1-0.015)^{n-x} = 0.06962\]

<p>We can use python or any other programming language to calculate the probability of getting emails with different values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>
<span class="c1"># setting the values
# of n, p and x
</span><span class="n">n</span> <span class="o">=</span> <span class="mi">1134</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.015</span>
<span class="n">x_s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"x</span><span class="se">\t</span><span class="s">Binomial P(x, n, p)"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"----------------------------"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_s</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s">:</span><span class="se">\t</span><span class="si">{</span><span class="n">binom</span><span class="p">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-output">x	Binomial P(x, n, p)
----------------------------
10:	0.022507172903122208
17:	0.09701415708780352
20:	0.06962037106916726
30:	0.0012106250995813465
40:	6.815731666708672e-07
</code></pre>

<p>As you can see, by using binomial distribution the probability of getting, 10, 17, 20, 30 and 40 emails per week would be as follows:</p>

<table>
  <thead>
    <tr>
      <th>x</th>
      <th style="text-align: center">Binomial P(X=x)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td style="text-align: center">0.02250</td>
    </tr>
    <tr>
      <td>17</td>
      <td style="text-align: center">0.09701</td>
    </tr>
    <tr>
      <td>20</td>
      <td style="text-align: center">0.06962</td>
    </tr>
    <tr>
      <td>30</td>
      <td style="text-align: center">0.00121</td>
    </tr>
    <tr>
      <td>40</td>
      <td style="text-align: center">&lt; 0.000001</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h1 id="4-shortcomings-of-the-binomial-distribution">4. Shortcomings of the Binomial Distribution</h1>

<p>The very first problem with a binomial random variable is, “<strong>it being assumed to be binary (0 or 1)</strong>”. In the previous example, we have \(17 \frac{emails}{week}\). This means \(\frac{17}{7}=2.4\) people will send me emails per day, and \(\frac{17}{7*24}\) = 0.1 people send me email per hour.
If we model the success probability by hour (0.1 email/hr) using binomial random variable, this means most of the hours get zero emails but some hours will get exactly 1 email. However, it is also very possible that certain hours will get more that 1 email (2,3,5 emails, etc.)
The problem with binomial is that it cannot contain more than 1 event in the unit of time (in this case, 1 hr is the unit time). The unit of time can only have 0 or 1 event.</p>

<p>How about dividing 1 hour into 60 minutes, and make unit time smaller, for example, a minute? If that so, then 1 hour can contain multiple events (Still, one minute will contain exactly one or zero events.). What if, during that one minute, we got multiple emails? (i.e someone shared your my blog post on Twitter and the traffic spiked at that minute.) Then what? We can divide a minute into seconds. then our time unit becomes a second and again a minute can contain multiple events. But this binary container problem will always exist for ever-smaller time units. The idea is, we can make the binomial random variable handle multiple events by dividing a unit time into smaller units. By using smaller divisions, we can make the original unit time contain more than one event. Mathematically, this means \(n\) goes to infinity. Since we assumed the rate is fixed, \(p\) must goes to zero. Because, when $n$ grows up to infinity,the number of intervals between the period becomes grows as $n$ and the probability of getting an email at each interval tends to be merely zero. In the other words, If $n$ goes to infinity, \(p\) should become zero, Other wise, \(np\), which is the number of events will blow up.</p>

<p>The second problem with the binomial random variable is, “<strong>when we want to use the binomial distribution, the number of trails, \(n\), and the probability of success, \(p\), should be known</strong>”.
If you use Binomial, you cannot calculate the success probability only with the rate (i.e \(17\frac{emails}{week}\)). You need more information \(n\) and \(p\), in order to use the binomial PMF.
The Poisson Distribution, on the other hand, doesn’t require you to know \(n\) or \(p\). We are assuming \(n\) is infinitely large (\(n\rightarrow\infty\)) and \(p\) is infinitesimal (\(p\rightarrow 0\)).
The only parameter of the Poisson distribution is the rate \(\lambda\). (In real life only knowing the rate is much more common than knowing both \(n\) and \(p\))</p>

<h1 id="5-derive-the-poisson-formula-mathematically">5. Derive the poisson formula mathematically</h1>
<p>Now, let’s deep dive into the binomial distribution formula with the assumption that we reached from the ideas of the previous section (<a href="#4-shortcomings-of-the-binomial-distribution">Section 4</a>). We find out that to solve the deal with the binary nature of the binomial random variable, we should increase the number of time units in our one week interval. Mathematically it means \(n\rightarrow\infty\):</p>

\[P[X=x] = lim_{n\rightarrow\infty}\binom{n}{x}p^x(1-p)^{n-x}\]

<p>If, \(n\rightarrow\infty\) and \(p\rightarrow 0\) then we can assume that:</p>

\[p = \frac{\lambda}{n}\]

<p>Then we have:</p>

\[P[X=x] = lim_{n\rightarrow\infty}\binom{n}{x}(\frac{λ}{n})^x(1- (\frac{λ}{n}))^{n-x}\]

\[\Rightarrow lim_{n\rightarrow\infty} \frac{n!}{(n-x)!x!}(\frac{λ}{n})^x(1- (\frac{λ}{n}))^{n-x}\]

\[\Rightarrow lim_{n\rightarrow\infty} \frac{n!}{(n-x)!}\frac{1}{n^x}\frac{λ^x}{x!}(1-\frac{λ}{n})^n(1-\frac{λ}{n})^{-x}\]

\[\Rightarrow lim_{n\rightarrow\infty} \frac{n!}{(n-x)!}\frac{1}{n^x}\frac{λ^x}{x!}e^{-λ}(1)\]

<p>Because:</p>

\[lim_{n\rightarrow\infty}\frac{n!}{(n-x)!}\frac{1}{n^x} = 1\]

<p>We can say:</p>

<p>\begin{equation}
P[X=x] = e^{-λ}\frac{λ^{x}}{x!}
\end{equation}</p>

<p>Which is actually the Poisson random distribution formula.</p>

<h1 id="6-probability-of-events-for-a-poisson-distribution">6. Probability of events for a Poisson distribution</h1>

<p>An event can occur 0, 1, 2, … times in an interval. The average number of events in an interval is designated λ. λ is the event rate. also called the rate parameter. The probability of observing k events in an interval is given by the equation:</p>

\[P[k\ events\ in\ interval] = e^{-λ}\frac{λ^{k}}{k!}\]

<p>Where:</p>
<ul>
  <li>\(\lambda\) is the average number of events per interval</li>
  <li>\(e\) is the number \(2.71828…\) (Euler’s number) the base of the natural logarithm</li>
  <li>\(k\) takes values \(0, 1, 2, …\)</li>
  <li>\(k! = k(k-1)(k-2)…(2)(1)\) is the factorial of \(k\)</li>
</ul>

<p>We calculate the probability of observing 10, 17, 20, 30 and 40 emails in the interval using the poisson distribution formula as below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">poisson</span>

<span class="c1">#calculate probability
</span>
<span class="c1"># setting the values
# of lambda and x
</span><span class="n">l</span> <span class="o">=</span> <span class="mi">17</span>
<span class="n">x_s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"x</span><span class="se">\t</span><span class="s">Poisson P(x, lambda)"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"----------------------------"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_s</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s">:</span><span class="se">\t</span><span class="si">{</span><span class="n">poisson</span><span class="p">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">l</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<pre><code class="language-output">x	Poisson P(x, lambda)
----------------------------
10:	0.022999584406166312
17:	0.09628462779844556
20:	0.06915882695522822
30:	0.001278796308921649
40:	8.381188233781985e-07
</code></pre>

<p>As it can be observed, using the calculated probabilities using Poisson formula is very close to the values calculated using Binomial distribution formula, so we can conclude that the Poisson distribution in this situation is a really good approximation for our problem. Because of the simpler formula and lower and easy to obtain parameter of the poisson distribution, it would be come very useful to use this distribution to solve the problems of this kind.</p>

<table>
  <thead>
    <tr>
      <th>x</th>
      <th style="text-align: center">Binomial P(X=x)</th>
      <th style="text-align: center">Poisson P(X=x;lambda=17)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td style="text-align: center">0.02250</td>
      <td style="text-align: center">0.2300</td>
    </tr>
    <tr>
      <td>17</td>
      <td style="text-align: center">0.09701</td>
      <td style="text-align: center">0.09628</td>
    </tr>
    <tr>
      <td>20</td>
      <td style="text-align: center">0.06962</td>
      <td style="text-align: center">0.07595</td>
    </tr>
    <tr>
      <td>30</td>
      <td style="text-align: center">0.00121</td>
      <td style="text-align: center">0.00340</td>
    </tr>
    <tr>
      <td>40</td>
      <td style="text-align: center">&lt; 0.000001</td>
      <td style="text-align: center">&lt; 0.000001</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h1 id="7-some-notes-on-poisson-random-variable">7. Some notes on Poisson random variable</h1>
<p>Even though the Poisson distribution models are rare events, the rate \(\lambda\) can me any number. It doesn’t always have to be small. The Poisson Distribution is asymmetric, it is always skewed toward the right. Because it is inhibited by the zero occurrence barrier (there is no such thing as minus one email) on the left and it is unlimited on the other side. As \(\lambda\) becomes bigger, the graph looks more like a normal distribution.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">poisson</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">x_s</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">plots</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mus</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>

<span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="n">mus</span><span class="p">:</span>
  <span class="n">y_s</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_s</span><span class="p">:</span>
    <span class="n">y_s</span> <span class="o">+=</span> <span class="p">[</span><span class="n">poisson</span><span class="p">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)]</span>
  <span class="n">plots</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">x_s</span><span class="p">,</span> <span class="n">y_s</span><span class="p">)]</span>


<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">plots</span><span class="p">)):</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plots</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">plots</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">"lambda = </span><span class="si">{</span><span class="n">mus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p align="center"><img src="/assets/images/posts/blog/poisson/different-lambda.png" /><br /><span>Poisson distribution with different lambda's for our problem.</span></p>

<p><strong>The average rate of events per unit time in poisson distribution is constant</strong>. This means the number of people who visit my blog per hour might not follow a Poisson Distribution, because the hourly rate is not constant (higher rate during the daytime, lower rate during the night-time). Using monthly rate for consumer/biological data would be just an approximation as well, since the seasonality effect is non-trivial in that domain.</p>

<p><strong>In poisson random variable, Events are independent</strong>. The arrival of my blog visitors might not always be independent. For example, sometimes a large number of visitors come in a group because someone popular mentioned my blog, or my blog got featured on Medium’s first page, etc. the number of earthquakes per year in a country also might not follow a Poisson Distribution in one large earthquake increases the probability of aftershocks.</p>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="math" /><category term="statistics" /><category term="random-process" /><summary type="html"><![CDATA[1. Intro Knowing statistics for a computer engineer, a data scientist, or a machine-learning engineer is a unique need in their professional career. We learn about statistics in most universities more like learning differential equations or calculus instead. We know so many mathematical basics for statistics that we will never use in the future. That prevents us from seeing the use of statistics and what we can do with these concepts in the real world.]]></summary></entry></feed>