<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-09-30T16:20:24+03:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">mralinp</title><subtitle>My awesome blog</subtitle><entry><title type="html">How to bypass the ‘Islamic Republic’ internet filtering?</title><link href="http://localhost:4000/project/network/security/vpn/2022/09/26/bypass-islamic-republic.html" rel="alternate" type="text/html" title="How to bypass the ‘Islamic Republic’ internet filtering?" /><published>2022-09-26T17:50:22+03:30</published><updated>2022-09-26T17:50:22+03:30</updated><id>http://localhost:4000/project/network/security/vpn/2022/09/26/bypass-islamic-republic</id><content type="html" xml:base="http://localhost:4000/project/network/security/vpn/2022/09/26/bypass-islamic-republic.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>

<p>Some days, we hear some stories around the world that governments argue with people about some wrong laws, opaque decisions, bad economic environment, financial corruption, and many other reasons. To control the situation, one of their solutions is to disconnect people from the world by forcing ISPs and top-tier provider companies to shut down their internet connections. Some of these countries are China, North Korea, And the Islamic Republic Of Iran. The people living in these countries may do their jobs with the internet and in other words, their life has a direct relation with the connectivity to online services. In this situation, some necessary jobs that are in scathe are Developers, online shops, reporters, and many more. As a developer, I can’t live without the internet and my professional life is mixed with this technology. So I have to solve this problem by myself and in this case, I can’t accept the government’s politics. Let’s begin.</p>

<h1 id="2-what-is-the-solution">2. What is the solution</h1>
<p>How can we access the outside world? to access the outside world, we need to access a machine that is connected to the internet. We can access the world through that machine. In these situations, governments wouldn’t disconnect data centers from the internet because some bad things can happen to their servers and their companies will be at huge risk, especially in terms of security. So we can conclude that data centers that are inside the country are still connected to the internet and can access the outside world.</p>

<p>If we could successfully be connected to the world via a machine in the local data center, there still would be a problem for our freedom, <strong>cruel sanctions of the united states</strong>, which prevent these poor people to access services and contents which is accessible by other people in the world. To tackle this problem, we need a second machine which is in another country and is accessible through the internet. We have to send our packets using that second machine to be fully free. To do so, we need to make a <strong>virtual private network</strong>(VPN).</p>

<h2 id="21-virtual-private-network-vpn">2.1 Virtual Private Network (VPN)</h2>
<p>A virtual private network extends a private network across a public network and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network. The benefits of a VPN include increases in functionality, security, and management of the private network.</p>

<div align="center">
    <img width="70%" src="/assets/images/blog/vpn-setup/vpn-schema.png" />
</div>
<p><br /></p>

<p>It provides access to resources that are inaccessible on the public network and is typically used for remote workers. Encryption is common, although not an inherent part of a VPN connection. A VPN is created by establishing a virtual point-to-point connection through the use of dedicated circuits or with tunneling protocols over existing networks. A VPN available from the public Internet can provide some of the benefits of a wide area network. From a user perspective, the resources available within the private network can be accessed remotely (<a href="https://en.wikipedia.org/wiki/Virtual_private_network">Wikipedia</a>).</p>

<h1 id="3-running-a-wireguard-vpn-server-on-ubuntu-2004-lts">3. Running a WireGuard VPN server on Ubuntu 20.04 (LTS)</h1>
<p>WireGuard is a communication protocol and free and open-source software that implements encrypted virtual private networks, and was designed with the goals of ease of use, high speed performance, and low attack surface. It aims for better performance and more power than IPsec and OpenVPN, two common tunneling protocols (<a href="https://en.wikipedia.org/wiki/WireGuard">Wikipedia</a>).</p>

<div align="center">
    <img width="25%" src="/assets/images/blog/vpn-setup/wg-logo.png" />
</div>

<p>For this tutorial, I choose Wireguard as the VPN protocol of this article. Installation and configuration of the Wireguard VPN server are quite simple and easy to understand for those who are not quite familiar with some concepts of networking in Linux, in comparison with other protocols such as OpenVPN.</p>

<p>To get started, you need a Virtual Machine(VM) accessible through the internet via SSH. Let’s assume my VM IP address is <code class="language-plaintext highlighter-rouge">77.222.67.140</code>, I can connect to that VM using SSH as below:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ssh root@77.222.67.140
</code></pre></div></div>

<p>After running the command above, it asks you to type “yes” if you trust this host, just type “<code class="language-plaintext highlighter-rouge">yes</code>” and don’t ask why. Then you have to enter the VM password.
The first thing you do after connecting to the virtual machine is updating operating system packages to the latest available version using <code class="language-plaintext highlighter-rouge">Aptitude Package Manager</code>(apt):</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt update <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span>apt upgrade <span class="nt">--yes</span>
</code></pre></div></div>

<blockquote>
  <p>Note: It’s recommended that you reboot and reconnect to the VM after upgrading its packages.</p>
</blockquote>

<p>Now we have to install <code class="language-plaintext highlighter-rouge">wireguard</code> and <code class="language-plaintext highlighter-rouge">wireguard-tools</code> using apt:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>wireguard <span class="nt">--yes</span>
<span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>wireguard-tools <span class="nt">--yes</span>
</code></pre></div></div>

<p>This should install the Wireguard kernel module and the necessary tools for running our VPN server. If you would like to route your WireGuard Peer’s Internet traffic through the WireGuard Server then you will need to configure IP forwarding. To configure forwarding, open the <code class="language-plaintext highlighter-rouge">/etc/sysctl.conf</code> file using vim or your preferred editor:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>vim /etc/sysctl.conf 
</code></pre></div></div>

<p>Then you have to look for a line containing <code class="language-plaintext highlighter-rouge">net.ipv4.ip_forward=1</code> and uncomment that line (remove leading <code class="language-plaintext highlighter-rouge">#</code>) Or, you can just add this text at the end of <code class="language-plaintext highlighter-rouge">sysctl.conf</code> file. If you are using IPv6 with WireGuard, uncomment/add line <code class="language-plaintext highlighter-rouge">net.ipv6.conf.all.forwarding=1</code>. If you are using both IPv4 and IPv6, ensure that you include both lines. Save and close the file when you are finished (if you were using vim press <code class="language-plaintext highlighter-rouge">ESC</code> then type <code class="language-plaintext highlighter-rouge">wq</code> and press <code class="language-plaintext highlighter-rouge">enter</code>). To read the file and load the new values for your current terminal session, run:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>sysctl <span class="nt">-p</span>
</code></pre></div></div>
<p>If you did it right, you have to see an output as below:</p>
<pre><code class="language-output">net.ipv6.conf.all.forwarding = 1
net.ipv4.ip_forward = 1
</code></pre>

<p>Now your WireGuard Server will be able to forward incoming traffic from the virtual VPN ethernet device to others on the server, and from there to the public Internet. Using this configuration will allow you to route all web traffic from your WireGuard Peer via your server’s IP address, and <strong>your client’s public IP address will be effectively hidden</strong>.</p>

<p>However, before traffic can be routed via your server correctly, you will need to configure some firewall rules. These rules will ensure that traffic to and from your WireGuard Server and Peers flows properly.</p>

<h2 id="31-wireguard-ui">3.1 Wireguard UI</h2>
<p><a href="https://github.com/ngoduykhanh/wireguard-ui"><strong>Wireguard UI</strong></a> is a web-based config generator for wireguard server. If you’ve seen the DigitalOcean tutorial for running WireGurad server on ubuntu 20.04 which i pasted some parts of their tutorial here(Or other popular tutorials), they use the command line to generate configurations for clients which is called <strong>adding peers</strong> for wireguard server. Using command line interface and using wireguard-tool is quite hard to manage clients if you are making a network for co-workers, family or friends. Wireguard-ui is a web-based interface to generate client profiles, and manage them for the server and is written with go-lang which means that if you use its binary files which are available in <a href="https://github.com/ngoduykhanh/wireguard-ui/releases"><strong>releases page</strong></a> on their github, it should run without any problems. To use wireguard-ui, you have to download the binary files first:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>wget https://github.com/ngoduykhanh/wireguard-ui/releases/download/v0.3.7/wireguard-ui-v0.3.7-linux-amd64.tar.gz
</code></pre></div></div>

<p>Then unzip the downloaded file:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">tar</span> <span class="nt">-xvf</span> wireguard-ui-v0.3.7-linux-amd64.tar.gz
</code></pre></div></div>

<p>Before running wireguard-ui, you have to open port 5000 on your VM which is the default port of wireguard-ui:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ufw allow 5000 # Open 5000 port
$ ufw disable # stop the firewall
$ ufw enable  # start the firewall
</code></pre></div></div>

<p>Now, run wireguard-ui using:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">./wireguard-ui
</span></code></pre></div></div>
<blockquote>
  <p>Note: If the above command failed, make sure that you gave the run access to that binary file using <code class="language-plaintext highlighter-rouge">$ chmod +x wireguard-ui</code></p>
</blockquote>

<p>After running wireguard-ui you can open your browser and type <code class="language-plaintext highlighter-rouge">YOUR_MACHINE_ADDRESS:5000</code> at the address bar and start using wireguard-ui. The default username and passwords for wireguard-ui are:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>username: admin
password: admin
</code></pre></div></div>
<p>Login to the panel and make as many client as you want, then download the configuration files or save the qr code for each client. After you finished your job, press <code class="language-plaintext highlighter-rouge">apply config</code> and go back to your vm, terminate the wireguard-ui by pressing <code class="language-plaintext highlighter-rouge">ctrl + c</code>.</p>

<div align="center">
    <img src="/assets/images/blog/vpn-setup/wireguard-ui.png" />
</div>

<p><br /></p>

<blockquote>
  <p>Note: Before making user clients, I recommend you to first change the server port (then press <code class="language-plaintext highlighter-rouge">apply config</code>) and then begin creating profiles.</p>
</blockquote>

<p>Wireguard-ui should generate a configuration file and place it inside <code class="language-plaintext highlighter-rouge">/etc/wireguard/wg0.conf</code>. After terminating wireguard-ui, no further configurations are needed for adding clients and you can give the downloaded config files to your clients. To run the server there are two more steps to go with. One is configuring the server’s firewall and the other one is running wireguard server as a background service which is available in the next sections.</p>

<h2 id="32-configuring-the-wireguard-servers-firewall">3.2 Configuring the WireGuard Server’s Firewall</h2>

<p>In this section you will edit the WireGuard Server’s configuration to add firewall rules that will ensure traffic to and from the server and clients is routed correctly. As with the previous section, skip this step if you are only using your WireGuard VPN for a machine to machine connection to access resources that are restricted to your VPN.</p>

<p>To allow WireGuard VPN traffic through the Server’s firewall, you’ll need to enable masquerading, which is an iptables concept that provides on-the-fly dynamic network address translation (NAT) to correctly route client connections.</p>

<p>First find the public network interface of your WireGuard Server using the ip route sub-command:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>ip route list default
</code></pre></div></div>

<p>The public interface is the string found within this command’s output that follows the word “dev”. For example, this result shows the interface named eth0, which is highlighted below:</p>

<pre><code class="language-output">default via 77.222.67.140 dev eth0 proto static
</code></pre>
<p>Note your device’s name since you will add it to the iptables rules in the next step.
To add firewall rules to your WireGuard Server, open the /etc/wireguard/wg0.conf file with vim or your preferred editor again.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">vim /etc/wireguard/wg0.conf
</span></code></pre></div></div>
<p>At the bottom of the file after the <code class="language-plaintext highlighter-rouge">SaveConfig = true</code> line, paste the following lines:</p>

<pre><code class="language-txt">PostUp = ufw route allow in on wg0 out on eth0
PostUp = iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
PostUp = ip6tables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
PreDown = ufw route delete allow in on wg0 out on eth0
PreDown = iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE
PreDown = ip6tables -t nat -D POSTROUTING -o eth0 -j MASQUERADE
</code></pre>

<p>The PostUp lines will run when the WireGuard Server starts the virtual VPN tunnel. In the example here, it will add three ufw and iptables rules:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ufw route allow in on wg0 out on eth0</code> - This rule will allow forwarding IPv4 and IPv6 traffic that comes in on the wg0 VPN interface to the eth0 network interface on the server. It works in conjunction with the net.ipv4.ip_forward and net.ipv6.conf.all.forwarding sysctl values that you configured in the previous section.</li>
  <li><code class="language-plaintext highlighter-rouge">iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE</code> - This rule configures masquerading, and rewrites IPv4 traffic that comes in on the wg0 VPN interface to make it appear like it originates directly from the WireGuard Server’s public IPv4 address.</li>
  <li><code class="language-plaintext highlighter-rouge">ip6tables -t nat -I POSTROUTING -o eth0 -j MASQUERADE</code> - This rule configures masquerading, and rewrites IPv6 traffic that comes in on the wg0 VPN interface to make it appear like it originates directly from the WireGuard Server’s public IPv6 address.</li>
</ul>

<blockquote>
  <p>Note: You can run these command just after running the server without adding Post and Pre configs.</p>
</blockquote>

<p>The PreDown rules run when the WireGuard Server stops the virtual VPN tunnel. These rules are the inverse of the PostUp rules, and function to undo the forwarding and masquerading rules for the VPN interface when the VPN is stopped.</p>

<p>In both cases, edit the configuration to include or exclude the IPv4 and IPv6 rules that are appropriate for your VPN. For example, if you are just using IPv4, then you can exclude the lines with the ip6tables commands.</p>

<p>Conversely, if you are only using IPv6, then edit the configuration to only include the ip6tables commands. The ufw lines should exist for any combination of IPv4 and IPv6 networks. Save and close the file when you are finished.</p>

<p>The last part of configuring the firewall on your WireGuard Server is to allow traffic to and from the WireGuard UDP port itself. If you did not change the port in the server’s <code class="language-plaintext highlighter-rouge">/etc/wireguard/wg0.conf</code> file, the port that you will open is 51820. If you chose a different port when editing the configuration be sure to substitute it in the following UFW command.</p>

<blockquote>
  <p>Note: In my experience data centers might close irregular ports such as the default Wireguard port <code class="language-plaintext highlighter-rouge">51820</code> and I suggest you to choose a popular service port for your VPN connection. I usually prefer using database ports or streaming services ports that are working with data and high network traffic on these ports seems less suspicious. (i.e. MongoDB default port 27017)</p>
</blockquote>

<p>In case you forgot to open the SSH port when following the prerequisite tutorial, add it here too:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">ufw allow 51820/udp #</span><span class="w"> </span>The chosen VPN server port <span class="o">(</span>you can change it to what ever you want<span class="o">)</span>
<span class="gp">ufw allow OpenSSH   #</span><span class="w"> </span>To be able to connect the server using openSSH trough port 22
</code></pre></div></div>

<blockquote>
  <p>Note: If you are using a different firewall or have customized your UFW configuration, you may need to add additional firewall rules. For example, if you decide to tunnel all of your network traffic over the VPN connection, you will need to ensure that port 53 traffic is allowed for DNS requests, and ports like 80 and 443 for HTTP and HTTPS traffic respectively. If there are other protocols that you are using over the VPN then you will need to add rules for them as well.</p>
</blockquote>

<p>After adding those rules, disable and re-enable UFW to restart it and load the changes from all of the files you’ve modified:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">ufw disable
ufw enable
</span></code></pre></div></div>

<p>You can confirm the rules are in place by running the ufw status command. Run it, and you should receive output like the following:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">ufw status
</span></code></pre></div></div>
<pre><code class="language-output">Status: active

To                         Action      From
--                         ------      ----
51280/udp                  ALLOW       Anywhere                  
22/tcp                     ALLOW       Anywhere                  
51280/udp (v6)             ALLOW       Anywhere (v6)             
22/tcp (v6)                ALLOW       Anywhere (v6)
</code></pre>

<p>Your WireGuard Server is now configured to correctly handle the VPN’s traffic, including forwarding and masquerading for peers. With the firewall rules in place, you can start the WireGuard service itself to listen for peer connections.</p>

<h2 id="33-starting-the-wireguard-server">3.3 Starting the WireGuard Server</h2>
<p>WireGuard can be configured to run as a systemd service using its built-in wg-quick script. While you could manually use the wg command to create the tunnel every time you want to use the VPN, doing so is a manual process that becomes repetitive and error prone. Instead, you can use systemctl to manage the tunnel with the help of the wg-quick script.</p>

<p>Using a systemd service means that you can configure WireGuard to start up at boot so that you can connect to your VPN at any time as long as the server is running. To do this, enable the wg-quick service for the wg0 tunnel that you’ve defined by adding it to systemctl:</p>
<div class="language-terminal highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">systemctl enable wg-quick@wg0
</span></code></pre></div></div>
<p>Now start the service:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">systemctl start wg-quick@wg0
</span></code></pre></div></div>
<p>Double check that the WireGuard service is active with the following command. You should see active (running) in the output:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">systemctl status wg-quick@wg0.service
</span></code></pre></div></div>
<pre><code class="language-output">● wg-quick@wg0.service - WireGuard via wg-quick(8) for wg0
     Loaded: loaded (/lib/systemd/system/wg-quick@.service; enabled; vendor preset: enabled)
     Active: active (exited) since Wed 2021-08-25 15:24:14 UTC; 5s ago
       Docs: man:wg-quick(8)
             man:wg(8)
             https://www.wireguard.com/
             https://www.wireguard.com/quickstart/
             https://git.zx2c4.com/wireguard-tools/about/src/man/wg-quick.8
             https://git.zx2c4.com/wireguard-tools/about/src/man/wg.8
    Process: 3245 ExecStart=/usr/bin/wg-quick up wg0 (code=exited, status=0/SUCCESS)
   Main PID: 3245 (code=exited, status=0/SUCCESS)

Aug 25 15:24:14 wg0 wg-quick[3245]: [#] wg setconf wg0 /dev/fd/63
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip -4 address add 10.8.0.1/24 dev wg0
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip -6 address add fd0d:86fa:c3bc::1/64 dev wg0
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip link set mtu 1420 up dev wg0
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ufw route allow in on wg0 out on eth0
Aug 25 15:24:14 wg0 wg-quick[3279]: Rule added
Aug 25 15:24:14 wg0 wg-quick[3279]: Rule added (v6)
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] iptables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
Aug 25 15:24:14 wg0 wg-quick[3245]: [#] ip6tables -t nat -I POSTROUTING -o eth0 -j MASQUERADE
Aug 25 15:24:14 wg0 systemd[1]: Finished WireGuard via wg-quick(8) for wg0.
</code></pre>

<p>The output shows the ip commands that are used to create the virtual wg0 device and assign it the IPv4 and IPv6 addresses that you added to the configuration file. You can use these rules to troubleshoot the tunnel, or with the wg command itself if you would like to try manually configuring the VPN interface.</p>

<p>With the server configured and running, the next step is to configure your client machine as a WireGuard Peer and connect to the WireGuard Server. Wireguard clients are available for almost every popular operating system such as Windows, Linux, Android, IOS, Mac OS, and many more. You can simply download the proper client and pass the client configuration file which you downloaded from wireguard-ui and connect to the server. (<a href="https://www.wireguard.com/install/"><strong>Download wireguard client</strong></a>)</p>

<blockquote>
  <p>Note: when ever you want to add more clients to the server, just run wireguard-ui and add your clients. After terminating the wireguard-ui, you have to restart the wireguard service using <code class="language-plaintext highlighter-rouge">systemctl restart wg-quick@wg0</code>. If you didn’t add Post and Pre Scripts to the wireguard config file like the previous section, you have to run iptables MASQUERADE rules again.</p>
</blockquote>

<h1 id="5-revers-proxy">5. Revers Proxy</h1>
<p>Congratulations, till now, you have configured a Virtual private network for your self but you might not be able to connect to the network directly in situations the government restricts users from connecting to the outside world as regards your outer VPN server is out there. To make your clients escape from the local intranet, you need a second machine inside a local data-centers which is connected to the public internet. That machine would be your middle server or the bridge to connect to the VPN server that you have configured previously. One simple solution to use this middle server as a bridge is setting a proxy on that middle server which redirects our requests to the target VPN server. In computer networking, a proxy server is a server application that acts as an intermediary between a client requesting a resource and the server providing that resource(<a href="https://en.wikipedia.org/wiki/Proxy_server">Wikipedia</a>).</p>

<h2 id="51-nginx-reverse-proxy">5.1 Nginx Reverse Proxy</h2>
<p>Nginx is a popular web-server application that is used to deploy various web applications and it has so many capabilities. One of the configurations that you can set for Nginx is to redirect incoming requests to a specific address by setting proxy routes. As we know that WireGuard traffic is a stream of data and its UDP. So, we have to set a stream proxy route for our purpose.</p>
<div align="center">
    <img width="20%" src="/assets/images/blog/vpn-setup/nginx-logo.png" />
</div>
<p><br /></p>

<p>This time, let’s connect to our middle server using ssh and after updating its packages, install Nginx on that machine.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>apt <span class="nb">install </span>nginx <span class="nt">--yes</span>
</code></pre></div></div>

<p>After that, open Nginx configuration file from <code class="language-plaintext highlighter-rouge">/etc/nginx/nginx.conf</code> using vim or your preferred editor:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>vim /etc/nginx/nginx.conf
</code></pre></div></div>

<p>Then add a stream section at the end of that file and write your proxy config there:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>stream {
    server {
        listen 51820 udp;
        proxy_pass 77.222.67.140:51820;
    }
}
</code></pre></div></div>

<p>Save and exit when you are done. Restart nginx:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>service nginx restart
</code></pre></div></div>

<blockquote>
  <p>Note: In the config above, I opened 51820 port on my middle server and redirected incoming requests through this port to the target VPN server which we have wireguard installed. The first port number on the config <code class="language-plaintext highlighter-rouge">51820</code> is the port that I want to open on my middle server and the other one is the port I chose for my VPN server. You have to change these numbers if you chose something else.</p>
</blockquote>

<div align="center">
    <img width="20%" src="/assets/images/blog/vpn-setup/wg-client.png" />
</div>
<p><br /></p>

<p>Now your clients should be able to connect to the VPN server through the middle server by changing the <code class="language-plaintext highlighter-rouge">Endpoint</code> on their configuration.</p>

<pre><code class="language-txt">[Interface]
PrivateKey = [CLIENT_PRIVATE_KEY]
Address = 10.252.1.1/32
DNS = 1.1.1.1

[Peer]
PublicKey = [PUBLIC_KEY]
PresharedKey = [PRE_SHARED_KEY]
AllowedIPs = 0.0.0.0/0
Endpoint = 77.222.67.140:51820 --&gt; change this address to  YOUR_MIDDLE_SERVER_IP:51820
PersistentKeepalive = 15
</code></pre>

<p>After editing the config file on the client’s machines:</p>

<pre><code class="language-txt">[Interface]
PrivateKey = [CLIENT_PRIVATE_KEY]
Address = 10.252.1.1/32
DNS = 1.1.1.1

[Peer]
PublicKey = [PUBLIC_KEY]
PresharedKey = [PRE_SHARED_KEY]
AllowedIPs = 0.0.0.0/0
Endpoint = 192.168.0.1:51820
PersistentKeepalive = 15
</code></pre>

<h2 id="52-nginx-on-docker">5.2 Nginx on docker</h2>
<p>As the Nginx docker image is available on the docker hub, you can use the Nginx container instead of installing Nginx on a separate VM. You can run your proxy server on the cloud which is cheaper cost beneficial than renting a virtual machine. Also, some proxy managers are available on docker-hub with a web-based interface such as the popular <a href="https://nginxproxymanager.com/guide/#project-goal"><strong>nginx-proxy-manager</strong></a>.</p>
<div align="center">
    <img width="20%" src="/assets/images/blog/vpn-setup/docker-logo.png" />
</div>

<h1 id="6-final-worlds">6. Final worlds</h1>
<p>Some of you might have trouble using my solution for making your private network and you can read the article references and a little search on DuckDuckGo (Or google) to find the solution. I hope you find this article useful.</p>

<p>for a better world,<br />
Regards</p>

<h1 id="references">References</h1>
<ol>
  <li><a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-wireguard-on-ubuntu-20-04">https://www.digitalocean.com/community/tutorials/how-to-set-up-wireguard-on-ubuntu-20-04</a></li>
  <li><a href="https://github.com/ngoduykhanh/wireguard-ui">https://github.com/ngoduykhanh/wireguard-ui</a></li>
  <li><a href="https://ericiniguez.com/p/wireguard-vpn-and-nginx-reverse-proxy/">https://ericiniguez.com/p/wireguard-vpn-and-nginx-reverse-proxy/</a></li>
  <li><a href="https://nginxproxymanager.com/guide/#project-goal">https://nginxproxymanager.com/guide/#project-goal</a></li>
</ol>]]></content><author><name>Ali N. Parizi</name></author><category term="project" /><category term="network" /><category term="security" /><category term="vpn" /><summary type="html"><![CDATA[1. Intro]]></summary></entry><entry><title type="html">What is an AutoEncoder?</title><link href="http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/09/16/auto-encoder.html" rel="alternate" type="text/html" title="What is an AutoEncoder?" /><published>2022-09-16T13:21:13+04:30</published><updated>2022-09-16T13:21:13+04:30</updated><id>http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/09/16/auto-encoder</id><content type="html" xml:base="http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/09/16/auto-encoder.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>AutoEncoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.
AutoEncoder, by design, reduces data dimensions by learning how to ignore the noise in the data.
Here is an example of the input/output image from the MNIST dataset to an AutoEncoder.</p>

<p align="center">
  <img src="/assets/images/auto-encoder/ae-arch.jpeg" />
    <br />
    <span>a simple AutoEncoder</span>
</p>

<h2 id="11-autoencoder-components">1.1 AutoEncoder Components:</h2>
<p>Autoencoders consists of 4 main parts:</p>
<ol>
  <li>
    <p><strong>Encoder</strong>: In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.</p>
  </li>
  <li>
    <p><strong>Bottleneck</strong>: which is the layer that contains the compressed representation of the input data. This is the lowest possible dimensions of the input data.</p>
  </li>
  <li>
    <p><strong>Decoder</strong>: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.</p>
  </li>
  <li>
    <p><strong>Reconstruction Loss</strong>: This is the method that measures measure how well the decoder is performing and how close the output is to the original input.</p>
  </li>
</ol>

<p>The training then involves using back propagation in order to minimize the network’s reconstruction loss. You must be wondering why would I train a neural network just to output an image or data that is exactly the same as the input! This article will cover the most common use cases for Autoencoder. Let’s get started:</p>

\[Loss = \lVert X - \hat{X} \rVert_{2}^{2}\]

<h2 id="12-problem-statement">1.2 Problem statement:</h2>
<p>The network architecture for AutoEncoders can vary between a simple FeedForward network, LSTM network or Convolutional Neural Network depending on the use case. This article will use CNN networks to solve a simple problem. The problem is to remove an annoying text from the given picture. You might have seen that many photographic websites or some famous photographers use some texts as a sign or a signature on their images. That would prevent other people from stealing their valuable artistic photos, paintings, etc.</p>

<p>For example here is a sample photo taken by my psychologist friend Reza Parizi (<a href="https://www.instagram.com/reza__parizi/">reza__parizi</a>):</p>

<p align="center">
  <img width="70%" src="/assets/images/auto-encoder/reza-parizi.jpg" />
</p>

<p>We can consider these kinds of texts which may be known by the name <a href="https://en.wikipedia.org/wiki/Watermark"><strong>watermark</strong></a> as static noise in pictures. We can try to find a way or a set of filters to be applied to that image in order to remove that artifact. One of the main use cases of AutoEncoders is denoising, so let’s solve this problem using AutoEncoders.</p>

<h1 id="2-preparing-the-data">2. Preparing the data:</h1>
<p>As you know for deep learning models the first thing we need is the data. For this problem, I used the popular <a href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html"><strong>Stanford cars</strong></a> dataset and I added the static text “Hot-Tube” to the images as the signature of the image. Let’s say that the data is stored in a directory named <code class="language-plaintext highlighter-rouge">datasets/car</code> and the training data is located inside another directory called <code class="language-plaintext highlighter-rouge">train</code>. First, we import all required modules:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">keras.layers</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">cv2</span>
</code></pre></div></div>

<p>Then we have to load the dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">path_to_train_imgs</span> <span class="o">=</span> <span class="s">'./datasets/cars/train'</span>
<span class="n">train_imgs_list</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path_to_train_imgs</span><span class="p">)</span>
<span class="n">train_imgs_list</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">path_to_train_imgs</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">train_imgs_list</span><span class="p">]</span>
</code></pre></div></div>
<p>These images are the original images which considered the ground truth. To generate the input data we have 2 ways:</p>
<ol>
  <li>load all data into the memory and loop throw them adding the signature text.</li>
  <li>Write a DataGenerator which adds the signature to each image while creating the batch.</li>
</ol>

<p>The first method is not always a good option, especially while working with images. because image data volumes are regularly high, loading this amount of data into the memory will cause the Out of memory problem and lead your programs to crash.</p>

<p>DataGenerators will load only that part of the data which is needed for the training on each period of time and it prevents the out-of-memory problem. After knowing the need for DataGenerators let’s write a DataGenerator for our program.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DataGenerator</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">Sequence</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">image_list</span> <span class="o">=</span> <span class="n">image_list</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">on_epoch_end</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">load_img</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">img</span>
        
    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image_list</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">shuffle</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">indexes</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image_list</span><span class="p">)</span><span class="o">//</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span>
    
    <span class="k">def</span> <span class="nf">add_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cv2</span><span class="p">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'Hot-Tube'</span><span class="p">,</span> <span class="n">org</span><span class="o">=</span><span class="p">(</span><span class="mi">46</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">fontFace</span><span class="o">=</span><span class="n">cv2</span><span class="p">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="n">fontScale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">indexes</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">indexes</span><span class="p">[</span><span class="n">index</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">:</span> <span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">img_paths</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">image_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indexes</span><span class="p">]</span>
        
        <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span> <span class="k">for</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="n">img_paths</span><span class="p">]</span>
        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">add_text</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">))</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">/</span><span class="mi">255</span>
</code></pre></div></div>
<p>Let’s see how it works:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plt_img</span><span class="p">(</span><span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="p">,</span> <span class="n">title</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

<span class="n">validation_imgs</span><span class="p">,</span> <span class="n">train_imgs</span> <span class="o">=</span> <span class="n">train_imgs_list</span><span class="p">[:</span><span class="mi">100</span><span class="p">],</span> <span class="n">train_imgs_list</span><span class="p">[</span><span class="mi">100</span><span class="p">:]</span>
<span class="n">train_data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">image_list</span><span class="o">=</span><span class="n">train_imgs</span><span class="p">)</span>
<span class="n">validation_data_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">image_list</span><span class="o">=</span><span class="n">validation_imgs</span><span class="p">)</span>

<span class="c1"># Showing some sample images
</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">validation_data_generator</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">cnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
    <span class="n">plt_img</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s">"Original Image"</span><span class="p">)</span>
    <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
    <span class="n">plt_img</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s">"Augmented Image"</span><span class="p">)</span>
    <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p align="center">
  <img width="70%" src="/assets/images/auto-encoder/sample_data.png" />
</p>

<h1 id="3-building-the-model">3. Building the model</h1>

<p>Let’s say that we have trained an autoencoder on the Cars dataset. Using a simple FeedForward neural network, we can achieve this by building a simple 9 layers network as below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Input</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 128x128
</span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"bottle-neck"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 128*128
</span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">UpSampling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 256x256
</span><span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">"mean_squared_error"</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<pre><code class="language-output">Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 256, 256, 3)]     0         
                                                                 
 conv2d_2 (Conv2D)           (None, 256, 256, 32)      896       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         
 )                                                               
                                                                 
 bottle-neck (Conv2D)        (None, 128, 128, 8)       2312      
                                                                 
 up_sampling2d (UpSampling2D  (None, 256, 256, 8)      0         
 )                                                               
                                                                 
 conv2d_3 (Conv2D)           (None, 256, 256, 32)      2336      
                                                                 
 conv2d_4 (Conv2D)           (None, 256, 256, 64)      18496     
                                                                 
 conv2d_5 (Conv2D)           (None, 256, 256, 128)     73856     
                                                                 
 conv2d_6 (Conv2D)           (None, 256, 256, 3)       387       
                                                                 
=================================================================
Total params: 98,283
Trainable params: 98,283
Non-trainable params: 0
_________________________________________________________________
</code></pre>

<p>I used mean squared error (MSE) loss to train my model. Because I wanted the model’s output to be the same as the original image. MSE should do the job for us perfectly but, we could use a different loss function that would compare the images from a regional point of view and would be better for high-resolution images and more general datasets. But, we are good with MSE on this task.</p>

<h2 id="31-tensorboard">3.1 Tensorboard</h2>
<p>To see how the training process is going on and monitor the training process, there is a useful option called Tensorboard developed by the TensorFlow team. Tensorboard is a background process that looks inside a directory (usually named “logs”) and visualizes the training process logs such as training and validation accuracy and loss for us. It also is capable to display images that can be generated during the training process such as model predictions at the end of each epoch. It would be so handy to store the model prediction during the training process. It could help us to find out when to terminate the training process in an experimental way.</p>

<p>To do so, we have to define a custom callback class to store model prediction on each epoch ended.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TensorBoardImageCallBack</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">noisy_image</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">noisy_image</span> <span class="o">=</span> <span class="n">noisy_image</span>

    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">filename_suffix</span><span class="o">=</span><span class="s">'images'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">write_image</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">noisy_image</span><span class="p">,</span> <span class="s">'Noisy Image'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">write_image</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">image</span><span class="p">,</span> <span class="s">'Original Image'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">write_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="n">image_to_write</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">writer</span><span class="p">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">image</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">image_to_write</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
        <span class="n">denoised_image</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">noisy_image</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">write_image</span><span class="p">(</span><span class="n">denoised_image</span><span class="p">,</span> <span class="s">'Denoised Image'</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        
<span class="n">tensorboard_callback</span> <span class="o">=</span> <span class="n">TensorBoardImageCallBack</span><span class="p">(</span><span class="s">'./logs'</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">tensorboard_callback_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s">"./logs"</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="32-training-the-model">3.2 Training the model</h2>
<p>Now, it’s time to start training our model. I just hangup training the model after 25 epochs but, in code, I’ve defined the number of epochs to be 100. I hope continuing the training till 100 epochs will tend to a great convergence of the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">train_data_generator</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data_generator</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tensorboard_callback</span><span class="p">,</span> <span class="n">tensorboard_callback_loss</span><span class="p">]</span>
        <span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-output">...
502/502 [==============================] - 86s 171ms/step - loss: 6.6057e-04 - accuracy: 0.8184 - val_loss: 5.3678e-04 - val_accuracy: 0.8163
</code></pre>

<p>As you can see in the output, which is the results of training for about 25 epochs, the last reconstruction loss/error for the validation set is 5.3678e-04 which is great but it can be better if you run this code for about 100 epochs. Now, if I pass a new image from the test dataset, the reconstruction loss will be very low BUT if I tried to pass any other different image (outlier or anomaly), we will get a high reconstruction loss value because the network failed to reconstruct the image/input that is considered an anomaly, which is another use case of autoencoders to detect outlier data points.</p>

<p align="center">
  <img width="70%" src="/assets/images/auto-encoder/sample_prediction.png" />
</p>

<p>Notice in the code above, you can use only the encoder part to compress some data or images and you can also only use the decoder part to decompress the data by loading the decoder layers. As you can see, we reduced the input image dimensions from \(256 \times 256 \times 3\) to \(128 \times 128 \times 8\) which is accessible in the bottle-neck layer’s output. storing the features of this layer instead of the original images lowers the space needed to store the images by a factor of 1.5. If it was a video of size 900MB, using this technique would lead the size of the video to be 600MB which is more efficient for data storage.</p>

\[\frac{256 \times 256 \times 3}{128 \times 128 \times 8} = 1.5\]

<p align="center">
  <img src="/assets/images/auto-encoder/loss.png" />
  <br />
  <span>Model loss per epoch</span>
</p>

<blockquote>
  <p>Note: In the figure above, red is validation loss and the blue one is training loss per epoch.</p>
</blockquote>

<p>Another use case of AutoEncoders is learning a data representation in lower dimensions which tends to data compression. Another cool use case is to enhance the quality of the picture which is called super-resolution which we can’t see on our model but I’ll do an experiment to implement super-resolution using AutoEncoders in another article.</p>

<p>Finally, we removed a static noise from the input data which is another use case of auto encoders we were follow.
I hope you enjoyed reading my article. Stay tuned!</p>

<h1 id="references">References</h1>
<ol>
  <li><a href="https://paperswithcode.com/method/autoencoder"><em>G. E. Hinton, &amp; R. R. Salakhutdinov (2006). Reducing the Dimensionality of Data with Neural Networks. Science, 313(5786), 504-507.</em></a></li>
</ol>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><summary type="html"><![CDATA[1. Intro AutoEncoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible. AutoEncoder, by design, reduces data dimensions by learning how to ignore the noise in the data. Here is an example of the input/output image from the MNIST dataset to an AutoEncoder.]]></summary></entry><entry><title type="html">The Poisson Distribution</title><link href="http://localhost:4000/blog/math/statistics/random-process/2022/07/14/the-poisson-distribution.html" rel="alternate" type="text/html" title="The Poisson Distribution" /><published>2022-07-14T12:32:35+04:30</published><updated>2022-07-14T12:32:35+04:30</updated><id>http://localhost:4000/blog/math/statistics/random-process/2022/07/14/the-poisson-distribution</id><content type="html" xml:base="http://localhost:4000/blog/math/statistics/random-process/2022/07/14/the-poisson-distribution.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>Knowing statistics for a computer engineer, a data scientist, or a machine-learning engineer is a unique need in their professional career. We learn about statistics in most universities more like learning differential equations or calculus instead. We know so many mathematical basics for statistics that we will never use in the future. That prevents us from seeing the use of statistics and what we can do with these concepts in the real world.</p>

<p>In this article, we are about to learn two crucial statistics concepts, The Poisson Distribution and The Poisson Process, through solving a common problem in the concept of online website hosting.</p>

<h1 id="2-what-poisson-distribution-or-poisson-process-is-about">2. What Poisson Distribution or Poisson Process is about?</h1>
<p>Before we get started, let’s first ask our selves a simple question, “Why do we need Poisson?”</p>

<p>The Poisson distribution helps us to o predict the probability of a given number of events occurring in a fixed interval of time, or just simply, to predict the number of events in the future.</p>

<p>For example,</p>
<ul>
  <li>How many visitors do you get on your website in a day?</li>
  <li>How many clicks do your ads get for the next month?</li>
  <li>How many phone calls do you get during your shift?</li>
  <li>How many people will die from covid-19 next year?</li>
</ul>

<p>Every week, on average, 17 people react to my blog posts via sending me emails. I’d like to predict the number of people who react to my blog posts next week because I have to consider some free time to answer them properly and planning is so critical for me.</p>

<p>What is the probability that exactly 20 people (or 10, 30, 40, etc.) will react to my posts next week?</p>

<p>To answer this question, if we knew some statistics, it would comes my our minds that we should be able to solve this problem using <strong>the Binomial distribution</strong>. Let’s first, look at the concept of Binomial distribution and solve the problem using it.</p>

<h1 id="3-binomial-distribution">3. Binomial distribution</h1>
<p>One way to solve this should be to start with the number of reads. Each person who reads the blog has some probability that they will really have a question or found some thing interesting to share with me.</p>

<p>A binomial random variable is the number of successes \(x\) in \(n\) repeated trials. And we assume the probability of success \(p\) is constant over each trial. The Binomial distribution formula is:
\begin{equation}
P[X=x] = \binom{n}{x}p^x(1-p)^{n-x}
\end{equation}</p>

<p>However here, we are given only one piece of information, \(17 \frac{emails}{week}\), which is a rate. we don’t know any thing about the probability of receiving an email by an individual reader p, nor the number of blog visitors n. So, we use google analytics to retrieve this data from our blog history.</p>

<p align="center"> <img src="/assets/images/poisson/website-stats.png" /><br /><span>Stats from google</span></p>

<p>By looking to the stats we can say, in one year, A total of \(59k\) people read my blog. Out of \(59k\) people, \(888\) of them liked my post. Therefore, the number of people who read my blog per week (\(n\)) is \(\frac{59k}{52}=1134\). The number of people who liked my posts per week (\(x\)) is \(\frac{888}{52}=17\). So, the success probability p would be \(\frac{888}{59k} = 0.015\) or \(1.5\%\).</p>

<p>Now Using Binomial PMF, we should be able to calculate the probability of getting 20 emails for next week as below:</p>

\[P[X=20] = \binom{1134}{20}(0.015)^{20}(1-0.015)^{n-x} = 0.06962\]

<p>We can use python or any other programming language to calculate the probability of getting emails with different values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>
<span class="c1"># setting the values
# of n, p and x
</span><span class="n">n</span> <span class="o">=</span> <span class="mi">1134</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.015</span>
<span class="n">x_s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"x</span><span class="se">\t</span><span class="s">Binomial P(x, n, p)"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"----------------------------"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_s</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s">:</span><span class="se">\t</span><span class="si">{</span><span class="n">binom</span><span class="p">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<pre><code class="language-output">x	Binomial P(x, n, p)
----------------------------
10:	0.022507172903122208
17:	0.09701415708780352
20:	0.06962037106916726
30:	0.0012106250995813465
40:	6.815731666708672e-07
</code></pre>

<p>As you can see, by using binomial distribution the probability of getting, 10, 17, 20, 30 and 40 emails per week would be as follows:</p>

<table>
  <thead>
    <tr>
      <th>x</th>
      <th style="text-align: center">Binomial P(X=x)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td style="text-align: center">0.02250</td>
    </tr>
    <tr>
      <td>17</td>
      <td style="text-align: center">0.09701</td>
    </tr>
    <tr>
      <td>20</td>
      <td style="text-align: center">0.06962</td>
    </tr>
    <tr>
      <td>30</td>
      <td style="text-align: center">0.00121</td>
    </tr>
    <tr>
      <td>40</td>
      <td style="text-align: center">&lt; 0.000001</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h1 id="4-shortcomings-of-the-binomial-distribution">4. Shortcomings of the Binomial Distribution</h1>

<p>The very first problem with a binomial random variable is, “<strong>it being assumed to be binary (0 or 1)</strong>”. In the previous example, we have \(17 \frac{emails}{week}\). This means \(\frac{17}{7}=2.4\) people will send me emails per day, and \(\frac{17}{7*24}\) = 0.1 people send me email per hour.
If we model the success probability by hour (0.1 email/hr) using binomial random variable, this means most of the hours get zero emails but some hours will get exactly 1 email. However, it is also very possible that certain hours will get more that 1 email (2,3,5 emails, etc.)
The problem with binomial is that it cannot contain more than 1 event in the unit of time (in this case, 1 hr is the unit time). The unit of time can only have 0 or 1 event.</p>

<p>How about dividing 1 hour into 60 minutes, and make unit time smaller, for example, a minute? If that so, then 1 hour can contain multiple events (Still, one minute will contain exactly one or zero events.). What if, during that one minute, we got multiple emails? (i.e someone shared your my blog post on Twitter and the traffic spiked at that minute.) Then what? We can divide a minute into seconds. then our time unit becomes a second and again a minute can contain multiple events. But this binary container problem will always exist for ever-smaller time units. The idea is, we can make the binomial random variable handle multiple events by dividing a unit time into smaller units. By using smaller divisions, we can make the original unit time contain more than one event. Mathematically, this means \(n\) goes to infinity. Since we assumed the rate is fixed, \(p\) must goes to zero. Because, when $n$ grows up to infinity,the number of intervals between the period becomes grows as $n$ and the probability of getting an email at each interval tends to be merely zero. In the other words, If $n$ goes to infinity, \(p\) should become zero, Other wise, \(np\), which is the number of events will blow up.</p>

<p>The second problem with the binomial random variable is, “<strong>when we want to use the binomial distribution, the number of trails, \(n\), and the probability of success, \(p\), should be known</strong>”.
If you use Binomial, you cannot calculate the success probability only with the rate (i.e \(17\frac{emails}{week}\)). You need more information \(n\) and \(p\), in order to use the binomial PMF.
The Poisson Distribution, on the other hand, doesn’t require you to know \(n\) or \(p\). We are assuming \(n\) is infinitely large (\(n\rightarrow\infty\)) and \(p\) is infinitesimal (\(p\rightarrow 0\)).
The only parameter of the Poisson distribution is the rate \(\lambda\). (In real life only knowing the rate is much more common than knowing both \(n\) and \(p\))</p>

<h1 id="5-derive-the-poisson-formula-mathematically">5. Derive the poisson formula mathematically</h1>
<p>Now, let’s deep dive into the binomial distribution formula with the assumption that we reached from the ideas of the previous section (<a href="#4-shortcomings-of-the-binomial-distribution">Section 4</a>). We find out that to solve the deal with the binary nature of the binomial random variable, we should increase the number of time units in our one week interval. Mathematically it means \(n\rightarrow\infty\):</p>

\[P[X=x] = lim_{n\rightarrow\infty}\binom{n}{x}p^x(1-p)^{n-x}\]

<p>If, \(n\rightarrow\infty\) and \(p\rightarrow 0\) then we can assume that:</p>

\[p = \frac{\lambda}{n}\]

<p>Then we have:</p>

\[P[X=x] = lim_{n\rightarrow\infty}\binom{n}{x}(\frac{λ}{n})^x(1- (\frac{λ}{n}))^{n-x}\]

\[\Rightarrow lim_{n\rightarrow\infty} \frac{n!}{(n-x)!x!}(\frac{λ}{n})^x(1- (\frac{λ}{n}))^{n-x}\]

\[\Rightarrow lim_{n\rightarrow\infty} \frac{n!}{(n-x)!}\frac{1}{n^x}\frac{λ^x}{x!}(1-\frac{λ}{n})^n(1-\frac{λ}{n})^{-x}\]

\[\Rightarrow lim_{n\rightarrow\infty} \frac{n!}{(n-x)!}\frac{1}{n^x}\frac{λ^x}{x!}e^{-λ}(1)\]

<p>Because:</p>

\[lim_{n\rightarrow\infty}\frac{n!}{(n-x)!}\frac{1}{n^x} = 1\]

<p>We can say:</p>

<p>\begin{equation}
P[X=x] = e^{-λ}\frac{λ^{x}}{x!}
\end{equation}</p>

<p>Which is actually the Poisson random distribution formula.</p>

<h1 id="6-probability-of-events-for-a-poisson-distribution">6. Probability of events for a Poisson distribution</h1>

<p>An event can occur 0, 1, 2, … times in an interval. The average number of events in an interval is designated λ. λ is the event rate. also called the rate parameter. The probability of observing k events in an interval is given by the equation:</p>

\[P[k\ events\ in\ interval] = e^{-λ}\frac{λ^{k}}{k!}\]

<p>Where:</p>
<ul>
  <li>\(\lambda\) is the average number of events per interval</li>
  <li>\(e\) is the number \(2.71828…\) (Euler’s number) the base of the natural logarithm</li>
  <li>\(k\) takes values \(0, 1, 2, …\)</li>
  <li>\(k! = k(k-1)(k-2)…(2)(1)\) is the factorial of \(k\)</li>
</ul>

<p>We calculate the probability of observing 10, 17, 20, 30 and 40 emails in the interval using the poisson distribution formula as below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">poisson</span>

<span class="c1">#calculate probability
</span>
<span class="c1"># setting the values
# of lambda and x
</span><span class="n">l</span> <span class="o">=</span> <span class="mi">17</span>
<span class="n">x_s</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"x</span><span class="se">\t</span><span class="s">Poisson P(x, lambda)"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"----------------------------"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_s</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s">:</span><span class="se">\t</span><span class="si">{</span><span class="n">poisson</span><span class="p">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">l</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>
<pre><code class="language-output">x	Poisson P(x, lambda)
----------------------------
10:	0.022999584406166312
17:	0.09628462779844556
20:	0.06915882695522822
30:	0.001278796308921649
40:	8.381188233781985e-07
</code></pre>

<p>As it can be observed, using the calculated probabilities using Poisson formula is very close to the values calculated using Binomial distribution formula, so we can conclude that the Poisson distribution in this situation is a really good approximation for our problem. Because of the simpler formula and lower and easy to obtain parameter of the poisson distribution, it would be come very useful to use this distribution to solve the problems of this kind.</p>

<table>
  <thead>
    <tr>
      <th>x</th>
      <th style="text-align: center">Binomial P(X=x)</th>
      <th style="text-align: center">Poisson P(X=x;lambda=17)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td style="text-align: center">0.02250</td>
      <td style="text-align: center">0.2300</td>
    </tr>
    <tr>
      <td>17</td>
      <td style="text-align: center">0.09701</td>
      <td style="text-align: center">0.09628</td>
    </tr>
    <tr>
      <td>20</td>
      <td style="text-align: center">0.06962</td>
      <td style="text-align: center">0.07595</td>
    </tr>
    <tr>
      <td>30</td>
      <td style="text-align: center">0.00121</td>
      <td style="text-align: center">0.00340</td>
    </tr>
    <tr>
      <td>40</td>
      <td style="text-align: center">&lt; 0.000001</td>
      <td style="text-align: center">&lt; 0.000001</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h1 id="7-some-notes-on-poisson-random-variable">7. Some notes on Poisson random variable</h1>
<p>Even though the Poisson distribution models are rare events, the rate \(\lambda\) can me any number. It doesn’t always have to be small. The Poisson Distribution is asymmetric, it is always skewed toward the right. Because it is inhibited by the zero occurrence barrier (there is no such thing as minus one email) on the left and it is unlimited on the other side. As \(\lambda\) becomes bigger, the graph looks more like a normal distribution.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">poisson</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">x_s</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">plots</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mus</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>

<span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="n">mus</span><span class="p">:</span>
  <span class="n">y_s</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_s</span><span class="p">:</span>
    <span class="n">y_s</span> <span class="o">+=</span> <span class="p">[</span><span class="n">poisson</span><span class="p">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)]</span>
  <span class="n">plots</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">x_s</span><span class="p">,</span> <span class="n">y_s</span><span class="p">)]</span>


<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">plots</span><span class="p">)):</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plots</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">plots</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">"lambda = </span><span class="si">{</span><span class="n">mus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p align="center"><img src="/assets/images/poisson/different-lambda.png" /><br /><span>Poisson distribution with different lambda's for our problem.</span></p>

<p><strong>The average rate of events per unit time in poisson distribution is constant</strong>. This means the number of people who visit my blog per hour might not follow a Poisson Distribution, because the hourly rate is not constant (higher rate during the daytime, lower rate during the night-time). Using monthly rate for consumer/biological data would be just an approximation as well, since the seasonality effect is non-trivial in that domain.</p>

<p><strong>In poisson random variable, Events are independent</strong>. The arrival of my blog visitors might not always be independent. For example, sometimes a large number of visitors come in a group because someone popular mentioned my blog, or my blog got featured on Medium’s first page, etc. the number of earthquakes per year in a country also might not follow a Poisson Distribution in one large earthquake increases the probability of aftershocks.</p>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="math" /><category term="statistics" /><category term="random-process" /><summary type="html"><![CDATA[1. Intro Knowing statistics for a computer engineer, a data scientist, or a machine-learning engineer is a unique need in their professional career. We learn about statistics in most universities more like learning differential equations or calculus instead. We know so many mathematical basics for statistics that we will never use in the future. That prevents us from seeing the use of statistics and what we can do with these concepts in the real world.]]></summary></entry><entry><title type="html">LeNet-5 from scratch</title><link href="http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/06/21/lenet5.html" rel="alternate" type="text/html" title="LeNet-5 from scratch" /><published>2022-06-21T00:02:23+04:30</published><updated>2022-06-21T00:02:23+04:30</updated><id>http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/06/21/lenet5</id><content type="html" xml:base="http://localhost:4000/blog/ai/machine-learning/deep-learning/2022/06/21/lenet5.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>LeNet is a very first deep learning model that introduced in the research paper “Gradient-Based Learning Applied To Document Recognition” in the year 1998 by four legendary researchers, Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Many of the listed authors of the paper have gone on to provide several significant academic contributions to the field of deep learning.</p>
<p align="center">
    <img src="/assets/images/lenet5/authors.png" />
    <br />
    <span>From left: Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner</span>
</p>
<!-- Image -->
<p>This article will introduce the LeNet-5 CNN architecture as described in the original paper, along with the implementation of the architecture using TensorFlow 2.0. Then conclude with the utilization of the implemented LeNet-5 CNN for the classification of images from the MNIST dataset.</p>

<p align="center">
    <img width="30%" src="/assets/images/lenet5/keras-and-tf.jpeg" />
</p>

<p>What to find in this article:</p>
<ul>
  <li>Understanding of components within a convolutional neural network</li>
  <li>Key definitions of terms commonly used in deep learning and machine learning</li>
  <li>Understanding of LeNet-5 architecture as presented in the original research paper</li>
  <li>Implementation of a neural network using TensorFlow and Keras</li>
</ul>

<p>The content in this article is written for Deep learning and Machine Learning students of all levels. For those who are eager to get coding, scroll down to the <a href="#implementation"><strong>Implementation section</strong></a>.</p>

<h1 id="2-convolutional-neural-networks">2. Convolutional Neural Networks</h1>
<p>Convolutional Neural Networks are a standard form of neural network architecture for solving tasks associated with images. Solutions for tasks such as object detection, face detection, pose estimation and more, usually have CNN architecture variants.</p>

<p>A few characteristics of the CNN architecture makes them more favourable in several computer vision tasks. It would be good if we could introduce each characteristics before we get started on working with the LeNet-5 architecture.</p>

<p>Some convolutional networks characteristics that we are interested in here:</p>
<ul>
  <li>Local respective fields</li>
  <li>Sub-sampling</li>
  <li>Weight sharing</li>
</ul>

<p>LeNet-5 CNN architecture is made up of 7 layers. The layer composition consists of 3 convolutional layers, 2 subsampling layers and 2 fully connected layers.</p>

<p align="center">
    <img src="/assets/images/lenet5/arch.png" />
    <br />
    <span>LeNet architecture</span>
</p>

<p>The diagram above shows a depiction of the LeNet-5 architecture, as illustrated in the original paper.</p>

<p>The first layer is the input layer — this is generally not considered a layer of the network as nothing is learnt in this layer. The input layer is built to take in 32x32, and these are the dimensions of images that are passed into the next layer. Those who are familiar with the MNIST dataset will be aware that the MNIST dataset images have the dimensions 28x28. To get the MNIST images dimension to the meet the requirements of the input layer, the 28x28 images are padded.</p>

<p>The grayscale images used in the research paper had their pixel values normalized from 0 to 255, to values between -0.1 and 1.175. The reason for normalization is to ensure that the batch of images have a mean of 0 and a standard deviation of 1, the benefits of this is seen in the reduction in the amount of training time. In the image classification with LeNet-5 example below, we’ll be normalizing the pixel values of the images to take on values between 0 to 1.</p>

<p><strong>The LeNet-5 architecture utilizes two significant types of layer construct: convolutional layers and subsampling layers.</strong></p>

<ul>
  <li>Convolution layers</li>
  <li>Sub-sampling layers</li>
</ul>

<p>Within the research paper and the image below, convolutional layers are identified with the ‘Cx’, and subsampling layers are identified with ‘Sx’, where ‘x’ is the sequential position of the layer within the architecture. ‘Fx’ is used to identify fully connected layers. This method of layer identification can be seen in the image above.</p>

<p>The official first layer convolutional layer C1 produces as output 6 feature maps, and has a kernel size of 5x5. The kernel/filter is the name given to the window that contains the weight values that are utilized during the convolution of the weight values with the input values. 5x5 is also indicative of the local receptive field size each unit or neuron within a convolutional layer. The dimensions of the six feature maps the first convolution layer produces are 28x28.</p>

<p>A subsampling layer ‘S2’ follows the ‘C1’ layer’. The ‘S2’ layer halves the dimension of the feature maps it receives from the previous layer; this is known commonly as downsampling.</p>

<p>The ‘S2’ layer also produces 6 feature maps, each one corresponding to the feature maps passed as input from the previous layer. This link contains more information on subsampling layers.</p>

<p>More information on the rest of the LeNet-5 layers is covered in the implementation section.
Below is a table that summarises the key features of each layer:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Layer name</th>
      <th style="text-align: center">Input</th>
      <th style="text-align: center">Kernel size</th>
      <th style="text-align: center">Output</th>
      <th style="text-align: center">Activation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Input</td>
      <td style="text-align: center">28x28x1</td>
      <td style="text-align: center">None</td>
      <td style="text-align: center">28x28x1</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Convolution 1</td>
      <td style="text-align: center">28x28x1</td>
      <td style="text-align: center">5x5</td>
      <td style="text-align: center">24x24x6</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Max pooling 1</td>
      <td style="text-align: center">24x24x6</td>
      <td style="text-align: center">2x2</td>
      <td style="text-align: center">12x12x6</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Convolution 2</td>
      <td style="text-align: center">12x12x6</td>
      <td style="text-align: center">5x5</td>
      <td style="text-align: center">8x8x16</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Max pooling 2</td>
      <td style="text-align: center">8x8x16</td>
      <td style="text-align: center">1x1</td>
      <td style="text-align: center">4x4x16</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Flatten</td>
      <td style="text-align: center">4x4x16</td>
      <td style="text-align: center">None</td>
      <td style="text-align: center">256x1</td>
      <td style="text-align: center">None</td>
    </tr>
    <tr>
      <td style="text-align: center">Dense 1</td>
      <td style="text-align: center">256x1</td>
      <td style="text-align: center">None</td>
      <td style="text-align: center">120x1</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Dense 2</td>
      <td style="text-align: center">120x1</td>
      <td style="text-align: center">None</td>
      <td style="text-align: center">84x1</td>
      <td style="text-align: center">Relu</td>
    </tr>
    <tr>
      <td style="text-align: center">Dense 3</td>
      <td style="text-align: center">84x1</td>
      <td style="text-align: center">None</td>
      <td style="text-align: center">10x1</td>
      <td style="text-align: center">Softmax</td>
    </tr>
  </tbody>
</table>

<p><br />
We begin implementation by importing the libraries we will be utilizing:</p>

<ul>
  <li>TensorFlow: An open-source platform for the implementation, training, and deployment of machine learning models.</li>
  <li>Keras: An open-source library used for the implementation of neural network architectures that run on both CPUs and GPUs.</li>
  <li>Numpy: A library for numerical computation with n-dimensional arrays.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">optimizers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div>
<p>Next, we load the MNIST dataset using the Keras library. The Keras library has a suite of datasets readily available for use with easy accessibility.</p>

<p>We are also required to partition the dataset into testing, validation and training. Here are some quick descriptions of each partition category.</p>

<ul>
  <li>Training Dataset: This is the group of our dataset used to train the neural network directly. Training data refers to the dataset partition exposed to the neural network during training.</li>
  <li>Validation Dataset: This group of the dataset is utilized during training to assess the performance of the network at various iterations.</li>
  <li>Test Dataset: This partition of the dataset evaluates the performance of our network after the completion of the training phase.</li>
</ul>

<p>It is also required that the pixel intensity of the images within the dataset are normalized from the value range 0–255 to 0–1.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">),</span> <span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yTest</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">xTrain</span><span class="p">),</span> <span class="mi">9</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">xTrain</span><span class="p">[</span><span class="n">indexes</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">yTrain</span><span class="p">[</span><span class="n">indexes</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p>In the code snippet above, we expand the dimensions of the training and dataset. The reason we do this is that during the training and evaluation phases, the network expects the images to be presented within batches; the extra dimension is representative of the numbers of images in a batch.</p>

<p>The code below is the main part where we implement the actual LeNet-5 based neural network. Keras provides tools required to implement the classification model. Keras presents a Sequential API for stacking layers of the neural network on top of each other.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">numClasses</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Input</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">MaxPool2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">numClasses</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">leNet5</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
<span class="n">leNet5</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s">"accuracy"</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">leNet5</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<pre><code class="language-output">Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 24, 24, 6)         156       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 12, 12, 6)         0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 8, 8, 16)          2416      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 4, 4, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 256)               0         
_________________________________________________________________
dense (Dense)                (None, 120)               30840     
_________________________________________________________________
dense_1 (Dense)              (None, 84)                10164     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                850       
=================================================================
Total params: 44,426
Trainable params: 44,426
Non-trainable params: 0
</code></pre>

<p>We first assign the variable <code class="language-plaintext highlighter-rouge">lenet_5_model</code> to an instance of the tf.keras.Sequential class constructor. Within the class constructor, we then proceed to define the layers within our model.</p>

<p>The C1 layer is defined by the <code class="language-plaintext highlighter-rouge">linekeras.layers.Conv2D(6, kernel_size=5, strides=1, activation='tanh', input_shape=train_x[0].shape, padding='same')</code>. We are using the <code class="language-plaintext highlighter-rouge">tf.keras.layers.Conv2D</code> class to construct the convolutional layers within the network. We pass a couple of arguments which are described here.</p>

<ul>
  <li>Activation Function: A mathematical operation that transforms the result or signals of neurons into a normalized output. An activation function is a component of a neural network that introduces non-linearity within the network. The inclusion of the activation function enables the neural network to have greater representational power and solve complex functions.</li>
</ul>

<p>The rest of the convolutional layers follow the same layer definition as C1 with some different values entered for the arguments.</p>

<p>In the original paper where the LeNet-5 architecture was introduced, subsampling layers were utilized. Within the subsampling layer the average of the pixel values that fall within the 2x2 pooling window was taken, after that, the value is multiplied with a coefficient value. A bias is added to the final result, and all this is done before the values are passed through the activation function.</p>

<p>But in our implemented LeNet-5 neural network, we’re utilizing the tf.keras.layers.AveragePooling2D constructor. We don’ t pass any arguments into the constructor as some default values for the required arguments are initialized when the constructor is called. Remember that the pooling layer role within the network is to downsample the feature maps as they move through the network.</p>

<p>There are two more types of layers within the network, the flatten layer and the dense layers.</p>

<p>The flatten layer is created with the class constructor tf.keras.layers.Flatten.</p>

<p>The purpose of this layer is to transform its input to a 1-dimensional array that can be fed into the subsequent dense layers.</p>

<p>The dense layers have a specified number of units or neurons within each layer, F6 has 84, while the output layer has ten units.</p>

<p>The last dense layer has ten units that correspond to the number of classes that are within the MNIST dataset. The activation function for the output layer is a softmax activation function.</p>

<ul>
  <li>Softmax: An activation function that is utilized to derive the probability distribution of a set of numbers within an input vector. The output of a softmax activation function is a vector in which its set of values represents the probability of an occurrence of a class/event. The values within the vector all add up to 1.</li>
</ul>

<p>Keras provides the ‘compile’ method through the model object we have instantiated earlier. The compile function enables the actual building of the model we have implemented behind the scene with some additional characteristics such as the loss function, optimizer, and metrics.</p>

<p>To train the network, we utilize a loss function that calculates the difference between the predicted values provided by the network and actual values of the training data.</p>

<p>The loss values accompanied by an optimization algorithm(Adam) facilitates the number of changes made to the weights within the network. Supporting factors such as momentum and learning rate schedule, provide the ideal environment to enable the network training to converge, herby getting the loss values as close to zero as possible.</p>

<p>During training, we’ll also validate our model after every epoch with the valuation dataset partition created earlier</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">leNet5</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span><span class="n">yTest</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>
<pre><code class="language-output">Epoch 1/10
938/938 [==============================] - 10s 10ms/step - loss: 1.1559 - accuracy: 0.7988 - val_loss: 0.1056 - val_accuracy: 0.9681
Epoch 2/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0982 - accuracy: 0.9690 - val_loss: 0.0759 - val_accuracy: 0.9763
Epoch 3/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.0706 - val_accuracy: 0.9792
Epoch 4/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.0723 - val_accuracy: 0.9770
Epoch 5/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.0594 - val_accuracy: 0.9825
Epoch 6/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0364 - accuracy: 0.9877 - val_loss: 0.0532 - val_accuracy: 0.9850
Epoch 7/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 0.0813 - val_accuracy: 0.9776
Epoch 8/10
938/938 [==============================] - 10s 10ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.0682 - val_accuracy: 0.9829
Epoch 9/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0618 - val_accuracy: 0.9839
Epoch 10/10
938/938 [==============================] - 9s 10ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0729 - val_accuracy: 0.9835
313/313 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9835
</code></pre>
<p>After training, you will notice that your model achieves a validation accuracy of over 90%. But for a more explicit verification of the performance of the model on an unseen dataset, we will evaluate the trained model on the test dataset partition created earlier.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">leNet5</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">xTest</span><span class="p">,</span> <span class="n">yTest</span><span class="p">)</span>
</code></pre></div></div>
<pre><code class="language-output">[0.07292196899652481, 0.9835000038146973]
</code></pre>

<p>After training my model, I was able to achieve 98% accuracy on the test dataset, which is quite useful for such a simple network.</p>

<h1 id="analyze-the-model-training-and-performance">Analyze the model training and performance</h1>

<h2 id="confusion-matrix">Confusion matrix</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="n">yPred</span> <span class="o">=</span> <span class="n">leNet5</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xTest</span><span class="p">)</span>
<span class="n">yPred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">yPred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">conf</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">yPred</span><span class="p">,</span> <span class="n">yTest</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy Score:"</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">conf</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Confusion matrix"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="accuracy-and-error-plots">Accuracy and error plots</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_train</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]</span>
<span class="n">loss_val</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss_train</span><span class="p">,</span> <span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss_val</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'validation loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and Validation loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>You can see the complete project code in my github repo from <a href="https://github.com/mralinp/cnn-networks/tree/main/lenet5"><strong>here</strong></a>.</p>

<p>I hope you found the article useful.</p>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><category term="ai" /><category term="machine-learning" /><category term="deep-learning" /><summary type="html"><![CDATA[1. Intro LeNet is a very first deep learning model that introduced in the research paper “Gradient-Based Learning Applied To Document Recognition” in the year 1998 by four legendary researchers, Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Many of the listed authors of the paper have gone on to provide several significant academic contributions to the field of deep learning. From left: Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner This article will introduce the LeNet-5 CNN architecture as described in the original paper, along with the implementation of the architecture using TensorFlow 2.0. Then conclude with the utilization of the implemented LeNet-5 CNN for the classification of images from the MNIST dataset.]]></summary></entry><entry><title type="html">Snake game</title><link href="http://localhost:4000/project/game/python/entry-level/2022/03/21/snake-game.html" rel="alternate" type="text/html" title="Snake game" /><published>2022-03-21T18:15:32+03:30</published><updated>2022-03-21T18:15:32+03:30</updated><id>http://localhost:4000/project/game/python/entry-level/2022/03/21/snake-game</id><content type="html" xml:base="http://localhost:4000/project/game/python/entry-level/2022/03/21/snake-game.html"><![CDATA[<h1 id="1-intro">1. Intro</h1>
<p>Hello there, this is Ali speaking. When I started studying computer engineering at Shiraz University, CSE101 was the introductory course we should take to familiarize ourselves with basic programming concepts. There, I have introduced to the <strong>python</strong> programming language for the first time. Python is a very cool programming language that wastes practical areas in almost any major, such as data science, machine learning, web development, game development, etc.</p>

<p><br /></p>
<div align="center">
    <img src="/assets/images/snake-game/python-logo.png" width="200px" />
</div>
<p><br /></p>

<p>Now, I’m using python almost every day of my academic career. So it was an excellent choice to begin programming and get familiar with programming concepts. On the other hand, in the first year of high school, I learned <strong>C</strong> programming as my first programming language. I was using C to solve mathematic problems and only for fun because I had no other source to learn except our computer teacher and an ancient resource based on <strong>Borland C++</strong> and running on <strong>MS-DOS</strong>. Those days we didn’t have access to the internet in our home or school, so the only way of learning things was by reading books and asking questions. To me, CSE101 was the most straightforward course of my life. I never studied anything about the course syllabuses; I just learned everything possible about python that I could find on the internet. The course’s final project was <strong>“Making a Very Simple Snake Game”</strong> (like old school Nokia phones game) without using advanced libraries or frameworks such as PyGame or other alternatives.</p>

<p>In this article, we are about to implement a <strong>Very Simple Snake Game</strong>. The problem statement is available in the next section.</p>

<h1 id="table-of-contents">Table Of Contents</h1>
<ul>
  <li><a href="#1-intro">1. Intro</a></li>
  <li><a href="#2-problem-statement">2. Problem Statement</a></li>
  <li><a href="#3-Challenges of The Project">3. Challenges of The Project</a></li>
  <li><a href="#4.solution-and-design">4. Solution and Design</a></li>
  <li><a href="#5-implementation">5. Implementation</a></li>
  <li><a href="#6-final-words">6. Final words</a></li>
</ul>

<h1 id="2-problem-statement">2. Problem Statement:</h1>

<p>Develop a straightforward snake game such as the one on old-school Nokia phones. A single snake moves around the game world. You can control the snake using arrow keys or <code class="language-plaintext highlighter-rouge">W</code>, <code class="language-plaintext highlighter-rouge">A</code>, <code class="language-plaintext highlighter-rouge">S</code>, and <code class="language-plaintext highlighter-rouge">D</code> to move <code class="language-plaintext highlighter-rouge">UP</code>, <code class="language-plaintext highlighter-rouge">LEFT</code>, <code class="language-plaintext highlighter-rouge">DOWN</code>, and <code class="language-plaintext highlighter-rouge">RIGHT</code>. Meanwhile, at any random time, it could be deployed an apple (or food) on a random spot on the map. If the snake eats the food, its tail extends by a unit, and the player receives 100 points. The map can contain some walls or obstacles. The player loses the game if the snake hits a block or its tail. Pressing the <code class="language-plaintext highlighter-rouge">Esc</code> key pauses and unpauses the game. You have to make the ability to store the achieved score after each game.</p>
<blockquote>
  <p>Note: Any creative ideas and implementations that improve performance, game experience, and appearance will be considered as bonuses.</p>
</blockquote>

<h1 id="2-solution">2. Solution</h1>
<p>Did you read the <strong><a href="#11-problem-statement">problem statement</a></strong> section carefully? As it could be found from the problem statement. We can break the problem into some parts and levels. First is to implement a moving object on the 2D game board which actually is our snake. As the game world is console and no graphical libraries are allowed here we need to think and consider about a simple world of char games. In this world, all objects in the game are nothing but characters. For example snake head can be displayed as the character <code class="language-plaintext highlighter-rouge">@</code>, its tail segments can be displayed with <code class="language-plaintext highlighter-rouge">o</code> and Apples are displayed with <code class="language-plaintext highlighter-rouge">A</code>. At the end walls could be represented as <code class="language-plaintext highlighter-rouge">#</code>. First, we try to implement the basics of the game. The challenge here is how to print a character on a specific position of the screen.</p>

<h1 id="3-challenges-of-the-project">3. Challenges of The Project</h1>

<h1 id="4-solution-and-design">4. Solution and Design</h1>

<h1 id="5-implementation">5. Implementation</h1>

<h1 id="6-final-words">6. Final words</h1>]]></content><author><name>Ali N. Parizi</name></author><category term="project" /><category term="game" /><category term="python" /><category term="entry-level" /><summary type="html"><![CDATA[1. Intro Hello there, this is Ali speaking. When I started studying computer engineering at Shiraz University, CSE101 was the introductory course we should take to familiarize ourselves with basic programming concepts. There, I have introduced to the python programming language for the first time. Python is a very cool programming language that wastes practical areas in almost any major, such as data science, machine learning, web development, game development, etc.]]></summary></entry><entry><title type="html">Hello, world!</title><link href="http://localhost:4000/blog/2022/03/20/hello-world.html" rel="alternate" type="text/html" title="Hello, world!" /><published>2022-03-20T20:02:05+03:30</published><updated>2022-03-20T20:02:05+03:30</updated><id>http://localhost:4000/blog/2022/03/20/hello-world</id><content type="html" xml:base="http://localhost:4000/blog/2022/03/20/hello-world.html"><![CDATA[<p>This is my first post on the blog on the first day of the new century (1401-01-01 00:00:00 +330).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"Hello, world!"</span>
</code></pre></div></div>

<script>
    let welcomeMessage = "IF9fICAgICAgICBfXyAgIF8gICAgICAgICAgICAgICAgICAgICAgICAgICAgXyAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgXyAgICAgICAgIF8gXyAgICAgICAgIAogXCBcICAgICAgLyAvX198IHwgX19fIF9fXyAgXyBfXyBfX18gICBfX18gIHwgfF8gX19fICAgIF8gX18gX19fICBfICAgXyAgX18gICAgICBfX19fX3wgfF9fICBfX18oXykgfF8gX19fICAgCiAgXCBcIC9cIC8gLyBfIFwgfC8gX18vIF8gXHwgJ18gYCBfIFwgLyBfIFwgfCBfXy8gXyBcICB8ICdfIGAgXyBcfCB8IHwgfCBcIFwgL1wgLyAvIF8gXCAnXyBcLyBfX3wgfCBfXy8gXyBcICAKICAgXCBWICBWIC8gIF9fLyB8IChffCAoXykgfCB8IHwgfCB8IHwgIF9fLyB8IHx8IChfKSB8IHwgfCB8IHwgfCB8IHxffCB8ICBcIFYgIFYgLyAgX18vIHxfKSBcX18gXCB8IHx8ICBfXy9fIAogICAgXF8vXF8vIFxfX198X3xcX19fXF9fXy98X3wgfF98IHxffFxfX198ICBcX19cX19fLyAgfF98IHxffCB8X3xcX18sIHwgICBcXy9cXy8gXF9fX3xfLl9fL3xfX18vX3xcX19cX19fKF8pCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIHxfX18vICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICA="
    console.log(atob(welcomeMessage));
</script>]]></content><author><name>Ali N. Parizi</name></author><category term="blog" /><summary type="html"><![CDATA[This is my first post on the blog on the first day of the new century (1401-01-01 00:00:00 +330).]]></summary></entry></feed>